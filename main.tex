\documentclass[journal]{IEEEtran}

\usepackage{adjustbox}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{array}
\usepackage{bookmark}
\usepackage{circuitikz}
\usepackage{cite}
\usepackage{colortbl}
\usepackage{environ}
\usepackage{fixmath}
\usepackage{grffile}
\usepackage{hyperref}
\usepackage{import}
\usepackage{mathtools}
\usepackage{microtype}
\usepackage{multirow}
\usepackage{pgffor}
\usepackage{pgfgantt}
\usepackage{pgfplots}
\usepackage{physics}
\usepackage{siunitx}
\usepackage{stfloats}
\usepackage{tcolorbox}
\usepackage{tikz}
\usepackage{url}
\usepackage{xcolor}
\usepackage[T1]{fontenc}
\usepackage[acronym]{glossaries-extra}
\usepackage[caption=false,font=footnotesize,subrefformat=parens,labelformat=parens]{subfig}
\usepackage[short]{optidef}
\usepackage[subtle]{savetrees}

\usepackage{xcolor} \pagecolor[rgb]{0,0,0} \color[rgb]{1,1,1}

\listfiles
\interdisplaylinepenalty=2500
\pgfplotsset{compat=newest}
\usepgfplotslibrary{patchplots,groupplots}
\usetikzlibrary{decorations.pathreplacing,calligraphy}
\usetikzlibrary{arrows,calc,matrix,plotmarks,patterns,positioning}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}
\newtheorem{theorem}{Theorem}
\DeclareSIUnit{\belm}{Bm}
\DeclareSIUnit{\dBm}{\deci\belm}
\DeclareSIUnit{\beli}{Bi}
\DeclareSIUnit{\dBi}{\deci\beli}
\ctikzset{american}
\usetikzlibrary{arrows,calc,matrix,patterns,pgfplots.groupplots,plotmarks,positioning}

\DeclarePairedDelimiterX{\infdivx}[2]{(}{)}{%
	#1\;\delimsize\|\;#2%
}
\newcommand{\infdiv}{D\infdivx}
\renewcommand{\qedsymbol}{\hfill\ensuremath{\Box}}

\makeatletter
\tikzset{
	block/.style={draw,rectangle,align=center},
    from/.style args={#1 to #2}{
        above right={0cm of #1},
        /utils/exec=\pgfpointdiff
            {\tikz@scan@one@point\pgfutil@firstofone(#1)\relax}
            {\tikz@scan@one@point\pgfutil@firstofone(#2)\relax},
        minimum width/.expanded=\the\pgf@x,
        minimum height/.expanded=\the\pgf@y
	}
}
\makeatother

\algrenewcommand{\algorithmicwhile}{\textbf{While}}
\algrenewcommand{\algorithmicif}{\textbf{If}}
\algrenewcommand{\algorithmicthen}{\textbf{Then}}
\algrenewcommand{\algorithmicelse}{\textbf{Else}}
\algrenewcommand{\algorithmicend}{\textbf{End}}
\algrenewcommand{\algorithmicrepeat}{\textbf{Repeat}}
\algrenewcommand{\algorithmicuntil}{\textbf{Until}}

\setabbreviationstyle[acronym]{long-short}

\newacronym{af}{AF}{Amplify-and-Forward}
\newacronym{ambc}{AmBC}{Ambient Backscatter Communications}
\newacronym{ap}{AP}{Access Point}
\newacronym{awgn}{AWGN}{Additive White Gaussian Noise}
\newacronym{bcd}{BCD}{Block Coordinate Descent}
\newacronym{bibo}{BIBO}{Binary-Input Binary-Output}
\newacronym{bpcu}{\si{bpcu}}{bits per channel use}
\newacronym{bpsphz}{\si{bps/Hz}}{bits per second per Hertz}
\newacronym{cr}{CR}{Cognitive Radio}
\newacronym{cscg}{CSCG}{Circularly Symmetric Complex Gaussian}
\newacronym{csi}{CSI}{Channel State Information}
\newacronym{df}{DF}{Decode-and-Forward}
\newacronym{dmc}{DMC}{Discrete Memoryless Channel}
\newacronym{dmtc}{DMTC}{Discrete Memoryless Thresholding Channel}
\newacronym{dmtmac}{DMTMAC}{Discrete Memoryless Thresholding Multiple Access Channel}
\newacronym{dtmac}{DTMAC}{Discrete Thresholding Multiple Access Channel}
\newacronym{dp}{DP}{Dynamic Programming}
\newacronym{iid}{i.i.d.}{independent and identically distributed}
\newacronym{irs}{IRS}{Intelligent Reflecting Surface}
\newacronym{kkt}{KKT}{Karush–Kuhn–Tucker}
\newacronym{mac}{MAC}{Multiple Access Channel}
\newacronym{mc}{MC}{Multiplication Coding}
\newacronym{miso}{MISO}{Multiple-Input Single-Output}
\newacronym{mimo}{MIMO}{Multiple-Input Multiple-Output}
\newacronym{ml}{ML}{Maximum-Likelihood}
\newacronym{noma}{NOMA}{Non-Orthogonal Multiple Access}
\newacronym{ofdm}{OFDM}{Orthogonal Frequency-Division Multiplexing}
\newacronym{pdf}{PDF}{Probability Density Function}
\newacronym{pgd}{PGD}{Projected Gradient Descent}
\newacronym{psk}{PSK}{Phase Shift Keying}
\newacronym{pin}{PIN}{Positive Intrinsic-Negative}
\newacronym{qam}{QAM}{Quadrature Amplitude Modulation}
\newacronym{rf}{RF}{Radio-Frequency}
\newacronym{sc}{SC}{Superposition Coding}
\newacronym{sic}{SIC}{Successive Interference Cancellation}
\newacronym{simo}{SIMO}{Single-Input Multiple-Output}
\newacronym{sinr}{SINR}{Signal-to-Interference-plus-Noise Ratio}
\newacronym{smawk}{SMAWK}{Shor-Moran-Aggarwal-Wilber-Klawe}
\newacronym{sr}{SR}{Symbiotic Radio}
\newacronym{tdma}{TDMA}{Time-Division Multiple Access}
\newacronym{tg}{TG}{tag}
\newacronym{ue}{UE}{user}
\newacronym{wit}{WIT}{Wireless Information Transfer}
\newacronym{wpcn}{WPCN}{Wireless Powered Communication Network}
\newacronym{wpt}{WPT}{Wireless Power Transfer}


\begin{document}
\title{Metascatter: Unifying Symbiotic Radio and Intelligent Reflecting Surface}
\author{
	\IEEEauthorblockN{
		Yang~Zhao,~\IEEEmembership{Member,~IEEE,}
		and~Bruno~Clerckx,~\IEEEmembership{Fellow,~IEEE}
	}
	\thanks{
		The authors are with the Department of Electrical and Electronic Engineering, Imperial College London, London SW7 2AZ, U.K. (e-mail: \{yang.zhao18, b.clerckx\}@imperial.ac.uk).
	}
}
\maketitle

\begin{abstract}
	% Backscatter allows wireless nodes to harvest energy from, modulate information over, and reconfigure propagation of surrounding radio waves.
	Backscatter nodes can harvest energy from, modulate information over, and reconfigure propagation of ambient signals.
	% Backscatter nodes can harvest energy from, modulate information over, and reconfigure propagation of surrounding radio waves.
	We uniquely introduce \emph{Metascatter} that adapts the input distribution of a finite-state passive backscatter node based on \gls{csi}, to \emph{simultaneously} encode self message and assist legacy transmission while powered by surrounding waves.
	% Compared to conventional \gls{irs}-empowered \gls{sr} that encodes and precodes independently (e.g., overlay or parallel), Metascatter refines backscatter principles to bridge parasitic source of \gls{sr} and reflecting element of \gls{irs} as extreme cases.
	Compared to existing \gls{irs}-empowered \gls{sr} that encodes and precodes independently using advanced architecture (e.g., overlay or parallel), Metascatter softly bridges and generalizes parasitic source of \gls{sr} and reflecting element of \gls{irs} via smart input design.
	% Compared to \gls{irs}-empowered \gls{sr} that encodes and precodes independently (e.g., overlay or parallel), Metascatter refines backscatter principles to bridge parasitic source of \gls{sr} and reflecting element of \gls{irs} as extreme cases.
	% Such an integrated distribution design not only yields universal modularity with reduced optimization cost, but also enables a flexible tradeoff between primary and backscatter links using shared spectrum, energy, and infrastructures.
	This not only reduces hardware complexity and optimization cost, but also enables a flexible tradeoff between primary (legacy) and backscatter links using shared spectrum, energy, and infrastructures.
	Moreover, we consider a specific scenario where a multi-antenna \gls{ap} serves a single-antenna user surrounded by multiple Metascatters.
	For simplicity, it is assumed the user first jointly decodes all backscatter messages from accumulated energy, then models reflection patterns and backscatter paths within equivalent channel for primary decoding.
	% Once modulation uncertainty of Metascatters are eliminated, models contributions from additional paths within equivalent channel
	% decodes all Metascatters jointly by energy detection, then models their contribution within equivalent channel and decodes the primary link.
	% For simplicity, the user is assumed first decodes all Metascatters jointly by energy detection, then models their contribution within equivalent channel and decodes the primary link.
	We characterize the achievable primary-(total-)backscatter rate region by optimizing the input distribution at Metascatters, the active beamforming at the AP, and the decision regions at the user.
	% A suboptimal \gls{bcd} algorithm was proposed, where the input distribution satisfying the \gls{kkt} conditions is evaluated in closed form, the transmit beamforming is optimized by \gls{pgd}, and the decision thresholds are optimized by \gls{dp}.
	A suboptimal \gls{bcd} algorithm is proposed, where the \gls{kkt} input distribution is evaluated in closed form, the active beamforming is updated by \gls{pgd}, and the suboptimal convex decision regions are refined by \gls{dp}.
	% A suboptimal \gls{bcd} algorithm was proposed with the \gls{kkt} input distribution evaluated in closed form, the active beamforming updated by \gls{pgd}, and the decision regions restricted to convex then refined by \gls{dp}.
	% the decision regions are restricted as convex then optimized by \gls{dp}.
	% A suboptimal \gls{bcd} algorithm was proposed, where the \gls{kkt} input distribution is evaluated in closed form, the active beamforming is optimized by \gls{pgd} with backtracking line search, and the decision thresholds are optimized by \gls{dp}.
	Simulation results demonstrate Metascatters can exploit additional propagation paths to transmit and assist via input design.
\end{abstract}

\begin{section}{Introduction}
	\IEEEPARstart{B}{ackscatter} is recently re-innovated as a promising approach to support low-power communications and control wireless propagation environments.
	% \IEEEPARstart{B}{ackscatter} is re-innovated to support low-power communications and control wireless propagation environments.
	% \IEEEPARstart{B}{ackscatter} allows wireless nodes to recycle existing .
	% \IEEEPARstart{B}{ackscatter} allows wireless nodes to communicate without generating carrier.
	% The concept of \gls{ambc} was first proposed in \cite{Liu2013b}, where battery-free communication between passive nodes was established by
	\gls{ambc} that enables battery-free communication between interactive nodes was first introduced and prototyped in \cite{Liu2013b}, where devices harvest energy from and modulate information over ambient \gls{rf} signals by switching between reflecting and absorbing states.
	To combat the strong direct-link interference of \gls{ambc}, \cite{Yang2018d} exploited the repeating structure of \gls{ofdm} symbol and proposed a multi-antenna detector that only requires the backscatter channel strength.
	% with periodical change of states.
	% each tag harvests energy from and modulates information over ambient \gls{rf} signals by periodically switching between different reflection patterns.
	% It enables battery-free communication between fully passive nodes, but the backscatter signal strength can be relatively weak and the decoding is subject to strong direct-link interference.
	% To solve this, \cite{Yang2018d} exploited the repeating structure of \gls{ofdm} symbol for interference cancellation based on backscatter channel strength.
	% Using co-located receiver to decode
	Cooperative \gls{ambc} that decodes primary and backscatter links using co-located receiver was proposed in \cite{Yang2018}, where the authors evaluated the error performance of \gls{ml}, linear, and \gls{sic} detectors for flat fading channels and proposed a low-complexity \gls{ml} detector for frequency-selective fading channels.
	The concept was then generalized to \gls{sr} in \cite{Liang2020} to ``exploit the benefits and address the drawbacks'' of \gls{cr} and \gls{ambc}.
	% The concept of \gls{sr} was then proposed in \cite{Liang2020} to exploit
	% symbiotic radio (SR), is proposed to ex- ploit the benefits and address the drawbacks of cognitive radio (CR) and ambient backscattering communications (AmBC)
	% When transmit cooperation is also available, cooperative \gls{ambc} is also termed as \gls{sr} \cite{Liang2020}.
	The authors of \cite{Guo2019b} classified \gls{sr} into commensal, parasitic, and competitive types based on link priority, and derived their instantaneous rates and optimal power allocations.
	The corresponding outage probabilities were also studied in \cite{Ding2020}.
	Besides, \cite{Long2020a} concluded that if the backscatter symbol period is sufficiently long, then the non-coherent primary rate would approach its coherent counterpart.
	The authors thus proposed to decode the primary link under backscatter uncertainty, then perform \gls{sic} and decode the backscatter link.
	% The authors also considered the transmit precoder design for weighted total-rate maximization and transmit power minimization problems.
	% \cite{Zhou2019a} explored how the number of transmit antennas, receive antennas, and symbol period ratio asymptotically influence the ergodic rate of primary and backscatter links.
	% For \gls{sr} with a single-antenna backscatter node,
	\cite{Zhou2019a} also explored the asymptotic impact of transmit/receive antenna and backscatter symbol period on the ergodic rate of primary and backscatter links.
	% When multi-antenna is available at the node, \cite{Wu2021a} proposed
	For a \gls{mimo} \gls{sr} system with a multi-antenna backscatter node, \cite{Wu2021a} proposed a beamforming design to maximize the backscatter rate while guaranteeing the primary performance.
	% For multi-antenna at all ends, \cite{Wu2021a} optimized transmit beamforming to maximize the backscatter achievable rate under primary rate constraint.
	% For multi-antenna at all ends, \cite{Wu2021a} optimized transmit beamforming to maximize the backscatter achievable rate under primary rate constraint.
	% For multi-antenna at all ends, \cite{Wu2021a} optimized transmit beamforming to enlarge the achievable rate region.
	However, those paper only considered one backscatter node and backscatter multiple access remains an open issue.
	In \cite{Xu2021a}, a \gls{noma}-based \gls{sr} was proposed and receive combining was investigated when \gls{sic} order follows equivalent channel strength.
	% \cite{Xu2021a} proposed a \gls{noma}-based \gls{sr} and investigated receive beamforming when \gls{sic} order is determined by equivalent channel strength.
	% \cite{Xu2021a} proposed a \gls{noma}-based \gls{sr} and studied the receive combiner design when the receiver decodes in the order of equivalent channel strength.
	% A \gls{tdma}-based \gls{sr} with energy harvesting constraints was also presented in \cite{Yang2021a}, and energy efficiency maximization was considered with respect to transmit power, reflection efficiency, and time allocation design.
	A \gls{tdma}-based \gls{sr} with energy harvesting constraints was also presented in \cite{Yang2021a}, where transmit power, reflection efficiency, and time allocation were jointly optimized to maximize energy efficiency.
	% In \cite{Han2021}, random code-assisted backscatter multiple access was combined with \gls{sr}, and the authors evaluated the asymptotic \gls{sinr} performance using random matrix theory.
	To reduce coordination between passive nodes, \cite{Han2021} proposed a random code-assisted multiple access for \gls{sr} and evaluated the asymptotic \gls{sinr} using random matrix theory.

	% On the other hand, \gls{irs} has recently emerged as a promising technique to enhance the energy efficiency.
	% In practice, an \gls{irs} consists of multiple individual sub-wavelength reflecting elements to adjust the amplitude and phase of the incoming signal (i.e., passive beamforming).
	% Different from relay, backscatter and frequency-selective surface \cite{Anwar2018}, \gls{irs} assists the primary transmission using passive components with much lower energy consumption and thermal noise, but is limited to frequency-dependent reflection.
	% On the other hand, \gls{irs} consists of numerous sub-wavelength passive elements that alter propagation environment using adaptive backscatter pattern to assist existing networks. Extensive research has been devoted to optimizing the reflection coefficient
	% On the other hand, \gls{irs} consists of numerous sub-wavelength passive elements with adaptive amplitudes and/or phases that alter propagation environment to assist existing networks.
	On the other hand, \gls{irs} alters propagation environment for legacy networks using numerous sub-wavelength passive elements with adaptive amplitudes and/or phases.
	Extensive research has been devoted to optimizing the phase shifts for the whole channel block to improve communication, sensing, and power performances \cite{Wu2018,Zhang2019a,Lin2022,Liu2022,Feng2022,Zhao2022}.
	% In contrast, dynamic passive beamforming that adjusts \gls{irs} within channel block was proposed in \cite{Yang2020} to create diversity for \gls{ofdm} systems.
	% In contrast, dynamic passive beamforming that adjusts \gls{irs} over finer time slots was proposed in \cite{Yang2020} to create diversity for \gls{ofdm} systems.
	Besides, \cite{Yang2020} proposed a dynamic passive beamforming that further adjusts \gls{irs} over fine-grained time slots for \gls{ofdm} systems to balance beamforming gain and multiuser diversity.
	The idea was further applied to \gls{wpcn} to accommodate the downlink \gls{wpt} phase and uplink \gls{wit} phase of the ``harvest-then-transmit'' protocol \cite{Wu2021d,Hua2022a}.
	% For multiuser \gls{wpt}, \cite{Qiu2022} also reported that despite \gls{irs} is restricted to single-beam reflection, dynamic beamforming can mimic multi-beam reflection in a time-division manner and reduce the phase extraction loss.
	For multiuser \gls{wpt}, \cite{Qiu2022} also reported that dynamic beamforming can mimic multi-beam reflection in a time-division manner and reduce the phase extraction loss.
	% However, dynamic passive beamforming demands additional computational complexity and control overhead, and the performance-cost tradeoff needs reconsideration especially when the number of \gls{irs} elements is large.
	% Although dynamic passive beamforming can artificially create time-varying channels for flexible channel reconfiguration and resource allocation, it demands additional computational complexity and control overhead, and the performance-cost tradeoff deserves further attention.
	% Although dynamic passive beamforming can artificially introduce temporal diversity for flexible channel reconfiguration and resource allocation, it demands additional computational complexity and control overhead, and the performance-cost tradeoff deserves further attention.
	Although dynamic passive beamforming artificially creates temporal diversity for flexible channel reconfiguration and resource allocation, it demands additional computational cost and control overhead, and the tradeoff deserves further attention especially for large \gls{irs}.
	In \cite{Chen2021,Zhang2021d}, \gls{irs} was also introduced to single- and multi-node \gls{sr} systems to reduce the total transmit power.
	When joint transmitter-\gls{irs} encoding is possible, \cite{Karasik2019} proved using \gls{irs} only for passive beamforming is generally suboptimal in terms of achievable rate for finite input constellations.
	% The capacity-achieving \gls{irs} strategy was found to
	Recently, \gls{irs}-empowered \gls{sr} was introduced in \cite{Xu2020b,Hua2022,Hu2021a} where independent passive beamforming and backscatter encoding were combined using advanced architectures.
	The authors of \cite{Xu2020b,Hua2022} proposed the \gls{irs} to modulate binary message over the whole phase shift matrix and the receiver to decodes from (non-coherent) primary to (coherent) backscatter link.
	In contrast, \cite{Hu2021a} divided the \gls{irs} into reflection and information elements, and evaluated the error performance of non-coherent backscatter detection.
	% Compared to existing \gls{irs}-empowered \gls{sr} that encodes and precodes independently using advanced architecture (e.g., overlay or parallel), Metascatter softly bridges and generalizes parasitic source of \gls{sr} and reflecting element of \gls{irs} via smart input design.

	To the best of our knowledge, all existing \gls{sr} literatures assumed backscatter modulation employs either Gaussian codebook \cite{Guo2019b,Ding2020,Long2020a,Zhou2019a,Wu2021a,Xu2021a,Yang2021a} or finite equiprobable inputs \cite{Yang2018,Han2021,Zhang2022,Xu2020b,Hua2022,Hu2021a}.
	The former is impractical for passive nodes with constrained number of states, while the latter does not fully exploit \gls{csi} to boost achievable backscatter rate.
	Besides, most relevant designs \cite{Guo2019b,Ding2020,Long2020a,Zhou2019a,Wu2021a,Xu2021a,Yang2021a,Yang2018,Han2021,Zhang2022,Xu2020b,Hua2022} were built over ideal \gls{ml} or \gls{sic} receiver.
	However, the advantage of \gls{sic} is questionable because 1) it requires non-coherent primary encoding at the transmitter and re-encoding, precoding, and subtraction at the receiver, 2) the primary and backscatter symbols are mixed by multiplication instead of superposition, and 3) the backscatter symbol period is typically much longer due to physical constraints.
	% Motivated by above, we propose a novel Metascatter network where multiple battery-free tags ride over a conventional point-to-point system and adapt their input probability distribution to simultaneously act as backscatter tags of \gls{sr} and reflecting elements of \gls{irs}.
	Motivated by those, we propose the concept of Metascatter, which adapts the input distribution of a passive backscatter node to generalize backscatter sources of \gls{sr} and reflecting elements of \gls{irs}.
	% An application scenario was considered where multiple Metascatters are introduced to conventional point-to-point system and adapt their input probability distribution to simultaneously act as backscatter tags of \gls{sr} and reflecting elements of \gls{irs}.
	% An application scenario was considered where multiple Metascatters ride over a point-to-point transmission and simultaneously perform backscatter encoding and passive beamforming.
	% ! An application scenario was considered where multiple Metascatters ride over a point-to-point transmission to simultaneously encode self message and perform passive beamforming.
	% To fully accommodate backscatter characteristics, we also propose a novel receiving strategy that first jointly decodes all Metascatter from accumulated energy, then models their reflection patterns and backscatter paths within equivalent channel for primary decoding.
	% minor modifications on existing receivers, easy to perform, fits backscatter characteristics.
	The contributions of this paper is summarized as follows.

	\emph{First,} Metascatter adapts the input probability distribution of a finite-state passive backscatter device based on primary and (cascaded) backscatter \gls{csi} to unify and generalize parasitic source of \gls{sr} and reflecting elements of \gls{irs}.
	The reflection pattern over time is no longer fully random or deterministic, but can be flexibly distributed to balance backscatter encoding and passive beamforming.
	For single-user scenario, when primary link is absolutely prioritized, the distribution falls on one state and Metascatter boils down to conventional \gls{irs}.
	When only considering backscatter performance, the distribution involves the highest entropy and Metascatter is essentially an \gls{ambc} node.

	\emph{Second,} we consider an application scenario where multiple Metascatters ride over a point-to-point transmission, exploiting additional propagation paths to simultaneously transmit and assist.
	To fully accommodate backscatter characteristics, we also propose a novel receiving strategy that first jointly decodes all Metascatter from accumulated energy, then models their reflection patterns and backscatter paths within equivalent channel for primary decoding.
	Since backscatter message is modulated over primary signal, backscatter decoding is indeed part of primary channel training, and there is no need for operation-intensive \gls{sic} at the receiver.

	% \emph{Second,} we propose a novel receiving strategy where the backscatter symbol of all tags are first recovered by energy-based decoding, then modeled within equivalent \gls{csi} for primary decoding.
	% When the ratio of backscatter symbol period over primary symbol period is large enough, the randomness of primary source can be averaged out and the performance of non-coherent backscatter decoding can be greatly improved.
	% Since the primary and backscatter symbols are mixed by multiplication coding, the backscatter decoding can be viewed as part of primary channel training, which avoids non-coherent encoding at the transmitter and \gls{sic} at the receiver.

	\emph{Third,} we evaluate the achievable primary-(total-)backscatter rate region by optimizing the input distribution at Metascatters, the active beamforming at the \gls{ap}, and the decision regions at the user. Since the original problem is highly non-convex, we consider a suboptimal \gls{bcd} algorithm where the \gls{kkt} input distribution is numerically evaluated by limit of sequences, the active beamforming is sequentially updated by \gls{pgd} accelerated by backtracking line search, and the decision regions are first restricted to convex, then refined by \gls{dp} and \gls{smawk} algorithm.

	% \emph{Third,} we characterize the achievable primary-(total-)backscatter rate region by iteratively optimizing the tag input distribution, the backscatter decision threshold, and the transmit precoder.
	% For the input design, we propose a numerical method to evaluate the \gls{kkt} solutions by limits of sequences.
	% For the threshold design, we derive the minimum number of decision thresholds to maximize the total backscatter rate, and obtain the optimal thresholds by \gls{dp} accelerated by \gls{smawk} algorithm.
	% However, the optimal precoder design can be non-trivial and we may end up with a low-complexity suboptimal solution.

	\emph{Notations:} Scalars, vectors and matrices are respectively denoted by italic, bold lower-case, and bold upper-case letters.
	$j$ represents the imaginary unit.
	% $\boldsymbol{0}$ and $\boldsymbol{1}$ denote respectively zero and one vector or matrix.
	% $\boldsymbol{I}$ represents the identity matrix.
	% $\mathbb{R}_+^{x \times y}$ and $\mathbb{C}^{x \times y}$ denote respectively the space of real nonnegative and complex $x \times y$ matrices.
	$\mathbb{R}_+^{x \times y}$ and $\mathbb{C}^{x \times y}$ respectively denote the space of real nonnegative and complex $x \times y$ matrices.
	$\Delta^n = \left\{ (p_0,\dots,p_n) \in \mathbb{R}_+^{n+1}|\sum_{i=0}^n t_i = 1 \right\}$ denotes the standard $n$-simplex.
	% $\Re\{\cdot\}$ retrieves the real part of a complex entity. $[\cdot]_{(n)}$ denotes the $n$-th entry of a vector and $[\cdot]_{(1:n)}$ denotes the first $n$ entries of a vector.
	$(\cdot)^*$, $(\cdot)^T$, $(\cdot)^H$, $(\cdot)^+$, $\lvert{\cdot}\rvert$, $\lVert{\cdot}\rVert$ respectively represent the conjugate, transpose, conjugate transpose, ramp function, absolute value, and Euclidean norm.
	% $\arg(\cdot)$, $\mathrm{rank}(\cdot)$, $\mathrm{tr}(\cdot)$, $\mathrm{diag}(\cdot)$ and $\mathrm{diag}^{-1}(\cdot)$ respectively denote the argument, rank, trace, a square matrix with input vector on the main diagonal, and a vector retrieving the main diagonal of the input matrix.
	% $\odot$ denotes the Hadamard product.
	% $\boldsymbol{S} \succeq \boldsymbol{0}$ means $\boldsymbol{S}$ is positive semi-definite.
	% $\mathbb{A}\{\cdot\}$ extracts the DC component of a signal.
	% $\mathbb{E}_X\{\cdot\}$ takes expectation w.r.t. random variable $X$ ($X$ is omitted for simplicity).
	The distribution of a CSCG random vector with mean $\boldsymbol{0}$ and covariance $\boldsymbol{\Sigma}$ is denoted by $\mathcal{CN}(\boldsymbol{0},\boldsymbol{\Sigma})$.
	$\sim$ means ``distributed as''.
	$(\cdot)^{(i)}$ represents the $i$-th iterated value and $(\cdot)^{\star}$ represents the end solution.
\end{section}

\begin{section}{Backscatter Principles}
	% \begin{figure}[!t]
	% 	\centering
	% 	\subfloat[Block Diagram]{
	% 		\resizebox{0.8\columnwidth}{!}{
	% 			\input{assets/block_diagram.tex}
	% 		}
	% 		\label{fi:block_diagram}
	% 	}
	% 	\\
	% 	\subfloat[Equivalent Circuit]{
	% 		\resizebox{0.95\columnwidth}{!}{
	% 			\input{assets/equivalent_circuit.tex}
	% 		}
	% 		\label{fi:equivalent_circuit}
	% 	}
	% 	\\
	% 	\subfloat[Scatter Model]{
	% 		\resizebox{0.8\columnwidth}{!}{
	% 			\input{assets/scatter_model.tex}
	% 		}
	% 		\label{fi:scatter_model}
	% 	}
	% 	\caption{Block diagram, equivalent circuit, and scatter model of a typical passive tag. The solid and dashed vectors represent signal and energy flows. The backscatter antenna behaves as a constant power source, where the voltage $V_0$ and current $I_0$ are introduced by incident electric field $\vec{E}_{\mathrm{I}}$ and magnetic field $\vec{H}_{\mathrm{I}}$ \cite{Huang2021}.}
	% \end{figure}

	\begin{figure*}[!t]
		\centering
		\subfloat[Block Diagram]{
			\resizebox{0.32\linewidth}{!}{
				\input{assets/block_diagram.tex}
			}
			\label{fi:block_diagram}
		}
		\subfloat[Equivalent Circuit]{
			\resizebox{0.37\linewidth}{!}{
				\input{assets/equivalent_circuit.tex}
			}
			\label{fi:equivalent_circuit}
		}
		\subfloat[Scatter Model]{
			\resizebox{0.28\linewidth}{!}{
				\input{assets/scatter_model.tex}
			}
			\label{fi:scatter_model}
		}
		\caption{Block diagram, equivalent circuit, and scatter model of a passive backscatter node. The solid and dashed vectors represent signal and energy flows. The backscatter antenna behaves as a constant power source, where the voltage $V_0$ and current $I_0$ are introduced by incident electric field $\vec{E}_{\mathrm{I}}$ and magnetic field $\vec{H}_{\mathrm{I}}$ \cite{Huang2021}.}
	\end{figure*}

	Passive backscatter nodes harvest energy from and modulate information over surrounding \gls{rf} signals.
	As shown in Fig. \subref*{fi:block_diagram}, a typical passive node consists of a scattering antenna, an energy harvester, an integrated receiver, a load-switching modulator, and on-chip components (e.g., micro-controller and sensors) \cite{Dobkin2012}.
	Its equivalent circuit is presented in Fig. \subref*{fi:equivalent_circuit}.
	% When illuminated, the node absorbs a portion of the impinging wave for information decoding and energy harvesting \cite{Kim2021a}, while scatters the remaining back to the space. The scattered signal is further decomposed into the \emph{structural} component that consistently contributes to environment multipath and covered by channel estimation \cite{Boyer2014}, and the
	When illuminated, the node absorbs a portion of the impinging wave for information decoding and/or energy harvesting \cite{Kim2021a}, and backscatters the remaining as \emph{structural} and \emph{antenna} components.
	% The scattered signal is further decomposed into the \emph{structural} component that consistently contributes to environment multipath and covered by channel estimation \cite{Boyer2014}, and the \emph{antenna} mode component that
	% and \emph{antenna} mode components \cite{Hansen1989}.
	The former consistently contributes to environment multipath and can be modelled by channel estimation \cite{Boyer2014}, while the latter depends on antenna-load impedance mismatch and can be used for backscatter modulation \cite{Boyer2012} and/or channel reconfiguration \cite{Wu2021b}.
	% Depending on structure, shape and material of general objects, structural scattering consistently contributes to environment multipath and is covered by channel estimation \cite{Boyer2014}.
	% In contrast, antenna scattering models radiation pattern from antenna-load impedance mismatch and can be used for backscatter modulation \cite{Boyer2012} and/or channel reconfiguration \cite{Wu2021b}.
	Fig. \subref*{fi:scatter_model} illustrates the scatter model of a node with $M$ states, where the reflection coefficient of state $m \in \mathcal{M} \triangleq \{1,\ldots,M\}$ is defined as%
	\footnote{It corresponds to a linear backscatter model where the reflection coefficient is irrelevant to incident electromagnetic field strength.}
	\begin{equation}
		\Gamma_m = \frac{Z_m - Z_{\mathrm{A}}^*}{Z_m + Z_{\mathrm{A}}},
		\label{eq:reflection_coefficient}
	\end{equation}
	where $Z_m$ is the load impedance at state $m$ and $Z_{\mathrm{A}}$ is the antenna input impedance.

	\begin{subsection}{SR: Backscatter Modulation}
		% Backscatter sources encode self message by \emph{randomly changing reflection states.} For $M$-ary \gls{qam}, reflection coefficient $\Gamma_m$ maps to the corresponding complex constellation point $c_m$ by \cite{Thomas2012a}
		Backscatter sources encode self message by \emph{random reflection states variation.} For $M$-ary \gls{qam}, reflection coefficient $\Gamma_m$ maps to the corresponding \emph{complex constellation point $c_m$} by \cite{Thomas2012a}
		\begin{equation}
			\Gamma_m = \alpha \frac{c_m}{\max_{m'} \lvert c_{m'} \rvert},
			\label{eq:backscatter_modulation}
		\end{equation}
		where $\alpha \in [0,1]$ is the amplitude reflect ratio that controls the harvest-scatter tradeoff at the direction of interest.
		% When the \gls{csi} and reflection alphabet $\{\Gamma_1,\ldots,\Gamma_M\}$ are available at the reader, it can decode the tag message from the observed scattered signal.
		% ! Use larger alpha in simulation: for high-order QAM, some constellation point may harvests more power than others

	\end{subsection}

	\begin{subsection}{IRS: Channel Reconfiguration}
		% \gls{irs} elements assist legacy transmission by \emph{deterministically choosing phase shifts} based on relevant \gls{csi}. For a reflecting element with $M$ candidate states, reflection coefficient $\Gamma_m$ maps to the corresponding phase shift $\theta_m$ by \cite{Wu2018}
		\gls{irs} elements assist legacy transmission by \emph{deterministic phase shifts selection} based on relevant \gls{csi}.
		For a reflecting element with $M$ candidate states, reflection coefficient $\Gamma_m$ relates to the corresponding \emph{phase shift $\theta_m$} by \cite{Wu2018}
		\begin{equation}
			\Gamma_m = \beta_m \exp(j \theta_m),
		\end{equation}
		where $\beta_m \in [0,1]$ is overall amplitude reflect ratio of state $m$.
		% Based on relevant \gls{csi}
	\end{subsection}
	% Tags periodically switch between different states to perform backscatter modulation.
	% For $M$-ary \gls{qam}, the complex constellation point $c_m \in \mathcal{C}$ maps to the reflection coefficient by \cite{Thomas2012a}
	% \begin{equation}
	% 	\Gamma_m = \alpha \frac{c_m}{\max_{m'} \lvert c_{m'} \rvert},
	% 	\label{eq:backscatter_modulation}
	% \end{equation}
	% where $\alpha \in [0,1]$ models the harvest-backscatter ratio at the direction of interest.
	% For passive tags, $\alpha \ll 1$ is commonly assumed as the majority of the incident wave can be harvested to support tag modules \cite{Thomas2012a}.

	\begin{subsection}{Metascatter: Bridge and Generalization}
		\begin{figure}[!t]
			\centering
			\subfloat[Reflection State Distribution]{
				\resizebox{0.8\columnwidth}{!}{
					\input{assets/reflection_state_distribution.tex}
				}
			}
			\\
			\subfloat[Time Slot Structure]{
				\resizebox{0.8\columnwidth}{!}{
					\input{assets/time_block_structure.tex}
				}
			}
			\caption{
				Reflection state distribution and time block structure of \gls{sr}, \gls{irs}, and Metascatter.
				$T_s$ and $T_c$ respectively denote the primary and backscatter symbol period.
				Within channel coherence time, Metascatter semi-randomly selects reflection state for each backscatter block, with guidance from input probability distribution.
			}
			\label{fi:metascatter}
		\end{figure}
		% For a passive node with finite states, is it possible to unify backscatter modulation and channel reconfiguration by proper selection of reflection coefficient?
		Metascatters simultaneously transmit and assist by \emph{adaptive input distribution design} based on primary and (cascaded) backscatter \gls{csi}.
		% The reflection pattern is neither fully random nor fully deterministic, but flexibly distributed to balance backscatter encoding and passive beamforming.
		% Instead of using fully random or deterministic reflection pattern over time, as shown in Fig. \ref{fi:metascatter}, Metascatter flexibly controls input distribution of candidate reflection states to balance backscatter encoding and passive beamforming.
		% Instead of using fully random or deterministic reflection pattern over time, as shown in Fig. \ref{fi:metascatter}, Metascatter semi-randomly selects reflection state for each backscatter block with guidance from \emph{input probability distribution $P(\Gamma_m)$.}
		% Instead of using fully random or deterministic reflection pattern over time, as shown in Fig. \ref{fi:metascatter}, Metascatter semi-randomly selects reflection state for each backscatter block, with guidance from \emph{input probability distribution $P(\Gamma_m)$.} In other words, it flexibly controls input distribution of candidate reflection states to balance backscatter encoding and passive beamforming. \gls{sr} and \gls{irs} can be regarded as extreme cases of Metascatter, where node input distribution boils down to uniform and deterministically biased, respectively.
		Instead of using fully random or deterministic reflection pattern over time, as shown in Fig. \ref{fi:metascatter}, Metascatter semi-randomly selects reflection state for each backscatter block, with \emph{guidance of input probability $P(\Gamma_m)$} for state $m$. In other words, it flexibly controls input distribution of candidate reflection states to balance backscatter encoding and passive beamforming. \gls{sr} and \gls{irs} can be regarded as extreme cases of Metascatter, where node input distribution boils down to uniform and deterministic, respectively.
		% flexibly controls input distribution of candidate reflection states to balance backscatter encoding and passive beamforming.
		% Metascatter semi-randomly selects reflection state for each backscatter block, with guidance from \emph{input probability distribution $P(\Gamma_m)$.}
		% % Based on \gls{csi}, Metascatter adapts the reflection state distribution to unify data transmission and channel reconfiguration.
		% \gls{sr} and \gls{irs} can be regarded as its extreme cases, where node input distribution boils down to uniform and deterministically biased, respectively.
		% Within channel coherence time, Metascatter semi-randomly selects reflection state for each backscatter block, with guidance from \emph{input probability distribution $P(\Gamma_m)$.}
		\begin{remark}
			Compared to conventional \gls{irs} literatures that optimize phase shifts under unit-module constraint, Metascatter starts from predefined reflection coefficients and designs their input distribution under sum-probability constraint to achieve flexible primary-backscatter tradeoff.
		\end{remark}
		% Next, we will discuss the input design in a Metascatter-enabled network.
		% consider a Metascatter-aided system to evaluate
	\end{subsection}
\end{section}

\begin{section}{Metascatter-Enabled Network}
	\begin{subsection}{System Model}
		\begin{figure}[!t]
			\centering
			\def\svgwidth{0.8\columnwidth}
			\footnotesize{
				\import{assets/}{metascatter_network.eps_tex}
			}
			\caption{A Metascatter-enabled single-user multi-node network.}
			\label{fi:metascatter_network}
		\end{figure}
		% As shown in Fig. \ref{fi:metascatter_network}, we propose a Metascatter-enabled single-user multi-node network where the spectrum, energy and infrastructures are shared by two coexisting systems.
		As shown in Fig. \ref{fi:metascatter_network}, we propose a Metascatter-enabled single-user multi-node network where two coexisting systems share spectrum, energy and infrastructures.
		% In the primary point-to-point system, the \gls{ap} transmits information to the single-antenna user.
		% In the primary point-to-point system, a $Q$-antenna \gls{ap} transmit to a single-antenna user while assisted by $K$ nearby single-antenna Metascatters.
		The primary point-to-point transmission from a $Q$-antenna \gls{ap} to a single-antenna user is assisted by $K$ nearby single-antenna Metascatters.
		In the secondary backscatter \gls{mac} system, the \gls{ap} serves as the carrier emitter, $K$ nearby single-antenna Metascatters modulate information over reradiated \gls{rf} signals, and the user decodes their messages.
		For simplicity, we consider a quasi-static block fading model where channels remain constant within coherence interval while vary independently between consecutive blocks.
		% Since backscatter modulation involves load switching, tags typically transmit at much lower rate, and we assume the backscatter symbol period is $N \in \mathbb{Z}_{++}$ times the primary symbol period.
		Due to physical constraints on load switching, we assume the backscatter symbol period is $N \gg 1$ times longer than primary and consider integer $N$ without loss of generality.
		We also assume the direct channel and all cascaded channels can be estimated and fed back to the \gls{ap}.%
		\footnote{
			Due to the lack of \gls{rf} chains at the passive tag, accurate and efficient \gls{csi} acquisition at the \gls{ap} can be challenging.
			One possibility is the \gls{ap} sends training pilots, the tags respond in predefined manners, and the user performs least-square estimation with feedbacks \cite{Bharadia2015,Yang2015b,Guo2019g}.
		}
		Besides, we omit the signal reflected by two or more times\cite{Wu2019} and ignore the time difference of arrival from different paths\cite{Guo2019b}.


		Denote the \gls{ap}-user direct channel as $\boldsymbol{h}_{\mathrm{D}}^H \in \mathbb{C}^{1 \times Q}$, the \gls{ap}-node $k \in \mathcal{K} \triangleq \{1,\ldots,K\}$ forward channel as $\boldsymbol{h}_{\mathrm{F},k}^H \in \mathbb{C}^{1 \times Q}$, and the node $k$-user backward channel as $h_{\mathrm{B},k}$. Also, define the cascaded channel of tag $k$ as $\boldsymbol{h}_{\mathrm{C},k}^H \triangleq h_{\mathrm{B},k} \boldsymbol{h}_{\mathrm{F},k}^H \in \mathbb{C}^{1 \times Q}$, and $\boldsymbol{H}_{\mathrm{C}} \triangleq [\boldsymbol{h}_{\mathrm{C},1},\ldots,\boldsymbol{h}_{\mathrm{C},K}]^H \in \mathbb{C}^{K \times Q}$.
		% Let $x_{\mathcal{K}} \triangleq \{x_k : k \in \mathcal{K}\}$ be the backscatter symbols of all Metascatters.
		Let $x_{\mathcal{K}} \triangleq (x_1,\ldots,x_K)$ be the backscatter symbol tuple of all Metascatters.
		Consider the signal model during one backscatter block (i.e., $N$ primary blocks).
		% We assume the primary symbol follows standard \gls{cscg} distribution and the backscatter symbol of all tags employs $M$-\gls{qam}.
		Under perfect synchronization, the equivalent primary channel is a function of backscatter symbols
		\begin{subequations}
			\label{eq:equivalent_channel}
			\begin{align}
				\boldsymbol{h}_{\mathrm{E}}^H(x_{\mathcal{K}})
				 & \triangleq \boldsymbol{h}_{\mathrm{D}}^H + \sum_{k \in \mathcal{K}} \sqrt{\alpha_k} \boldsymbol{h}_{\mathrm{C},k}^H x_k \\
				 & = \boldsymbol{h}_{\mathrm{D}}^H + \boldsymbol{x}^H \mathrm{diag}(\boldsymbol{\alpha}) \boldsymbol{H}_{\mathrm{C}},
			\end{align}
		\end{subequations}
		where $\alpha_k$ is the amplitude reflect ratio of Metascatter $k$, $\boldsymbol{\alpha} \triangleq [\alpha_1,\ldots,\alpha_K]^T \in \mathbb{R}_+^{K \times 1}$, $x_k \in \mathcal{X} \triangleq \{\Gamma_1,\ldots,\Gamma_M\}$ is the backscatter symbol of Metascatter $k$, and $\boldsymbol{x} \triangleq [x_1,\ldots,x_K]^H \in \mathbb{C}^{K \times 1}$. The signal received by the user at primary block $n \in \mathcal{N} \triangleq \{1,\ldots,N\}$ is
		\begin{equation}
			y[n] = \boldsymbol{h}_{\mathrm{E}}^H(x_{\mathcal{K}}) \boldsymbol{w} s[n] + v[n],
		\end{equation}
		where $s \sim \mathcal{CN}(0,1)$ is the primary symbol, $v \sim \mathcal{CN}(0,\sigma_v^2)$ is the \gls{awgn}, and $\boldsymbol{w} \in \mathbb{C}^{Q \times 1}$ is the active beamforming vector with average power constraint $\lVert \boldsymbol{w} \rVert^2 \le P$.
		% The equivalent channel for primary link is subject to backscatter uncertainty
		% The equivalent primary channel is a function of backscatter symbols  as
		% \begin{equation}
		% 	% \boldsymbol{h}_{\mathrm{E}}^H(x_{\mathcal{K}}) \triangleq \boldsymbol{h}_{\mathrm{D}}^H + \sum_{k \in \mathcal{K}} \sqrt{\alpha_k} \boldsymbol{h}_{\mathrm{C},k}^H x_k.
		% 	\boldsymbol{h}_{\mathrm{E}}^H(\boldsymbol{x}) \triangleq \boldsymbol{h}_{\mathrm{D}}^H + \boldsymbol{x}^H \mathrm{diag}(\boldsymbol{\alpha}) \boldsymbol{H}_{\mathrm{C}}.
		% 	\label{eq:equivalent_channel}
		% \end{equation}

		% where $\alpha_k$ and $x_k$ denote respectively the harvest-backscatter efficiency and backscatter symbol of tag $k$, $s[n]$ and $w[n] \sim \mathcal{CN}(0,\sigma_w^2)$ denote respectively the primary symbol and \gls{awgn} at block $n$, and $\boldsymbol{w} \in \mathbb{C}^{Q \times 1}$ is the transmit precoder satisfying power constraint $\lVert \boldsymbol{w} \rVert^2 \le P$.
		% For the ease of notation, we define $x_{\mathcal{K}} \triangleq \{x_k : k \in \mathcal{K}\}$ as the tag input combination, and $\boldsymbol{y} \triangleq \left[y[1],\ldots,y[N]\right]^T \in \mathbb{C}^{N \times 1}$ as the received signal per backscatter symbol period.
		% For primary transmission, the equivalent channel is subject to backscatter modulation uncertainty as
		% \begin{equation}
		% 	\boldsymbol{h}_{\mathrm{E}}^H(x_{\mathcal{K}}) \triangleq \boldsymbol{h}_{\mathrm{D}}^H + \sum_{k \in \mathcal{K}} \sqrt{\alpha_k} \boldsymbol{h}_{\mathrm{C},k}^H x_k.
		% 	\label{eq:equivalent_channel}
		% \end{equation}

		\begin{remark}
			Metascatter involves a symbiotic \gls{mac} where the primary and backscatter symbols of different duration are mixed by \gls{mc} instead of \gls{sc}.
			For each node, the reflection coefficient not only encodes the backscatter message, but also influences the equivalent primary channel \eqref{eq:equivalent_channel}.
			% As such, novel receiving strategy other than \gls{sic} should be tailored to signal characteristics to unveil how reflection pattern potentially influences the primary-backscatter tradeoff.
			To accommodate such signal characteristics, novel receiving strategy apart from \gls{sic} is desired to better utilize the reflection pattern and boost the primary-backscatter tradeoff.
		\end{remark}
	\end{subsection}

	\begin{subsection}{Receiving Strategy}
		We propose a Metascatter receiver where the backscatter symbols of all Metascatters are first jointly and semi-coherently detected using total received energy per backscatter block, then modeled within equivalent channel \eqref{eq:equivalent_channel} as dynamic passive beamforming.
		% identified by non-coherent energy detection, then
		% Compared with conventional schemes as joint decoding and \gls{sic}, the Metascatter receiver may not achieve as high data rate for one tag, but it avoids non-coherent primary encoding and enables tag multiple access in a practical and low-complexity manner.
		% Therefore, we believe it can be compatible to and readily implemented over legacy point-to-point systems.
		Compared with \gls{ml} and \gls{sic}, Metascatter receiver allows practical and low-complexity node multiple access with minor adjustment over legacy equipments.

		% At a specific backscatter block, denote $m_k \in \mathcal{M}$ as the state index of Metascatter $k$, and let $m_{\mathcal{K}} \triangleq \{m_k: k \in \mathcal{K}\}$ collect the state indexes of all Metascatters.
		At a specific backscatter block, denote $m_k \in \mathcal{M}$ as the state index of Metascatter $k$, and let $m_{\mathcal{K}} \triangleq (m_1,\ldots,m_K)$ be the state index tuple of all Metascatters.
		% The received signal at primary block $n$ is subject to the variation of $s[n]$ and $v[n]$, and thus distributed as $y[n] \sim \mathcal{CN}(0,\sigma_v^2)$
		Conditioned on $m_{\mathcal{K}}$, the received signal at primary block $n$ is subject to the variation of $s[n]$ and $v[n]$, distributed as $y[n] \sim \mathcal{CN}(0,\sigma_{m_{\mathcal{K}}}^2)$ with
		\begin{equation}
			% \sigma_{m_{\mathcal{K}}}^2 = \Bigl\lvert \underbrace{\bigl(\boldsymbol{h}_{\mathrm{D}}^H + \sum_{k \in \mathcal{K}} \sqrt{\alpha_k} \boldsymbol{h}_{\mathrm{C},k}^H x_{m_k}\bigr)}_{\boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}})} \boldsymbol{w} \Bigr\rvert^2 + \sigma_v^2,
			\sigma_{m_{\mathcal{K}}}^2 = \lvert \boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}}) \boldsymbol{w} \rvert^2 + \sigma_v^2,
			\label{eq:receive_variance}
		\end{equation}
		where $x_{m_k}$ and $x_{m_\mathcal{K}}$ are the symbol and symbol tuple associated with state $m_k$ and state tuple $m_{\mathcal{K}}$, respectively.%
		\footnote{
			$x_k$ and $x_{\mathcal{K}}$ are random variables, while $x_{m_k}$ and $x_{m_{\mathcal{K}}}$ are their instances indexed by $m_k$ and $m_{\mathcal{K}}$.
		}
		Also, denote the total received energy within backscatter block as $z=\sum_{n=1}^N \lvert y[n] \rvert^2$.
		% As the sum of $N$ \gls{iid} exponential variables, conditioned on $m_{\mathcal{K}}$, its \gls{pdf} follows Erlang distribution
		As the sum of $N$ \gls{iid} exponential variables, the \gls{pdf} of $z$ conditioned on $m_{\mathcal{K}}$ follows Erlang distribution
		\begin{equation}
			f(z|\mathcal{H}_{m_{\mathcal{K}}}) = \frac{z^{N-1} e^{-z/\sigma_{m_{\mathcal{K}}}^2}}{\sigma_{m_{\mathcal{K}}}^{2N} (N-1)!},
			\label{eq:energy_distribution}
		\end{equation}
		where $\mathcal{H}_{m_{\mathcal{K}}}$ denotes hypothesis $m_{\mathcal{K}}$.
		% To accommodate backscatter characteristics and reduce decoding complexity, we consider a joint semi-coherent energy detection for all Metascatters based on disjoint decision regions over accumulated energy $z$.
		To accommodate backscatter characteristics and reduce decoding complexity, we consider a joint semi-coherent detection for all Metascatters over accumulated energy $z$.
		% To reduce decoding complexity, we consider a joint semi-coherent energy detection for all Metascatters based on disjoint decision regions over accumulated energy $z$.
		\begin{figure}[!t]
			\centering
			\resizebox{0.9\columnwidth}{!}{
				\input{assets/energy_distribution.tex}
			}
			% \caption{\gls{pdf} of Average Received Power Conditioned on Different Input Hypothesis. Example \gls{ml}.}
			\caption{
				\gls{pdf} of total received energy per backscatter block, conditioned on different input hypothesis.
				% This \gls{ml} decision consists of convex regions and is generally rate-suboptimal except for equiprobable inputs.}
				Here, the convex \gls{ml} decision regions are generally rate-suboptimal except for equiprobable inputs.
			}
			\label{fi:energy_distribution}
		\end{figure}
		% The idea is presented in Fig. \ref{fi:energy_distribution}.
		% As illustrated in Fig. \ref{fi:energy_distribution}, o
		Once disjoint energy decision regions are determined, we can construct a \gls{dtmac} and formulate the transition probability from input $x_{m_{\mathcal{K}}}$ to output $\hat{x}_{m_{\mathcal{K}}'}$ as
		% it essentially formulates a \gls{dtmac}, and the transition probability from input $x_{m_{\mathcal{K}}}$ to output $\hat{x}_{m_{\mathcal{K}}'}$ is
		\begin{equation}
			P(\hat{x}_{m_{\mathcal{K}}'}|x_{m_{\mathcal{K}}}) = \int_{\mathcal{R}_{m_{\mathcal{K}}'}} f(z|\mathcal{H}_{m_{\mathcal{K}}}) \dd z,
			\label{eq:dtmac}
		\end{equation}
		where $\mathcal{R}_{m_{\mathcal{K}}'}$ is the decision region of hypothesis $\mathcal{H}_{m_{\mathcal{K}}'}$. An example of \gls{ml} energy decision is illustrated in Fig. \ref{fi:energy_distribution}.

		\begin{remark}
			% For a general input distribution, not only the optimal decision thresholds
			The rate-optimal thresholding channel design remains under-investigated, and some attempts were made for single source with binary inputs in \cite{Qian2019b,Nguyen2021b}.
			% The question was only answered for single source with binary inputs in \cite{Qian2019b,Nguyen2021b}.
			% Some attempts for single source with binary inputs were presented in \cite{Qian2019b,Nguyen2021b}.
			For non-binary inputs with general distribution, the optimal decision region for each letter can be non-convex (i.e., with non-adjacent partitions) and the optimal number of thresholds is still unknown.
			% Next, we will restrict the design over convex decision regions.
			Next, we will constrain all decision regions to convex and consider suboptimal threshold design accordingly.
			% For a general input distribution, not only the rate-optimal decision thresholds
			% % Interestingly, the optimal threshold design to maximize the mutual information for a general \gls{dmtc} with a fixed number of output letters remains an open issue.
			% % The reason is that each decision region may contain more than one disjoint partitions (i.e., non-convex) and the number of thresholds are unknown.
			% % Fortunately, for the proposed energy detection, we proved that the \gls{dmtc} capacity can be achieved using only convex decision regions.
			% not only the capacity-achieving thresholding design remains an open problem, but also the optimal number of thresholds for general non-binary-input channels remains unknown.
		\end{remark}
	\end{subsection}

	\begin{subsection}{Achievable Rates}
		Denote the input probability of state $m_k$ of Metascatter node $k$ as $P_k(x_{m_k})$, and define the input probability distribution vector of node $k$ as $\boldsymbol{p}_k \triangleq [P_k(\Gamma_1),\ldots,P_k(\Gamma_M)]^T \in \mathbb{R}^{M \times 1}$. With independent encoding at all nodes, the probability of backscatter symbol tuple $x_{m_{\mathcal{K}}}$ is $P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) = \prod_{k \in \mathcal{K}} P_k(x_{m_k})$.
		% Denote the input probability distribution vector of tag $k$ as $\boldsymbol{p}_k \triangleq [P_k(x_1),\ldots,P_k(x_M)]^T \in \mathbb{R}^{M \times 1}$, where $P_k(x_{m_k})$ is the probability at state $m_k$.
		% Consider independent encoding at all tags such that the probability of input combination $x_{m_{\mathcal{K}}}$ is $P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) = \prod_{k \in \mathcal{K}} P_k(x_{m_k})$.
		% The backscatter information function of input combination $x_{m_{\mathcal{K}}}$ is defined as
		Similar to \cite{Rezaeian2004}, we define the backscatter information function between input symbol tuple instance $x_{m_{\mathcal{K}}}$ and output symbol tuple $\hat{x}_{\mathcal{K}}$ as
		\begin{equation}
			I^{\mathrm{B}}(x_{m_{\mathcal{K}}};\hat{x}_{\mathcal{K}}) \triangleq \sum_{m_{\mathcal{K}}'} P(\hat{x}_{m_{\mathcal{K}}'}|x_{m_{\mathcal{K}}}) \log \frac{P(\hat{x}_{m_{\mathcal{K}}'}|x_{m_{\mathcal{K}}})}{P(\hat{x}_{m_{\mathcal{K}}'})},
			\label{eq:backscatter_information_function}
		\end{equation}
		where $P(\hat{x}_{m_{\mathcal{K}}'}) = \sum_{m_{\mathcal{K}}} P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) P(\hat{x}_{m_{\mathcal{K}}'}|x_{m_{\mathcal{K}}})$.
		We also define the backscatter marginal information of letter $x_{m_k}$ of node $k$ as
		% Besides, the backscatter marginal information function associated with letter $x_{m_k}$ of tag $k$ is
		\begin{equation}
			% I_{\mathrm{B},k}(x_{m_k};\hat{x}_{\mathcal{K}}) \triangleq \sum_{m_{\mathcal{K} \setminus \{k\}}} P_{\mathcal{K} \setminus \{k\}}(x_{m_{\mathcal{K} \setminus \{k\}}}) I_{\mathrm{B}}(x_{m_{\mathcal{K}}};\hat{x}_{\mathcal{K}}),
			I^{\mathrm{B}}_{k}(x_{m_k};\hat{x}_{\mathcal{K}}) \triangleq \sum_{m_{\mathcal{K} \setminus \{k\}}} P_{\mathcal{K} \setminus \{k\}}(x_{m_{\mathcal{K} \setminus \{k\}}}) I^{\mathrm{B}}(x_{m_{\mathcal{K}}};\hat{x}_{\mathcal{K}}),
			\label{eq:backscatter_marginal_information_function}
		\end{equation}
		where $P_{\mathcal{K} \setminus \{k\}}(x_{m_{\mathcal{K} \setminus \{k\}}}) = \prod_{q \in \mathcal{K} \setminus \{k\}} P_{q}(x_{m_{q}})$.
		Moreover, we can write the backscatter mutual information as
		\begin{equation}
			% I^{\mathrm{B}}(x_{\mathcal{K}};\hat{x}_{\mathcal{K}}) = \sum_{m_{\mathcal{K}}} P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) \sum_{m_{\mathcal{K}}'} P(\hat{x}_{m_{\mathcal{K}}'}|x_{m_{\mathcal{K}}}) \log \frac{P(\hat{x}_{m_{\mathcal{K}}'}|x_{m_{\mathcal{K}}})}{P(\hat{x}_{m_{\mathcal{K}}'})}.
			I^{\mathrm{B}}(x_{\mathcal{K}};\hat{x}_{\mathcal{K}}) = \sum_{m_{\mathcal{K}}} P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) I^{\mathrm{B}}(x_{m_{\mathcal{K}}};\hat{x}_{\mathcal{K}}).
			\label{eq:backscatter_mutual_information}
		\end{equation}

		% Once the tag input combination is successfully decoded, the backscatter uncertainty can be eliminated and the equivalent channel for primary transmission can be updated by \eqref{eq:equivalent_channel}.
		Once backscatter symbols are successfully decoded, we can eliminate modulation uncertainty and retrieve equivalent primary channel by \eqref{eq:equivalent_channel}. We define the primary information function conditioned on backscatter symbol tuple $x_{m_{\mathcal{K}}}$ as
		% \begin{equation}
		% 	I_{\mathrm{P}}(x_{m_{\mathcal{K}}};\boldsymbol{y}) \triangleq \log \left(1 + \frac{\lvert \boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}}) \boldsymbol{w} \rvert^2}{\sigma_w^2}\right),
		% 	\label{eq:primary_information_function}
		% \end{equation}
		\begin{equation}
			I^{\mathrm{P}}(s;y|x_{m_{\mathcal{K}}}) \triangleq \log \left(1 + \frac{\lvert \boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}}) \boldsymbol{w} \rvert^2}{\sigma_w^2}\right),
			\label{eq:primary_information_function}
		\end{equation}
		the primary marginal information conditioned on letter $x_{m_k}$ of node $k$ as
		% the primary marginal information function associated with letter $x_{m_k}$ of tag $k$ is
		\begin{equation}
			I^{\mathrm{P}}_{k}(s;y|x_{m_k}) \triangleq \sum_{m_{\mathcal{K} \setminus \{k\}}} P_{\mathcal{K} \setminus \{k\}}(x_{m_{\mathcal{K} \setminus \{k\}}}) I^{\mathrm{P}}(s;y|x_{m_{\mathcal{K}}}),
			\label{eq:primary_marginal_information_function}
		\end{equation}
		and the primary ergodic mutual information as
		% and the primary (ergodic) mutual information is
		\begin{equation}
			% I^{\mathrm{P}}(s;y|x_{\mathcal{K}}) = \sum_{m_{\mathcal{K}}} P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) \log \left(1 + \frac{\lvert \boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}}) \boldsymbol{w} \rvert^2}{\sigma_w^2}\right).
			I^{\mathrm{P}}(s;y|x_{\mathcal{K}}) = \sum_{m_{\mathcal{K}}} P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) I^{\mathrm{P}}(s;y|x_{m_{\mathcal{K}}}).
			\label{eq:primary_mutual_information}
		\end{equation}

		% Moreover, with $\rho \in [0,1]$ being the relative priority of the primary link, we define corresponding weighted sum information function, marginal information, and mutual information respectively as
		Finally, with a slight abuse of notation, we define the corresponding weighted sum information function, marginal information, and mutual information respectively as
		\begin{align}
			I(x_{m_{\mathcal{K}}})
			 & \triangleq \rho I^{\mathrm{P}}(s;y|x_{m_{\mathcal{K}}}) + (1 - \rho) I^{\mathrm{B}}(x_{m_{\mathcal{K}}};\hat{x}_{\mathcal{K}}),\label{eq:weighted_sum_information_function} \\
			I_k(x_{m_k})
			 & \triangleq \rho I^{\mathrm{P}}_{k}(s;y|x_{m_k}) + (1 - \rho) I^{\mathrm{B}}_{k}(x_{m_k};\hat{x}_{\mathcal{K}}),\label{eq:weighted_sum_marginal_information}                 \\
			I(x_{\mathcal{K}})
			 & \triangleq \rho I^{\mathrm{P}}(s;y|x_{\mathcal{K}}) + (1 - \rho) I^{\mathrm{B}}(x_{\mathcal{K}};\hat{x}_{\mathcal{K}}),\label{eq:weighted_sum_mutual_information}
		\end{align}
		where $\rho \in [0,1]$ is the relative priority of the primary link.


		% Therefore, the weighted sum information function, marginal information function, and mutual information of primary and backscatter links are respectively given by
		% \begin{align}
		% 	I(x_{m_{\mathcal{K}}};\hat{x}_{\mathcal{K}},\boldsymbol{y})
		% 	 & \triangleq \rho I_{\mathrm{P}}(x_{m_{\mathcal{K}}};\boldsymbol{y}) + (1 - \rho) I_{\mathrm{B}}(x_{m_{\mathcal{K}}};\hat{x}_{\mathcal{K}}),\label{eq:weighted_sum_information_function} \\
		% 	I_k(x_{m_k};\hat{x}_{\mathcal{K}},\boldsymbol{y})
		% 	 & \triangleq \rho I_{\mathrm{P},k}(x_{m_k};\boldsymbol{y}) + (1 - \rho) I_{\mathrm{B},k}(x_{m_k};\hat{x}_{\mathcal{K}}),\label{eq:weighted_sum_marginal_information}                     \\
		% 	I(x_{\mathcal{K}};\hat{x}_{\mathcal{K}},\boldsymbol{y})
		% 	 & \triangleq \rho I_{\mathrm{P}}(x_{\mathcal{K}};\boldsymbol{y}) + (1 - \rho) I_{\mathrm{B}}(x_{\mathcal{K}};\hat{x}_{\mathcal{K}}),\label{eq:weighted_sum_mutual_information}
		% \end{align}
		% where $\rho \in [0,1]$ represents the priority of the primary link.
	\end{subsection}
\end{section}

\begin{section}{Input Distribution, Decision Threshold, and Active Beamformer Design}
	To characterize the achievable primary-(total-)backscatter rate region of Metascatter, we aim to maximize the weighted sum mutual information with respect to tag input probability distribution $\{\boldsymbol{p}_k\}$, decision threshold vector $\boldsymbol{t}$, and transmit precoder $\boldsymbol{w}$
	\begin{maxi!}
		{\scriptstyle{\{\boldsymbol{p}_k\},\boldsymbol{t},\boldsymbol{w}}}{I(x_{\mathcal{K}})}{\label{op:weighted_sum_rate}}{\label{ob:weighted_sum_rate}}
		\addConstraint{\sum \nolimits_{m_k} P_k(x_{m_k})}{=1,}{\quad \forall k \in \mathcal{K}}{\label{co:sum_probability}}
		\addConstraint{P_k(x_{m_k})}{\ge 0,}{\quad \forall k \in \mathcal{K}, \ \forall m_k \in \mathcal{M}}{\label{co:nonnegative_probability}}
		\addConstraint{\lVert \boldsymbol{w} \rVert^2}{\le P.}{\label{co:transmit_power}}
	\end{maxi!}
	Since problem \eqref{op:weighted_sum_rate} is not jointly convex, we propose a \gls{bcd} algorithm that iteratively updates $\{\boldsymbol{p}_k\}$, $\boldsymbol{t}$ and $\boldsymbol{w}$ until convergence.

	\begin{subsection}{Input Probability Distribution}
		For any fixed decision boundary $\boldsymbol{t}$ and transmit precoder $\boldsymbol{w}$, the equivalent \gls{dtmac} can be formulated by \eqref{eq:dtmac} and problem \eqref{op:weighted_sum_rate} boils down to
		\begin{maxi!}
			{\scriptstyle{\{\boldsymbol{p}_k\}}}{I(x_{\mathcal{K}})}{\label{op:input_probability_distribution}}{}
			\addConstraint{\eqref{co:sum_probability},\eqref{co:nonnegative_probability},}
		\end{maxi!}
		which involves the product term $\prod_{k \in \mathcal{K}} P_k(x_{m_k})$ and is non-convex when $K > 1$.
		Interestingly, the total-rate optimal input design for general discrete memoryless \gls{mac} remains an open problem, and we instead propose a \gls{kkt} solution to problem \eqref{op:input_probability_distribution}.
		\begin{footnote}
			As pointed out in \cite{Buhler2011}, \gls{kkt} conditions are only necessary for total-rate optimality and these solutions may end up being saddle points.
		\end{footnote}
		\begin{proposition}
			The \gls{kkt} optimality conditions for problem \eqref{op:input_probability_distribution} are equivalent to, $\forall k \in \mathcal{K}$ and $\forall m_k \in \mathcal{M}$,
			\begin{subequations}
				\label{eq:input_kkt_condition}
				\begin{alignat}{2}
					I_k^\star(x_{m_k}) & = I^\star(x_{\mathcal{K}}), \quad   &  & P_k^\star(x_{m_k}) > 0,\label{eq:probable_states} \\
					I_k^\star(x_{m_k}) & \le I^\star(x_{\mathcal{K}}), \quad &  & P_k^\star(x_{m_k}) = 0.\label{eq:dropped_states}
				\end{alignat}
			\end{subequations}
			\label{pr:input_kkt_condition}
		\end{proposition}

		\begin{proof}
			Please refer to Appendix \ref{ap:input_kkt_condition}.
			\label{pf:input_kkt_condition}
		\end{proof}

		We notice \eqref{eq:probable_states} means each probable state of each tag should produce the same marginal information (averaged over all states of other tags), while \eqref{eq:dropped_states} implies any state of any tag with potentially less marginal information than above should not be used.
		Next, we generalize the Blahut-Arimoto algorithm \cite{Arimoto1972,Blahut1972a} and propose a numerical evaluation of \gls{kkt} points by limits of sequences.

		\begin{proposition}
			The \gls{kkt} solution of input probability of tag $k$ at state $m_k$ is given by the converging point of the sequence
			\begin{equation}
				P_k^{(r+1)}(x_{m_k}) = \frac{P_k^{(r)}(x_{m_k}) \exp \left( \frac{\rho}{1 - \rho} I_k^{(r)}(x_{m_k}) \right)}{\sum_{m_k'} P_k^{(r)}(x_{m_k'}) \exp \left( \frac{\rho}{1 - \rho} I_k^{(r)}(x_{m_k'}) \right)},
				\label{eq:input_kkt_solution}
			\end{equation}
			where $r$ is the iteration index and $\boldsymbol{p}_k^{(0)} > \boldsymbol{0}$, $\forall k \in \mathcal{K}$.
			At each iteration, the input distribution of tag $k$ is evaluated based on the updated input distribution of tags $1$ to $k-1$.
			\label{pr:input_kkt_solution}
		\end{proposition}
		\begin{proof}
			Please refer to Appendix \ref{ap:input_kkt_solution}.
			\label{pf:input_kkt_solution}
		\end{proof}
	\end{subsection}


	\begin{subsection}{Decision Threshold}

		For a given tag input distribution $\{\boldsymbol{p}_k\}$, we can formulate an equivalent information source with augmented alphabet of tag input combination.
		This equivalent source transmits at the total backscatter rate, and the input distribution is given by $P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) = \prod_{k \in \mathcal{K}} P_k(x_{m_k})$, $\forall k \in \mathcal{K}$ and $\forall m_k \in \mathcal{M}$.

		\begin{remark}
			Since the equivalent source transmits at the total backscatter rate, the \gls{dtmac} \eqref{eq:dtmac} is essentially a point-to-point \gls{dmtc} and we can simplify the decision threshold design accordingly.
			\label{re:input_combination}
		\end{remark}

		Interestingly, the optimal threshold design to maximize the mutual information for a general \gls{dmtc} with a fixed number of output letters remains an open issue.
		The reason is that each decision region may contain more than one disjoint partitions (i.e., non-convex) and the number of thresholds are unknown.
		Fortunately, for the proposed energy detection, we proved that the \gls{dmtc} capacity can be achieved using only convex decision regions.
		This conclusion is summarized below.

		\begin{proposition}
			For a discrete-input continuous-output channel in Erlang distribution \eqref{eq:energy_distribution}, if the \gls{dmtc} is constructed for detection (i.e., same input/output alphabet) and $L$ input letters are with non-zero probability, then it is possible to achieve the \gls{dmtc} capacity by $L$ non-empty convex decision regions defined by $L+1$ distinct decision thresholds.
			\label{pr:threshold}
		\end{proposition}

		\begin{proof}
			Please refer to Appendix \ref{ap:threshold}.
			\label{pf:threshold}
		\end{proof}

		Once the optimal number of decision threshold is determined, we can first discretize the output energy level into numerous bins, then obtain the optimal decision regions that maximizes the total backscatter rate by \gls{dp} accelerated by \gls{smawk} algorithm \cite{He2021}.

		\begin{tcolorbox}
			We may need to tailor threshold design for Metascatter as threshold design has potential impact on primary achievable rate, as implied by some simulation results.
		\end{tcolorbox}
	\end{subsection}

	\begin{subsection}{Precoder}
		\begin{tcolorbox}
			The optimal precoder design is highly non-convex that involves integration, entropy term, and variable on exponential.
			We may propose a suboptimal precoder based on linear combination of equivalent and cascaded channels, or consider single transmit antenna instead.
		\end{tcolorbox}
		\begin{align}
			I(x_i;\hat{x}_j)
			 & = \sum_{j \in \mathcal{I}} \int_{t_{j-1,j}}^{t_{j,j+1}} \frac{z^{N-1} \exp \left(-\frac{z}{\mathrm{tr}(H_{\mathrm{E},i} W) + \sigma_w^2}\right)}{\left(\mathrm{tr}(H_{\mathrm{E},i} W) + \sigma_w^2\right)^N (N-1)!} \dd z\nonumber                                                                                                                                                                                                                    \\
			 & \quad \times \log \frac{\int_{t_{j-1,j}}^{t_{j,j+1}} \frac{z^{N-1} \exp \left(-\frac{z}{\mathrm{tr}(H_{\mathrm{E},i} W) + \sigma_w^2}\right)}{\left(\mathrm{tr}(H_{\mathrm{E},i} W) + \sigma_w^2\right)^N (N-1)!} \dd z}{\sum_{i' \in \mathcal{I}} \int_{t_{j-1,j}}^{t_{j,j+1}} \frac{z^{N-1} \exp \left(-\frac{z}{\mathrm{tr}(H_{\mathrm{E},i'} W) + \sigma_w^2}\right)}{\left(\mathrm{tr}(H_{\mathrm{E},i'} W) + \sigma_w^2\right)^N (N-1)!} \dd z},
		\end{align}
	\end{subsection}
\end{section}

\begin{section}{Preliminary Results}
	\begin{table}[t!]
		\centering
		\caption{Parameters in simulation}
		\begin{tabular}{ll}
			Transmit antenna $Q$     & 1   \\
			Tags $K$                 & 2   \\
			States $M$               & 2   \\
			Reflect ratio $\alpha$   & 0.5 \\
			Duration ratio $N$       & 10  \\
			Noise power $\sigma_w^2$ & 1   \\
			Discretization bins      & 256
		\end{tabular}
		\label{ta:parameters}
	\end{table}
	Table \ref{ta:parameters} shows the parameters used in simulation.
	We assume all links are in standard \gls{cscg} distribution and evaluated the rate regions on two instances.
	For the input design, ``Cooperation'' assumes full transmit cooperation at all tags (i.e., joint encoding), ``Exhaustion'' runs exhaustive search on all possible input distributions, ``\gls{kkt}'' is proposed \gls{kkt} input design \eqref{eq:input_kkt_solution}, and ``Marginalization'' marginalizes the joint input array by ``Cooperation'' to obtain independent tag input distribution.
	For the threshold design, ``\gls{smawk}'' refers to the \gls{dp}-based quantization proposed in \cite{He2021}, ``Bisection'' sequentially optimizes each threshold by bisection \cite{Nguyen2020a}, and ``\gls{ml}'' is the \gls{ml} detector that requires no knowledge of input distribution.

	Figs. \ref{fi:rate_region_1} and \ref{fi:rate_region_2} show two typical scenarios where joint encoding can be helpful and unnecessary, respectively.
	Although the proposed \gls{kkt} input design converges to the optimal solutions in both examples, it may be trapped at saddle points under poor initialization, especially when the number of tags increases.

	We believed threshold design has no impact on the primary achievable rate, because primary decoding acts on $\boldsymbol{y}$ while thresholding acts on $z$.
	As such, the threshold that maximizes the total backscatter rate should also maximize the weighted sum rate.
	Interestingly, this may not be the case because the \gls{smawk} and Bisection threshold designs, both maximizing the total backscatter rate, can be outperformed by the \gls{ml} when it comes to weighted sum primary-(total-)backscatter rate.
	It may result from a precision issue, but inspires further research on threshold design for Metascatter.

	\begin{figure}[!t]
		\centering
		\resizebox{\columnwidth}{!}{
			\includegraphics{assets/rate_region_1.eps}
		}
		\caption{Achievable rate regions by input-threshold design: Case I.}
		\label{fi:rate_region_1}
	\end{figure}

	\begin{figure}[!t]
		\centering
		\resizebox{\columnwidth}{!}{
			\includegraphics{assets/rate_region_2.eps}
		}
		\caption{Achievable rate regions by input-threshold design: Case II.}
		\label{fi:rate_region_2}
	\end{figure}
	The parameters remain fixed unless specified.
\end{section}

\begin{appendix}
	\begin{subsection}{Proof of Proposition \ref{pr:input_kkt_condition}}
		Denote the Lagrange multipliers associated with \eqref{co:sum_probability} and \eqref{co:nonnegative_probability} as $\{\nu_k\}_{k \in \mathcal{K}}$ and $\{\lambda_{k,m_k}\}_{k \in \mathcal{K},m_k \in \mathcal{M}}$, respectively.
		The Lagrangian function of problem \eqref{op:input_probability_distribution} is
		\begin{align}
			% L(\{\boldsymbol{p}_k\},\{\nu_k\},\{\lambda_{k,m_k}\})
			L
			 & = - I(x_{\mathcal{K}}) + \sum_{k \in \mathcal{K}} \nu_k \left( \sum_{m_k \in \mathcal{M}} P_k(x_{m_k}) - 1 \right)\nonumber \\
			 & \quad - \sum_{k \in \mathcal{K}} \sum_{m_k \in \mathcal{M}} \lambda_{k,m_k} P_k(x_{m_k}),
		\end{align}
		and the \gls{kkt} conditions on the optimal primal and dual variables are, $\forall m_k \in \mathcal{M}$ and $\forall k \in \mathcal{K}$,
		\begin{subequations}
			\label{eq:input_kkt_condition_original}
			\begin{equation}
				- \nabla_{P_k^\star(x_{m_k})} I^\star(x_{\mathcal{K}}) + \nu_k^\star - \lambda_{k,m_k}^\star = 0,
			\end{equation}
			\begin{equation}
				\lambda_{k,m_k}^\star = 0, \quad P_k^\star(x_{m_k}) > 0,
			\end{equation}
			\begin{equation}
				\lambda_{k,m_k}^\star \ge 0, \quad P_k^\star(x_{m_k}) = 0,
			\end{equation}
		\end{subequations}
		where the directional derivative can be explicitly expressed as
		\begin{equation}
			\nabla_{P_k^\star(x_{m_k})} I^\star(x_{\mathcal{K}}) = I_k^\star(x_{m_k}) - (1 - \rho).
			\label{eq:input_directional_derivative}
		\end{equation}

		Combining \eqref{eq:input_kkt_condition_original} and \eqref{eq:input_directional_derivative}, we have
		\begin{subequations}
			\label{eq:input_kkt_condition_transformed}
			\begin{alignat}{2}
				I_k^\star(x_{m_k}) & = \nu_k^\star + (1 - \rho), \quad   &  & P_k^\star(x_{m_k}) > 0,\label{eq:probable_states_marginal} \\
				I_k^\star(x_{m_k}) & \le \nu_k^\star + (1 - \rho), \quad &  & P_k^\star(x_{m_k}) = 0,\label{eq:dropped_states_marginal}
			\end{alignat}
		\end{subequations}
		which suggests
		\begin{equation}
			\sum_{m_k} P_k^\star(x_{m_k}) I_k^\star(x_{m_k}) = \nu_k^\star + (1 - \rho).
			\label{eq:input_kkt_condition_implied}
		\end{equation}

		On the other hand, by definition of weighted sum marginal information \eqref{eq:weighted_sum_marginal_information},
		\begin{equation}
			\sum_{m_k} P_k^\star(x_{m_k}) I_k^\star(x_{m_k}) = I^\star(x_{\mathcal{K}}),
			\label{eq:weighted_sum_marginal_information_implied}
		\end{equation}
		where the right-hand side is irrelevant to $k$.
		\eqref{eq:input_kkt_condition_transformed}, \eqref{eq:input_kkt_condition_implied}, and \eqref{eq:weighted_sum_marginal_information_implied} together complete the proof.
		\qedsymbol
		\label{ap:input_kkt_condition}
	\end{subsection}

	\begin{subsection}{Proof of Proposition \ref{pr:input_kkt_solution}}
		We first prove sequence \eqref{eq:input_kkt_solution} is non-decreasing in mutual information.
		Let $P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) = \prod_{q \in \mathcal{K}} P_q(x_{m_q})$ and $P_{\mathcal{K}}'(x_{m_{\mathcal{K}}}) = P_k'(x_{m_k}) \prod_{q \in \mathcal{K} \setminus \{k\}} P_q(x_{m_q})$ be two probability distributions with potentially different marginal for tag $k \in \mathcal{K}$ at state $m_k \in \mathcal{M}$, and define an intermediate function $J \left( P_{\mathcal{K}}(x_{m_{\mathcal{K}}}),P_{\mathcal{K}}'(x_{m_{\mathcal{K}}}) \right)$ as \eqref{eq:intermediate_information_function}.
		\begin{figure*}[!b]
			\hrule
			\begin{align}
				J \left( P_{\mathcal{K}}(x_{m_{\mathcal{K}}}),P_{\mathcal{K}}'(x_{m_{\mathcal{K}}}) \right)
				 & \triangleq \rho \sum_{m_{\mathcal{K}}} P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) \log \left(1 + \frac{\lvert \boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}}) \boldsymbol{w} \rvert^2}{\sigma_w^2}\right)\nonumber                                                                                                                    \\
				 & \quad + (1 - \rho) \sum_{m_{\mathcal{K}}} P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) \sum_{m_{\mathcal{K}}'} P(\hat{x}_{m_{\mathcal{K}}'}|x_{m_{\mathcal{K}}}) \log \frac{P(\hat{x}_{m_{\mathcal{K}}'}|x_{m_{\mathcal{K}}}) P_{\mathcal{K}}'(x_{m_{\mathcal{K}}})}{P'(\hat{x}_{m_{\mathcal{K}}'}) P_{\mathcal{K}}(x_{m_{\mathcal{K}}})}.
				\label{eq:intermediate_information_function}
			\end{align}
		\end{figure*}
		It is straightforward to verify $J \left( P_{\mathcal{K}}(x_{m_{\mathcal{K}}}),P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) \right) = I(x_{\mathcal{K}})$ and $J \left( P_{\mathcal{K}}(x_{m_{\mathcal{K}}}),P_{\mathcal{K}}'(x_{m_{\mathcal{K}}}) \right)$ is a concave function for a fixed $P_{\mathcal{K}}'(x_{m_{\mathcal{K}}})$.
		By choosing $\nabla_{P_k^\star(x_{m_k})} J \left( P_{\mathcal{K}}(x_{m_{\mathcal{K}}}),P_{\mathcal{K}}'(x_{m_{\mathcal{K}}}) \right) = 0$, we have
		\begin{equation}
			S_k'(x_{m_k}) - S_k'(x_{i_k}) + (1 - \rho) \log \frac{P_k(x_{i_k})}{P_k^\star(x_{m_k})} = 0,
			\label{eq:optimal_intermediate_information_condition}
		\end{equation}
		where $i_k \ne m_k$ is the reference state and
		\begin{align}
			S_k'(x_{m_k})
			 & \triangleq I_k'(x_{m_k}) + (1 - \rho) \sum_{m_{\mathcal{K} \setminus \{k\}}} P_{\mathcal{K} \setminus \{k\}}(x_{m_{\mathcal{K} \setminus \{k\}}})\nonumber \\
			 & \quad \times \sum_{m_{\mathcal{K}}'} P(\hat{x}_{m_{\mathcal{K}}'}|x_{m_{\mathcal{K}}}) \log P_{\mathcal{K}}'(x_{m_{\mathcal{K}}}).
		\end{align}

		Evidently, $\forall m_k \ne i_k$, \eqref{eq:optimal_intermediate_information_condition} boils down to
		\begin{equation}
			P_k^\star(x_{m_k}) = \frac{P_k'(x_{m_k}) \exp \left( \frac{\rho}{1 - \rho} I_k'(x_{m_k}) \right)}{\sum_{m_k'} P_k'(x_{m_k'}) \exp \left( \frac{\rho}{1 - \rho} I_k'(x_{m_k'}) \right)}.
			\label{eq:optimal_relative_distribution}
		\end{equation}

		Although it seems $P_k(x_{i_k}) = 1 - \sum_{m_k \ne i_k} P_k^\star(x_{m_k})$ has no optimality guarantee, we can verify that $P_k(x_{i_k})$ has exactly the same form as \eqref{eq:optimal_relative_distribution}.
		It implies the selection of reference state does not matter and \eqref{eq:optimal_relative_distribution} is indeed optimal $\forall m_k \in \mathcal{M}$.
		Therefore, for a fixed $P_{\mathcal{K}}'(x_{m_{\mathcal{K}}})$, choosing $P_k(x_{m_k})$ by \eqref{eq:optimal_relative_distribution} ensures
		\begin{equation}
			J \left( P_{\mathcal{K}}(x_{m_{\mathcal{K}}}),P_{\mathcal{K}}'(x_{m_{\mathcal{K}}}) \right) \ge I'(x_{\mathcal{K}}).
			\label{eq:information_difference_lower}
		\end{equation}

		On the other hand, \eqref{eq:optimal_relative_distribution} also guarantees
		\begin{subequations}
			\label{eq:information_difference_upper}
			\begin{align}
				\Delta
				 & \triangleq I(x_{\mathcal{K}}) - J \left( P_{\mathcal{K}}(x_{m_{\mathcal{K}}}),P_{\mathcal{K}}'(x_{m_{\mathcal{K}}}) \right)                                                                                                                     \\
				 & = (1 - \rho) \sum_{m_k} \frac{P_k'(x_{m_k}) f_k'(x_{m_k})}{\sum_{m_k'} P_k'(x_{m_k'}) f_k'(x_{m_k'})} \sum_{m_{\mathcal{K}}''} P(\hat{x}_{m_{\mathcal{K}}''}|x_{m_k})\nonumber                             \\
				 & \quad \times \log \frac{\sum_{m_k'} P_k'(x_{m_k'}) P(\hat{x}_{m_{\mathcal{K}}''}|x_{m_k'}) f_k'(x_{m_k})}{\sum_{m_k'} P_k'(x_{m_k'}) P(\hat{x}_{m_{\mathcal{K}}''}|x_{m_k'}) f_k'(x_{m_k'})}               \\
				 & \ge (1 - \rho) \sum_{m_k} \frac{P_k'(x_{m_k}) f_k'(x_{m_k})}{\sum_{m_k'} P_k'(x_{m_k'}) f_k'(x_{m_k'})} \sum_{m_{\mathcal{K}}''} P(\hat{x}_{m_{\mathcal{K}}''}|x_{m_k})\nonumber                           \\
				 & \quad \times \left( 1 - \frac{\sum_{m_k'} P_k'(x_{m_k'}) P(\hat{x}_{m_{\mathcal{K}}''}|x_{m_k'}) f_k'(x_{m_k'})}{\sum_{m_k'} P_k'(x_{m_k'}) P(\hat{x}_{m_{\mathcal{K}}''}|x_{m_k'}) f_k'(x_{m_k})} \right) \\
				 & = 0,
			\end{align}
		\end{subequations}
		where $f_k'(x_{m_k}) \triangleq \exp \left( \frac{\rho}{1 - \rho} I_k'(x_{m_k}) \right)$ and the equality holds if and only if \eqref{eq:optimal_relative_distribution} converges.
		\eqref{eq:information_difference_lower} and \eqref{eq:information_difference_upper} together imply $I(x_{\mathcal{K}}) \ge I'(x_{\mathcal{K}})$.
		Since mutual information is bounded above, we conclude the sequence \eqref{eq:input_kkt_solution} is non-decreasing and convergent in mutual information.

		Next, we prove that any converging point of sequence \eqref{eq:input_kkt_solution}, denoted as $P_k^\star(x_{m_k})$, fulfills \gls{kkt} conditions \eqref{eq:input_kkt_condition}.
		To see this, consider $P_k^{(0)}(x_{m_k}) > 0$ and define
		\begin{equation}
			D_k^{(r)}(x_{m_k}) \triangleq \frac{P_k^{(r+1)}(x_{m_k})}{P_k^{(r)}(x_{m_k})} = \frac{f_k^{(r)}(x_{m_k})}{\sum_{m_k'} P_k^{(r)}(x_{m_k'}) f_k^{(r)}(x_{m_k'})}.
		\end{equation}

		As sequence \eqref{eq:input_kkt_solution} is convergent, any state with $P_k^\star(x_{m_k}) > 0$ need to satisfy $D_k^\star(x_{m_k}) \triangleq \lim_{r \to \infty} D_k^{(r)}(x_{m_k}) = 1$, namely
		\begin{equation}
			I_k^\star(x_{m_k}) = \frac{1 - \rho}{\rho} \log \sum_{m_k'} P_k^\star(x_{m_k'}) f_k^\star(x_{m_k'}),
		\end{equation}
		which is reminiscent of \eqref{eq:probable_states_marginal} (and hence \eqref{eq:probable_states}).
		That is to say, given $P_k^{(0)}(x_{m_k}) > 0$, any converging point with $P_k^\star(x_{m_k}) > 0$ must satisfy \eqref{eq:probable_states}.
		On the other hand, we assume $P_k^\star(x_{m_k})$ does not satisfy \eqref{eq:dropped_states}, such that for any state with $P_k^\star(x_{m_k}) = 0$,
		% On the other hand, we show if $P_k^\star(x_{m_k})$ does not satisfy \eqref{eq:dropped_states}, then it is not a converging point of sequence \eqref{eq:input_kkt_solution}. By this assumption, for any state with $P_k^\star(x_{m_k}) = 0$,
		\begin{equation}
			I_k^\star(x_{m_k}) > I^\star(x_{\mathcal{K}}) = \sum_{m_k'} P_k^\star(x_{m_k'}) I_k^\star(x_{m_k'}),
		\end{equation}
		where the equality inherits from \eqref{eq:weighted_sum_mutual_information}.
		Since the exponential function is monotonically increasing, we have $f_k^\star(x_{m_k}) > \sum_{m_k'} P_k^\star(x_{m_k'}) f_k^\star(x_{m_k'})$ and $D_k^\star(x_{m_k}) > 1$.
		Considering $P_k^{(0)}(x_{m_k}) > 0$ and $P_k^\star(x_{m_k}) = 0$, it contradicts with
		\begin{equation}
			P_k^{(r)}(x_{m_k}) = P_k^{(0)}(x_{m_k}) \prod_{n=1}^r D_k^{(n)}(x_{m_k}).
		\end{equation}
		Therefore, given $P_k^{(0)}(x_{m_k}) > 0$, any converging point with $P_k^\star(x_{m_k}) = 0$ must satisfy \eqref{eq:dropped_states}.
		This completes the proof.
		\qedsymbol
		\label{ap:input_kkt_solution}
	\end{subsection}

	\begin{subsection}{Proof of Proposition \ref{pr:threshold}}
		Since $L$ input letters are with non-zero probability and $x \to z \to \hat{x}$ formulates a Markov chain, we need $L$ non-empty decision regions and at least $L+1$ distinct thresholds (including \num{0} and $\infty$) to minimize the distortion between source and decision.
		On the other hand, the optimal decision regions are apparently empty for those unused letters.

		Suppose the optimal number of thresholds is $S+1$ where $S \ge L$.
		Let $\boldsymbol{t} \triangleq [t_0,\ldots,t_S]^T \in \mathbb{R}_{+}^{(S+1) \times 1}$ be the optimal threshold vector where $t_{s-1} < t_s$, $\forall s \in \mathcal{S} \triangleq \{1,\ldots,S\}$.
		Since the optimal decision region for any letter may consist of multiple partitions, without loss of generality, we assume the mapping from threshold vector to decision region $l' \in \mathcal{L} \triangleq \{1,\ldots,L\}$ is given by $\mathcal{R}_{l'} = \bigcup_{s \equiv l' \pmod L} [t_{s-1},t_s)$.
		\begin{footnote}
			The proof holds for any valid mapping from threshold vector to decision regions, and we consider this specific case for the ease of presentation.
		\end{footnote}
		The threshold optimization problem is
		\begin{maxi!}
			{\scriptstyle{\boldsymbol{t}}}{I_{\mathrm{B}}(x;\hat{x})}{\label{op:decision_threshold}}{\label{ob:backscatter_mutual_information}}
			\addConstraint{t_{s-1}}{< t_s,}{\quad \forall s \in \mathcal{S}.}{\label{co:strict_inequality}}
		\end{maxi!}

		Problem \eqref{op:decision_threshold} is intricate due to the strict inequality constraint \eqref{co:strict_inequality}.
		Following \cite{Nguyen2020}, we first relax it to the convex counterpart, then discard the solutions that violate any original constraint.
		The Lagrangian function for the relaxed problem is
		\begin{equation}
			L = - I_{\mathrm{B}}(x;\hat{x}) + \sum_{s \in \mathcal{S}} \mu_s (t_{s-1} - t_s),
		\end{equation}
		where $\mu_s$ is the Lagrange multiplier associated with the non-strict version of \eqref{co:strict_inequality}.
		The \gls{kkt} conditions on the optimal primal and dual solutions are, $\forall s \in \mathcal{S}$,
		\begin{subequations}
			\label{eq:kkt_thresholding}
			\begin{equation}
				- \nabla_{t_s^\star} I^\star_{\mathrm{B}}(x;\hat{x}) + \mu_{s-1}^\star - \mu_s^\star = 0,
				\label{eq:stationarity}
			\end{equation}
			\begin{equation}
				\mu_s^\star \ge 0,
				\label{eq:dual_feasibility}
			\end{equation}
			\begin{equation}
				\mu_s^\star (t_{s-1}^\star - t_s^\star) = 0.
				\label{eq:complementary_slackness}
			\end{equation}

		\end{subequations}
		Due to the strict inequality constraint \eqref{co:strict_inequality}, conditions \eqref{eq:dual_feasibility} and \eqref{eq:complementary_slackness} together imply $\mu_s^\star = 0$, $\forall s \in \mathcal{S}$.
		Besides, it is trivial to conclude $t_0^\star = 0$ for energy-based detection.
		As such, the necessary optimality conditions for problem \eqref{op:decision_threshold}, $\forall s \in \mathcal{S}$,
		\begin{equation}
			\nabla_{t_{s}^\star} I^\star_{\mathrm{B}}(x;\hat{x}) = 0,
		\end{equation}
		which can be explicitly written as, $\forall s \equiv l' \pmod L$,
		\begin{equation}
			\sum_l P(x_l) \frac{(t_s^\star)^{N-1} e^{-t_s^\star/\sigma_l^2}}{\sigma_l^{2N} (N-1)!} \log \frac{P(x_l|\hat{x}_{l'+1})}{P(x_l|\hat{x}_{l'})} = 0,
			\label{eq:kkt_threshold_explicit}
		\end{equation}

		According to \cite{He2021}, the optimal backward channel quantizer is convex and separates each pair of posterior distribution by a hyperplane.
		It implies, for a given output letter $l'$, the sequence $\{\log {P(x_l|\hat{x}_{l'+1})}/{P(x_l|\hat{x}_{l'})}\}_{l \in \mathcal{L}}$ changes sign exactly once.
		We notice the left-hand side of \eqref{eq:kkt_threshold_explicit} is a generalized Dirichlet polynomial, and by Descartes' rule of signs \cite{Jameson2006}, has at most one positive solution.
		% TODO
		In other words, starting from $t_0^\star$, each optimal decision region requires at most one additional distinct threshold, and we have $S \le L$.
		Therefore, we conclude $S = L$ and the proof is completed.
		\qedsymbol
		\label{ap:threshold}
	\end{subsection}
\end{appendix}


\bibliographystyle{IEEEtran}
\bibliography{library.bib}
\end{document}
