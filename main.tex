\documentclass[journal]{IEEEtran}

\usepackage{adjustbox}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{bookmark}
\usepackage[american]{circuitikz}
\usepackage{cite}
\usepackage{fixmath}
\usepackage[acronym]{glossaries-extra}
\usepackage{hyperref}
\usepackage{import}
\usepackage{mathtools}
\usepackage{microtype}
\usepackage[short]{optidef}
\usepackage{pgfplots}
\usepackage[subtle]{savetrees}
\usepackage{siunitx}
\usepackage{stfloats}
\usepackage[caption=false,font=footnotesize,subrefformat=parens,labelformat=parens]{subfig}
\usepackage{tikz}
\usepackage{xcolor}

\usepackage{xcolor} \pagecolor[rgb]{0,0,0} \color[rgb]{1,1,1}

% amsthm
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}

% siunitx
\DeclareSIUnit{\belm}{Bm}
\DeclareSIUnit{\dBm}{\deci\belm}
\DeclareSIUnit{\beli}{Bi}
\DeclareSIUnit{\dBi}{\deci\beli}

% PGF/TikZ
\usetikzlibrary{arrows,calc,matrix,patterns,plotmarks,positioning}
\usepgfplotslibrary{groupplots,patchplots}
\pgfplotsset{compat=newest}

% algpseudocode
\makeatletter
\renewcommand{\fnum@algorithm}{\fname@algorithm{} \thealgorithm:}
\makeatother
\algrenewcommand{\algorithmicrequire}{\textbf{Input:}}
\algrenewcommand{\algorithmicensure}{\textbf{Output:}}
\algrenewcommand{\algorithmicwhile}{\textbf{While}}
\algrenewcommand{\algorithmicend}{\textbf{End}}
\algrenewcommand{\algorithmicrepeat}{\textbf{Repeat}}
\algrenewcommand{\algorithmicuntil}{\textbf{Until}}
\algrenewcommand{\algorithmicdo}{}

% glossaries-extra
\setabbreviationstyle[acronym]{long-short}
\newacronym{af}{AF}{Amplify-and-Forward}
\newacronym{ambc}{AmBC}{Ambient Backscatter Communications}
\newacronym{ap}{AP}{Access Point}
\newacronym{awgn}{AWGN}{Additive White Gaussian Noise}
\newacronym{bcd}{BCD}{Block Coordinate Descent}
\newacronym{bc}{BackCom}{Backscatter Communications}
\newacronym{bibo}{BIBO}{Binary-Input Binary-Output}
\newacronym{bpcu}{\si{bpcu}}{bits per channel use}
\newacronym{bpsphz}{\si{bps/Hz}}{bits per second per Hertz}
\newacronym{cp}{CP}{Canonical Polyadic}
\newacronym{cr}{CR}{Cognitive Radio}
\newacronym{cscg}{CSCG}{Circularly Symmetric Complex Gaussian}
\newacronym{csi}{CSI}{Channel State Information}
\newacronym{df}{DF}{Decode-and-Forward}
\newacronym{dmc}{DMC}{Discrete Memoryless Channel}
\newacronym{dmtc}{DMTC}{Discrete Memoryless Thresholding Channel}
\newacronym{dmtmac}{DMTMAC}{Discrete Memoryless Thresholding Multiple Access Channel}
\newacronym{dtmac}{DTMAC}{Discrete Thresholding Multiple Access Channel}
\newacronym{dp}{DP}{Dynamic Programming}
\newacronym{iid}{i.i.d.}{independent and identically distributed}
\newacronym{kkt}{KKT}{Karush-Kuhn-Tucker}
\newacronym{mac}{MAC}{Multiple Access Channel}
\newacronym{mc}{MC}{Multiplication Coding}
\newacronym{miso}{MISO}{Multiple-Input Single-Output}
\newacronym{mimo}{MIMO}{Multiple-Input Multiple-Output}
\newacronym{ml}{ML}{Maximum-Likelihood}
\newacronym{noma}{NOMA}{Non-Orthogonal Multiple Access}
\newacronym{ofdm}{OFDM}{Orthogonal Frequency-Division Multiplexing}
\newacronym{pdf}{PDF}{Probability Density Function}
\newacronym{pgd}{PGD}{Projected Gradient Descent}
\newacronym{psk}{PSK}{Phase Shift Keying}
\newacronym{qam}{QAM}{Quadrature Amplitude Modulation}
\newacronym{rf}{RF}{Radio-Frequency}
\newacronym{ris}{RIS}{Reconfigurable Intelligent Surface}
\newacronym{sc}{SC}{Superposition Coding}
\newacronym{sic}{SIC}{Successive Interference Cancellation}
\newacronym{simo}{SIMO}{Single-Input Multiple-Output}
\newacronym{sinr}{SINR}{Signal-to-Interference-plus-Noise Ratio}
\newacronym{smawk}{SMAWK}{Shor-Moran-Aggarwal-Wilber-Klawe}
\newacronym{sr}{SR}{Symbiotic Radio}
\newacronym{tdma}{TDMA}{Time-Division Multiple Access}
\newacronym{ue}{UE}{user}
\newacronym{wit}{WIT}{Wireless Information Transfer}
\newacronym{wpcn}{WPCN}{Wireless Powered Communication Network}
\newacronym{wpt}{WPT}{Wireless Power Transfer}


\begin{document}
% \title{UniScatter: Unifying Backscatter Communication, Reconfigurable Intelligent Surface, and Symbiotic Radio}
% \title{UniScatter:\\Unifying Backscatter Communication, Reconfigurable Intelligent Surface, and Symbiotic Radio}
\title{UniScatter: Unifying\\Backscatter Communications, Reconfigurable Intelligent Surface, and Symbiotic Radio}
% \title{UniScatter: Unifying Symbiotic Radio, Reconfigurable Intelligent Surface, and Wireless Sensor Network}
% \title{UniScatter: Unifying Symbiotic Radio and Reconfigurable Intelligent Surface}
\author{
	\IEEEauthorblockN{
		Yang~Zhao,~\IEEEmembership{Member,~IEEE,}
		and~Bruno~Clerckx,~\IEEEmembership{Fellow,~IEEE}
	}
	\thanks{
		The authors are with the Department of Electrical and Electronic Engineering, Imperial College London, London SW7 2AZ, U.K. (e-mail: \{yang.zhao18, b.clerckx\}@imperial.ac.uk).
	}
}
\maketitle

\begin{abstract}

	% Space-division multiple access (SDMA) utilizes linear precoding to separate users in the spatial domain and relies on fully treating any residual multi-user interference as noise. Non-orthogonal multiple access (NOMA) uses linearly precoded superposition coding with successive interference cancellation (SIC) to superpose users in the power domain and relies on user grouping and ordering to enforce some users to fully decode and cancel interference created by other users. In this paper, we argue that to efficiently cope with the high throughput, heterogeneity of quality of service (QoS), and massive connectivity requirements of future multi-antenna wireless networks, multiple access design needs to depart from those two extreme interference management strategies, namely fully treat interference as noise (as in SDMA) and fully decode interference (as in NOMA). Considering a multiple-input single-output broadcast channel, we develop a novel multiple access framework, called rate-splitting multiple access (RSMA). RSMA is a more general and more powerful multiple access for downlink multi-antenna systems that contains SDMA and NOMA as special cases. RSMA relies on linearly precoded rate-splitting with SIC to decode part of the interference and treat the remaining part of the interference as noise. This capability of RSMA to partially decode interference and partially treat interference as noise enables to softly bridge the two extremes of fully decoding interference and treating interference as noise and provides room for rate and QoS enhancements and complexity reduction. The three multiple access schemes are compared, and extensive numerical results show that RSMA provides a smooth transition between SDMA and NOMA and outperforms them both in a wide range of network loads (underloaded and overloaded regimes) and user deployments (with a diversity of channel directions, channel strengths, and qualities of channel state information at the transmitter). Moreover, RSMA provides rate and QoS enhancements over NOMA at a lower computational complexity for the transmit scheduler and the receivers (number of SIC layers).

	% In the past few years, a large body of literature has been created on downlink Non-Orthogonal Multiple Access (NOMA), employing superposition coding and Successive Interference Cancellation (SIC), in multi-antenna wireless networks. Furthermore, the benefits of NOMA over Orthogonal Multiple Access (OMA) have been highlighted. In this paper, we take a critical and fresh look at the downlink Next Generation Multiple Access (NGMA) literature. Instead of contrasting NOMA with OMA, we contrast NOMA with two other multiple access baselines. The first is conventional Multi-User Linear Precoding (MU–LP), as used in Space-Division Multiple Access (SDMA) and multi-user Multiple-Input MultipleOutput (MIMO) in 4G and 5G. The second, called Rate-Splitting Multiple Access (RSMA), is based on multi-antenna Rate-Splitting (RS). It is also a non-orthogonal transmission strategy relying on SIC developed in the past few years in parallel and independently from NOMA. We show that there is some confusion about the benefits of NOMA, and we dispel the associated misconceptions. First, we highlight why NOMA is inefficient in multi-antenna settings based on basic multiplexing gain analysis. We stress that the issue lies in how the NOMA literature, originally developed for single-antenna setups, has been hastily applied to multi-antenna setups, resulting in a misuse of spatial dimensions and therefore loss in multiplexing gains and rate. Second, we show that NOMA incurs a severe multiplexing gain loss despite an increased receiver complexity due to an inefficient use of SIC receivers. Third, we emphasize that much of the merits of NOMA are due to the constant comparison to OMA instead of comparing it to MU–LP and RS baselines. We then expose the pivotal design constraint that multi-antenna NOMA requires one user to fully decode the messages of the other users. This design constraint is responsible for the multiplexing gain erosion, rate and spectral efficiency loss, ineffectiveness to serve a large number of users, and inefficient use of SIC receivers in multi-antenna settings. Our analysis and simulation results confirm that NOMA should not be applied blindly to multi-antenna settings, highlight the scenarios where MU–LP outperforms NOMA and vice versa, and demonstrate the inefficiency, performance loss, and complexity disadvantages of NOMA compared to RSMA. The first takeaway message is that, while NOMA is suited for single-antenna settings (as originally intended), it is not efficient in most multi-antenna deployments. The second takeaway message is that another non-orthogonal transmission framework, based on RSMA, exists which fully exploits the multiplexing gain and the benefits of SIC to boost the rate and the number of users to serve in multi-antenna settings and outperforms both NOMA and MU–LP. Indeed, RSMA achieves higher multiplexing gains and rates, serves a larger number of users, is more robust to user deployments, network loads and inaccurate channel state information and has a lower receiver complexity than NOMA. Consequently, RSMA is a promising technology for NGMA and future networks such as 6G and beyond.


	Scatterers can harvest energy from, modulate information over, and influence propagation of surrounding radio waves.
	% Conventional literatures treat backscatter communication,
	% \gls{ris} employs scattering antennas or programmable metamaterial to control wireless channel of legacy networks.
	% \gls{bc} varies the input impedance of physical objects to manipulate the magnitude, phase, and/or frequency of scattered signal to communicate within range.
	\gls{bc} varies object impedance to manipulate the magnitude, phase, and/or frequency of scattered signal to encode information and deliver within coverage.
	% \gls{bc} changes the magnitude, phase, and/or frequency of scattered signal of ph
	% varies the input impedance of physical objects to manipulate the magnitude, phase, and/or frequency of the scattered signal to encode self information.
	% a tag af- fixed to objects [1]. The information on EPC-tagged objects
	% By varying the antenna impedance, a RFID tag can encode digital (typically binary) symbols onto the uplink signal, which is then decoded by the RFID reader.
	% changes the scattered signal
	\gls{ris} adapts scattering antennas or programmable metamaterial to control propagation environment and enhance signal strength in the desired direction.
	% Conventional \gls{ris} and \gls{sr} appeared as
	% \gls{sr} integrates scatter nodes into legacy systems to reuse
	% Different from CR that uses power-consuming active RF chains at both PTx and STx shown in Fig. 1(b), the SR uses backscattering radio technology to support the secondary transmission from STx to SRx, which greatly reduces the power consumption. In particular, STx transmits its messages to SRx over the RF signals received from PTx by varying the reflection coefficients, thus the secondary system shares the spectrum, energy, and infrastructure of the primary system with high spectrum- and power-efficiency.
	\gls{sr} incorporates scatter nodes into active wireless networks and utilize recycled signal to transmit self information and enhance legacy multipath to the cooperative receiver.
	% In this paper, we introduce UniScatter as a novel paradigm that bridges and generalizes those concepts to support the high throughput, ultralow power, and ubiquitous connectivity of future wireless networks.
	In this paper, we introduce UniScatter as a novel paradigm that bridges and generalizes those three concepts to support the high throughput, ultralow power, and ubiquitous connectivity of future wireless networks using shared spectrum, energy, and infrastructures.
	% Based on \gls{csi} and link priority, UniScatter nodes adapt input probability distribution of reflection states
	% Based on \gls{csi}, each UniScatter node adapts probability distribution of reflection states to flexibly balance information encoding and passive beamforming in a mutualistic manner.
	Based on \gls{csi}, each UniScatter node adapts probability distribution of reflection states to balance information encoding and passive beamforming in a mutualistic and flexible manner.
	The scatter source of \gls{bc}/\gls{sr} and reflecting element of \gls{ris} can be regarded as extreme cases of UniScatter node, where the input distribution boils down to equiprobable and degenerate, respectively.
	% Existing \gls{ris}-based \gls{bc}
	% UniScatter unifies \gls{bc}, \gls{ris} and \gls{sr} f
	% To evaluate the benefits of UniScatter, we consider
	% To accommodate signal characteristics, the receiver first jointly and semi-coherently decodes all UniScatter nodes over accumulated energy, then re-encodes to retrieve
	To accommodate signal characteristics, we propose a practical receiver that first semi-coherently decodes all nodes from accumulated energy, then re-encodes and determines the equivalent channel for primary decoding.
	% It not only avoids high complexity of joint \gls{ml} and \gls{sic}, but also preserves the benefits of passive beamforming on primary link.
	It reduces the complexity of cooperative decoding and preserves the benefit of passive beamforming on primary link.
	Moreover, we consider a scenario where a multi-antenna \gls{ap} serves a single-antenna user surrounded by multiple UniScatter nodes, and characterize the achievable primary-(total-)backscatter rate region by optimizing input distribution at nodes, active beamforming at the \gls{ap}, and decision regions at the user.
	Simulation results demonstrate UniScatter can unify \gls{bc}, \gls{ris} and \gls{sr} to flexibly control transmit-assist tradeoff via smart input distribution design.
	% Simulation results demonstrate Metascatters can exploit additional propagation paths to transmit and assist via adaptive input design.



	% characterize the achievable primary-(total-)backscatter rate region for a single-antenna user surrounded by multiple UniScatter nodes,



	% Since UniScatter nodes ride over legacy signal and , backscatter decoding can be viewed as part of primary channel training

	% To fully accommodate backscatter characteristics, we also propose a novel receiving strategy that first jointly decodes all Metascatter from accumulated energy, then models their reflection patterns and backscatter paths within equivalent channel for primary decoding.
	% Since backscatter message is modulated over primary signal, backscatter decoding is indeed part of primary channel training, and there is no need for operation-intensive \gls{sic} at the receiver.
	% To accommodate backscatter characteristics and reduce decoding complexity, we consider a joint semi-coherent detection for all Metascatters over accumulated energy $z$.

	% Moreover, we consider a specific scenario where a multi-antenna \gls{ap} serves a single-antenna user surrounded by multiple Metascatters.
	% For simplicity, it is assumed the user first jointly decodes all backscatter messages from accumulated energy, then models reflection patterns and backscatter paths within equivalent channel for primary decoding.
	% % Once modulation uncertainty of Metascatters are eliminated, models contributions from additional paths within equivalent channel
	% % decodes all Metascatters jointly by energy detection, then models their contribution within equivalent channel and decodes the primary link.
	% % For simplicity, the user is assumed first decodes all Metascatters jointly by energy detection, then models their contribution within equivalent channel and decodes the primary link.
	% We characterize the achievable primary-(total-)backscatter rate region by optimizing the input distribution at Metascatters, the active beamforming at the AP, and the decision regions at the user.
	% % A suboptimal \gls{bcd} algorithm was proposed, where the input distribution satisfying the \gls{kkt} conditions is evaluated in closed form, the transmit beamforming is optimized by \gls{pgd}, and the decision thresholds are optimized by \gls{dp}.
	% % A suboptimal \gls{bcd} algorithm is proposed, where the \gls{kkt} input distribution is numerically evaluated in closed form, the active beamforming is iteratively updated by \gls{pgd}, and the decision regions are restricted to convex and opty
	% % We then propose a suboptimal \gls{bcd} algorithm that numerically evaluates the \gls{kkt} input distribution in closed form, iteratively updates the active beamforming by \gls{pgd}, and employs existing thresholding schemes to refine suboptimal convex decision regions.
	% A suboptimal \gls{bcd} algorithm is proposed, which numerically evaluates the \gls{kkt} input distribution in closed form, iteratively updates the active beamforming by \gls{pgd}, and employs existing thresholding schemes for suboptimal convex decision regions.
	% % A suboptimal \gls{bcd} algorithm was proposed with the \gls{kkt} input distribution evaluated in closed form, the active beamforming updated by \gls{pgd}, and the decision regions restricted to convex then refined by \gls{dp}.
	% % the decision regions are restricted as convex then optimized by \gls{dp}.
	% % A suboptimal \gls{bcd} algorithm was proposed, where the \gls{kkt} input distribution is evaluated in closed form, the active beamforming is optimized by \gls{pgd} with backtracking line search, and the decision thresholds are optimized by \gls{dp}.
	% Simulation results demonstrate Metascatters can exploit additional propagation paths to transmit and assist via adaptive input design.



	% ! Φ(c[n]) vs P
	% In this paper, we argue that to efficiently cope with the high throughput, heterogeneity of quality of service (QoS), and massive connectivity requirements of future multi-antenna wireless networks, multiple access design needs to depart from those two extreme interference management strategies, namely fully treat interference as noise (as in SDMA) and fully decode interference (as in NOMA). Considering a multiple-input single-output broadcast channel, we develop a novel multiple access framework, called rate-splitting multiple access (RSMA). RSMA is a more general and more powerful multiple access for downlink multi-antenna systems that contains SDMA and NOMA as special cases. RSMA relies on linearly precoded rate-splitting with SIC to decode part of the interference and treat the remaining part of the interference as noise. This capability of RSMA to partially decode interference and partially treat interference as noise enables to softly bridge the two extremes of fully decoding interference and treating interference as noise and provides room for rate and QoS enhancements and complexity reduction. The three multiple access schemes are compared, and extensive numerical results show that RSMA provides a smooth transition between SDMA and NOMA and outperforms them both in a wide range of network loads (underloaded and overloaded regimes) and user deployments (with a diversity of channel directions, channel strengths, and qualities of channel state information at the transmitter). Moreover, RSMA provides rate and QoS enhancements over NOMA at a lower computational complexity for the transmit scheduler and the receivers (number of SIC layers).


	% We uniquely introduce \emph{Metascatter} that adapts the input distribution of a finite-state passive backscatter node based on \gls{csi}, to \emph{simultaneously} encode self message and assist legacy transmission while powered by surrounding waves.
	% % Compared to conventional \gls{ris}-empowered \gls{sr} that encodes and precodes independently (e.g., overlay or parallel), Metascatter refines backscatter principles to bridge parasitic source of \gls{sr} and reflecting element of \gls{ris} as extreme cases.
	% Compared to existing \gls{ris}-empowered \gls{sr} that encodes and precodes independently using advanced architecture (e.g., overlay or parallel), Metascatter softly bridges and generalizes parasitic source of \gls{sr} and reflecting element of \gls{ris} via smart input design.
	% % Compared to \gls{ris}-empowered \gls{sr} that encodes and precodes independently (e.g., overlay or parallel), Metascatter refines backscatter principles to bridge parasitic source of \gls{sr} and reflecting element of \gls{ris} as extreme cases.
	% % Such an integrated distribution design not only yields universal modularity with reduced optimization cost, but also enables a flexible tradeoff between primary and backscatter links using shared spectrum, energy, and infrastructures.
	% This not only reduces hardware complexity and optimization cost, but also enables a flexible tradeoff between primary (legacy) and backscatter links using shared spectrum, energy, and infrastructures.
	% Moreover, we consider a specific scenario where a multi-antenna \gls{ap} serves a single-antenna user surrounded by multiple Metascatters.
	% For simplicity, it is assumed the user first jointly decodes all backscatter messages from accumulated energy, then models reflection patterns and backscatter paths within equivalent channel for primary decoding.
	% % Once modulation uncertainty of Metascatters are eliminated, models contributions from additional paths within equivalent channel
	% % decodes all Metascatters jointly by energy detection, then models their contribution within equivalent channel and decodes the primary link.
	% % For simplicity, the user is assumed first decodes all Metascatters jointly by energy detection, then models their contribution within equivalent channel and decodes the primary link.
	% We characterize the achievable primary-(total-)backscatter rate region by optimizing the input distribution at Metascatters, the active beamforming at the AP, and the decision regions at the user.
	% % A suboptimal \gls{bcd} algorithm was proposed, where the input distribution satisfying the \gls{kkt} conditions is evaluated in closed form, the transmit beamforming is optimized by \gls{pgd}, and the decision thresholds are optimized by \gls{dp}.
	% % A suboptimal \gls{bcd} algorithm is proposed, where the \gls{kkt} input distribution is numerically evaluated in closed form, the active beamforming is iteratively updated by \gls{pgd}, and the decision regions are restricted to convex and opty
	% % We then propose a suboptimal \gls{bcd} algorithm that numerically evaluates the \gls{kkt} input distribution in closed form, iteratively updates the active beamforming by \gls{pgd}, and employs existing thresholding schemes to refine suboptimal convex decision regions.
	% A suboptimal \gls{bcd} algorithm is proposed, which numerically evaluates the \gls{kkt} input distribution in closed form, iteratively updates the active beamforming by \gls{pgd}, and employs existing thresholding schemes for suboptimal convex decision regions.
	% % A suboptimal \gls{bcd} algorithm was proposed with the \gls{kkt} input distribution evaluated in closed form, the active beamforming updated by \gls{pgd}, and the decision regions restricted to convex then refined by \gls{dp}.
	% % the decision regions are restricted as convex then optimized by \gls{dp}.
	% % A suboptimal \gls{bcd} algorithm was proposed, where the \gls{kkt} input distribution is evaluated in closed form, the active beamforming is optimized by \gls{pgd} with backtracking line search, and the decision thresholds are optimized by \gls{dp}.
	% Simulation results demonstrate Metascatters can exploit additional propagation paths to transmit and assist via adaptive input design.

	% Symbiotic radio has emerged as a promising technology for spectrum- and energy-efficient wireless communications, where the passive secondary backscatter devices (BDs) reuse not only the spectrum but also the power of the active primary users to transmit their own information. In return, the primary communication links can be enhanced by the additional multipaths created by the BDs. This is known as the mutualism relationship of symbiotic radio.

	% Symbiotic radio has emerged as a new paradigm to achieve both spectrum-efficient and energy-efficient wireless communications, for which the secondary user modulates its information over the radio frequency (RF) signals received from primary transmitter (PT) [1]–[3]. As such, the secondary backscatter device (BD) in symbiotic radio systems leverages not only the spectrum as in the extensively studied cognitive radio systems [4]–[6], but also the energy of the primary signals via passive backscattering technology for its own information transmission

	% Specifically, the passive secondary backscatter device (BD) in symbiotic radio systems reuses not only the spectrum of the active primary communication as in traditional CR systems, but also its power via passive backscattering technology [25].

	% Recently, mutualistic spectrum sharing has been observed in cognitive backscatter communication (CBC) systems [5], in which the active transmission achieves multipath diversity with the help of the backscatter transmission, while the backscatter device gains the transmission opportunity using the RF source and radio spectrum of the active transmission. Such mutualism advocates the coexistence of cellular and Internet-of-Things (IoT) networks in the same spectrum [6].

	% To be specific, there are two types of transmissions in SR: the primary transmission and the secondary transmission. In the primary transmission, a primary transmitter (PTx) transmits messages to its receiver by using the traditional active radio technology, while in the secondary transmission, a secondary transmitter (STx), operating as a passive device, pe- riodically switches its load impedance to change the amplitude and/or phase of its backscattered signal, thereby modulating its information bits over a signal received from PTx [6]. The receiver in SR receives two types of signals: a direct link signal from PTx and a backscatter link signal from STx. Due to the use of backscatter, the backscatter link signal contains information from both PTx and STx. When the secondary transmission rate is much lower than the primary transmission rate, the backscatter link can be seen as an additional path for the primary transmission with a slow channel variation introduced by the changing of load impedance at STx. In this case, the secondary system obtains the transmission op- portunity without requiring additional spectrum and power- consuming active components, and in return the secondary transmission provides multipath gain instead of interference to the primary transmission, thereby yielding mutual benefits.

	% opportunistically
	% \gls{sr} introduces scatter nodes modulate over active legacy transmission

	% \gls{sr} incorporates scatter nodes into active wireless systems to transmit over sh
	% \gls{sr} incorporates scatter nodes into active wireless systems to operate over recycled radio wave and transmit self information and enhance legacy multipath to the cooperative receiver.
	% In \gls{sr}, the scatter nodes are integrated with existing networks that transmit to legacy receiver

	% the passive secondary backscatter devices (BDs) reuse not only the spectrum but also the power of the active primary users to transmit their own information. In return, the primary communication links can be enhanced by the additional multipaths created by the BDs. This is known as the mutualism relationship of symbiotic radio.

	% to transmit to
\end{abstract}

\begin{section}{Introduction}
	\IEEEPARstart{B}{ackscatter} is recently re-innovated as a promising approach to support low-power communications and control wireless propagation environments.
	% \IEEEPARstart{B}{ackscatter} is re-innovated to support low-power communications and control wireless propagation environments.
	% \IEEEPARstart{B}{ackscatter} allows wireless nodes to recycle existing .
	% \IEEEPARstart{B}{ackscatter} allows wireless nodes to communicate without generating carrier.
	% The concept of \gls{ambc} was first proposed in \cite{Liu2013b}, where battery-free communication between passive nodes was established by
	\gls{ambc} that enables battery-free communication between interactive nodes was first introduced and prototyped in \cite{Liu2013b}, where devices harvest energy from and modulate information over ambient \gls{rf} signals by switching between reflecting and absorbing states.
	To combat the strong direct-link interference of \gls{ambc}, \cite{Yang2018d} exploited the repeating structure of \gls{ofdm} symbol and proposed a multi-antenna detector that only requires the backscatter channel strength.
	% with periodical change of states.
	% each tag harvests energy from and modulates information over ambient \gls{rf} signals by periodically switching between different reflection patterns.
	% It enables battery-free communication between fully passive nodes, but the backscatter signal strength can be relatively weak and the decoding is subject to strong direct-link interference.
	% To solve this, \cite{Yang2018d} exploited the repeating structure of \gls{ofdm} symbol for interference cancellation based on backscatter channel strength.
	% Using co-located receiver to decode
	Cooperative \gls{ambc} that decodes primary and backscatter links using co-located receiver was proposed in \cite{Yang2018}, where the authors evaluated the error performance of \gls{ml}, linear, and \gls{sic} detectors for flat fading channels and proposed a low-complexity \gls{ml} detector for frequency-selective fading channels.
	The concept was then generalized to \gls{sr} in \cite{Liang2020} to ``exploit the benefits and address the drawbacks'' of \gls{cr} and \gls{ambc}.
	% The concept of \gls{sr} was then proposed in \cite{Liang2020} to exploit
	% symbiotic radio (SR), is proposed to ex- ploit the benefits and address the drawbacks of cognitive radio (CR) and ambient backscattering communications (AmBC)
	% When transmit cooperation is also available, cooperative \gls{ambc} is also termed as \gls{sr} \cite{Liang2020}.
	The authors of \cite{Guo2019b} classified \gls{sr} into commensal, parasitic, and competitive types based on link priority, and derived their instantaneous rates and optimal power allocations.
	The corresponding outage probabilities were also studied in \cite{Ding2020}.
	Besides, \cite{Long2020a} concluded that if the backscatter symbol period is sufficiently long, then the non-coherent primary rate would approach its coherent counterpart.
	The authors thus proposed to decode the primary link under backscatter uncertainty, then perform \gls{sic} and decode the backscatter link.
	% The authors also considered the transmit precoder design for weighted total-rate maximization and transmit power minimization problems.
	% \cite{Zhou2019a} explored how the number of transmit antennas, receive antennas, and symbol period ratio asymptotically influence the ergodic rate of primary and backscatter links.
	% For \gls{sr} with a single-antenna backscatter node,
	\cite{Zhou2019a} also explored the asymptotic impact of transmit/receive antenna and backscatter symbol period on the ergodic rate of primary and backscatter links.
	% When multi-antenna is available at the node, \cite{Wu2021a} proposed
	For a \gls{mimo} \gls{sr} system with a multi-antenna backscatter node, \cite{Wu2021a} proposed a beamforming design to maximize the backscatter rate while guaranteeing the primary performance.
	% For multi-antenna at all ends, \cite{Wu2021a} optimized transmit beamforming to maximize the backscatter achievable rate under primary rate constraint.
	% For multi-antenna at all ends, \cite{Wu2021a} optimized transmit beamforming to maximize the backscatter achievable rate under primary rate constraint.
	% For multi-antenna at all ends, \cite{Wu2021a} optimized transmit beamforming to enlarge the achievable rate region.
	However, those paper only considered one backscatter node and backscatter multiple access remains an open issue.
	In \cite{Xu2021a}, a \gls{noma}-based \gls{sr} was proposed and receive combining was investigated when \gls{sic} order follows equivalent channel strength.
	% \cite{Xu2021a} proposed a \gls{noma}-based \gls{sr} and investigated receive beamforming when \gls{sic} order is determined by equivalent channel strength.
	% \cite{Xu2021a} proposed a \gls{noma}-based \gls{sr} and studied the receive combiner design when the receiver decodes in the order of equivalent channel strength.
	% A \gls{tdma}-based \gls{sr} with energy harvesting constraints was also presented in \cite{Yang2021a}, and energy efficiency maximization was considered with respect to transmit power, reflection efficiency, and time allocation design.
	A \gls{tdma}-based \gls{sr} with energy harvesting constraints was also presented in \cite{Yang2021a}, where transmit power, reflection efficiency, and time allocation were jointly optimized to maximize energy efficiency.
	% In \cite{Han2021}, random code-assisted backscatter multiple access was combined with \gls{sr}, and the authors evaluated the asymptotic \gls{sinr} performance using random matrix theory.
	To reduce coordination between passive nodes, \cite{Han2021} proposed a random code-assisted multiple access for \gls{sr} and evaluated the asymptotic \gls{sinr} using random matrix theory.

	% On the other hand, \gls{ris} has recently emerged as a promising technique to enhance the energy efficiency.
	% In practice, an \gls{ris} consists of multiple individual sub-wavelength reflecting elements to adjust the amplitude and phase of the incoming signal (i.e., passive beamforming).
	% Different from relay, backscatter and frequency-selective surface \cite{Anwar2018}, \gls{ris} assists the primary transmission using passive components with much lower energy consumption and thermal noise, but is limited to frequency-dependent reflection.
	% On the other hand, \gls{ris} consists of numerous sub-wavelength passive elements that alter propagation environment using adaptive backscatter pattern to assist existing networks. Extensive research has been devoted to optimizing the reflection coefficient
	% On the other hand, \gls{ris} consists of numerous sub-wavelength passive elements with adaptive amplitudes and/or phases that alter propagation environment to assist existing networks.
	On the other hand, \gls{ris} alters propagation environment for legacy networks using numerous sub-wavelength passive elements with adaptive amplitudes and/or phases.
	Extensive research has been devoted to optimizing the phase shifts for the whole channel block to improve communication, sensing, and power performances \cite{Wu2018,Zhang2019a,Lin2022,Liu2022,Feng2022,Zhao2022}.
	% In contrast, dynamic passive beamforming that adjusts \gls{ris} within channel block was proposed in \cite{Yang2020} to create diversity for \gls{ofdm} systems.
	% In contrast, dynamic passive beamforming that adjusts \gls{ris} over finer time slots was proposed in \cite{Yang2020} to create diversity for \gls{ofdm} systems.
	Besides, \cite{Yang2020} proposed a dynamic passive beamforming that further adjusts \gls{ris} over fine-grained time slots for \gls{ofdm} systems to balance beamforming gain and multiuser diversity.
	The idea was further applied to \gls{wpcn} to accommodate the downlink \gls{wpt} phase and uplink \gls{wit} phase of the ``harvest-then-transmit'' protocol \cite{Wu2021d,Hua2022a}.
	% For multiuser \gls{wpt}, \cite{Qiu2022} also reported that despite \gls{ris} is restricted to single-beam reflection, dynamic beamforming can mimic multi-beam reflection in a time-division manner and reduce the phase extraction loss.
	For multiuser \gls{wpt}, \cite{Qiu2022} also reported that dynamic beamforming can mimic multi-beam reflection in a time-division manner and reduce the phase extraction loss.
	% However, dynamic passive beamforming demands additional computational complexity and control overhead, and the performance-cost tradeoff needs reconsideration especially when the number of \gls{ris} elements is large.
	% Although dynamic passive beamforming can artificially create time-varying channels for flexible channel reconfiguration and resource allocation, it demands additional computational complexity and control overhead, and the performance-cost tradeoff deserves further attention.
	% Although dynamic passive beamforming can artificially introduce temporal diversity for flexible channel reconfiguration and resource allocation, it demands additional computational complexity and control overhead, and the performance-cost tradeoff deserves further attention.
	Although dynamic passive beamforming artificially creates temporal diversity for flexible channel reconfiguration and resource allocation, it demands additional computational cost and control overhead, and the tradeoff deserves further attention especially for large \gls{ris}.
	In \cite{Chen2021,Zhang2021d}, \gls{ris} was also introduced to single- and multi-node \gls{sr} systems to reduce the total transmit power.
	When joint transmitter-\gls{ris} encoding is possible, \cite{Karasik2019} proved using \gls{ris} only for passive beamforming is generally suboptimal in terms of achievable rate for finite input constellations.
	% The capacity-achieving \gls{ris} strategy was found to
	Recently, \gls{ris}-empowered \gls{sr} was introduced in \cite{Xu2020b,Hua2022,Hu2021a} where independent passive beamforming and backscatter encoding were combined using advanced architectures.
	The authors of \cite{Xu2020b,Hua2022} proposed the \gls{ris} to modulate binary message over the whole phase shift matrix and the receiver to decodes from (non-coherent) primary to (coherent) backscatter link.
	In contrast, \cite{Hu2021a} divided the \gls{ris} into reflection and information elements, and evaluated the error performance of non-coherent backscatter detection.
	% Compared to existing \gls{ris}-empowered \gls{sr} that encodes and precodes independently using advanced architecture (e.g., overlay or parallel), Metascatter softly bridges and generalizes parasitic source of \gls{sr} and reflecting element of \gls{ris} via smart input design.

	To the best of our knowledge, all existing \gls{sr} literatures assumed backscatter modulation employs either Gaussian codebook \cite{Guo2019b,Ding2020,Long2020a,Zhou2019a,Wu2021a,Xu2021a,Yang2021a} or finite equiprobable inputs \cite{Yang2018,Han2021,Zhang2022,Xu2020b,Hua2022,Hu2021a}.
	The former is impractical for passive nodes with constrained number of states, while the latter does not fully exploit \gls{csi} to boost achievable backscatter rate.
	Besides, most relevant designs \cite{Guo2019b,Ding2020,Long2020a,Zhou2019a,Wu2021a,Xu2021a,Yang2021a,Yang2018,Han2021,Zhang2022,Xu2020b,Hua2022} were built over ideal \gls{ml} or \gls{sic} receiver.
	However, the advantage of \gls{sic} is questionable because 1) it requires non-coherent primary encoding at the transmitter and re-encoding, precoding, and subtraction at the receiver, 2) the primary and backscatter symbols are mixed by multiplication instead of superposition, and 3) the backscatter symbol period is typically much longer due to physical constraints.
	% Motivated by above, we propose a novel Metascatter network where multiple battery-free tags ride over a conventional point-to-point system and adapt their input probability distribution to simultaneously act as backscatter tags of \gls{sr} and reflecting elements of \gls{ris}.
	Motivated by those, we propose the concept of Metascatter, which adapts the input distribution of a passive backscatter node to generalize backscatter sources of \gls{sr} and reflecting elements of \gls{ris}.
	% An application scenario was considered where multiple Metascatters are introduced to conventional point-to-point system and adapt their input probability distribution to simultaneously act as backscatter tags of \gls{sr} and reflecting elements of \gls{ris}.
	% An application scenario was considered where multiple Metascatters ride over a point-to-point transmission and simultaneously perform backscatter encoding and passive beamforming.
	% ! An application scenario was considered where multiple Metascatters ride over a point-to-point transmission to simultaneously encode self message and perform passive beamforming.
	% To fully accommodate backscatter characteristics, we also propose a novel receiving strategy that first jointly decodes all Metascatter from accumulated energy, then models their reflection patterns and backscatter paths within equivalent channel for primary decoding.
	% minor modifications on existing receivers, easy to perform, fits backscatter characteristics.
	The contributions of this paper is summarized as follows.

	\emph{First,} Metascatter adapts the input probability distribution of a finite-state passive backscatter device based on primary and (cascaded) backscatter \gls{csi} to unify and generalize parasitic source of \gls{sr} and reflecting elements of \gls{ris}.
	The reflection pattern over time is no longer fully random or deterministic, but can be flexibly distributed to balance backscatter encoding and passive beamforming.
	For single-user scenario, when primary link is absolutely prioritized, the distribution falls on one state and Metascatter boils down to conventional \gls{ris}.
	When only considering backscatter performance, the distribution involves the highest entropy and Metascatter is essentially an \gls{ambc} node.

	\emph{Second,} we consider an application scenario where multiple Metascatters ride over a point-to-point transmission, exploiting additional propagation paths to simultaneously transmit and assist.
	To fully accommodate backscatter characteristics, we also propose a novel receiving strategy that first jointly decodes all Metascatter from accumulated energy, then models their reflection patterns and backscatter paths within equivalent channel for primary decoding.
	Since backscatter message is modulated over primary signal, backscatter decoding is indeed part of primary channel training, and there is no need for operation-intensive \gls{sic} at the receiver.

	% \emph{Second,} we propose a novel receiving strategy where the backscatter symbol of all tags are first recovered by energy-based decoding, then modeled within equivalent \gls{csi} for primary decoding.
	% When the ratio of backscatter symbol period over primary symbol period is large enough, the randomness of primary source can be averaged out and the performance of non-coherent backscatter decoding can be greatly improved.
	% Since the primary and backscatter symbols are mixed by multiplication coding, the backscatter decoding can be viewed as part of primary channel training, which avoids non-coherent encoding at the transmitter and \gls{sic} at the receiver.

	\emph{Third,} we evaluate the achievable primary-(total-)backscatter rate region by optimizing the input distribution at Metascatters, the active beamforming at the \gls{ap}, and the decision regions at the user. Since the original problem is highly non-convex, we consider a suboptimal \gls{bcd} algorithm where the \gls{kkt} input distribution is numerically evaluated by limit of sequences, the active beamforming is iteratively updated by \gls{pgd} accelerated by backtracking line search, and the decision regions are first restricted to convex, then refined by existing thresholding designs.

	% \emph{Third,} we characterize the achievable primary-(total-)backscatter rate region by iteratively optimizing the tag input distribution, the backscatter decision threshold, and the transmit precoder.
	% For the input design, we propose a numerical method to evaluate the \gls{kkt} solutions by limits of sequences.
	% For the threshold design, we derive the minimum number of decision thresholds to maximize the total backscatter rate, and obtain the optimal thresholds by \gls{dp} accelerated by \gls{smawk} algorithm.
	% However, the optimal precoder design can be non-trivial and we may end up with a low-complexity suboptimal solution.

	\emph{Notations:} Scalars, vectors and matrices are respectively denoted by italic, bold lower-case, and bold upper-case letters.
	$j$ represents the imaginary unit.
	% $\boldsymbol{0}$ and $\boldsymbol{1}$ denote respectively zero and one vector or matrix.
	% $\boldsymbol{I}$ represents the identity matrix.
	% $\mathbb{R}_+^{x \times y}$ and $\mathbb{C}^{x \times y}$ denote respectively the space of real nonnegative and complex $x \times y$ matrices.
	$\mathbb{R}_+^{x \times y}$ and $\mathbb{C}^{x \times y}$ respectively denote the space of real nonnegative and complex $x \times y$ matrices.
	$\Delta^n = \left\{ (p_0,\dots,p_n) \in \mathbb{R}_+^{n+1}|\sum_{i=0}^n t_i = 1 \right\}$ denotes the standard $n$-simplex.
	% $\Re\{\cdot\}$ retrieves the real part of a complex entity. $[\cdot]_{(n)}$ denotes the $n$-th entry of a vector and $[\cdot]_{(1:n)}$ denotes the first $n$ entries of a vector.
	$(\cdot)^*$, $(\cdot)^T$, $(\cdot)^H$, $(\cdot)^+$, $\lvert{\cdot}\rvert$, $\lVert{\cdot}\rVert$ respectively represent the conjugate, transpose, conjugate transpose, ramp function, absolute value, and Euclidean norm.
	% $\arg(\cdot)$, $\mathrm{rank}(\cdot)$, $\mathrm{tr}(\cdot)$, $\mathrm{diag}(\cdot)$ and $\mathrm{diag}^{-1}(\cdot)$ respectively denote the argument, rank, trace, a square matrix with input vector on the main diagonal, and a vector retrieving the main diagonal of the input matrix.
	% $\odot$ denotes the Hadamard product.
	% $\boldsymbol{S} \succeq \boldsymbol{0}$ means $\boldsymbol{S}$ is positive semi-definite.
	% $\mathbb{A}\{\cdot\}$ extracts the DC component of a signal.
	% $\mathbb{E}_X\{\cdot\}$ takes expectation w.r.t. random variable $X$ ($X$ is omitted for simplicity).
	The distribution of a CSCG random vector with mean $\boldsymbol{0}$ and covariance $\boldsymbol{\Sigma}$ is denoted by $\mathcal{CN}(\boldsymbol{0},\boldsymbol{\Sigma})$.
	$\sim$ means ``distributed as''.
	$(\cdot)^{(i)}$ represents the $i$-th iterated value and $(\cdot)^{\star}$ represents the end solution.
\end{section}

\begin{section}{Backscatter Principles}
	% \begin{figure}[!t]
	% 	\centering
	% 	\subfloat[Block Diagram]{
	% 		\resizebox{0.8\columnwidth}{!}{
	% 			\input{assets/illustration/block_diagram.tex}
	% 		}
	% 		\label{fi:block_diagram}
	% 	}
	% 	\\
	% 	\subfloat[Equivalent Circuit]{
	% 		\resizebox{0.95\columnwidth}{!}{
	% 			\input{assets/illustration/equivalent_circuit.tex}
	% 		}
	% 		\label{fi:equivalent_circuit}
	% 	}
	% 	\\
	% 	\subfloat[Scatter Model]{
	% 		\resizebox{0.8\columnwidth}{!}{
	% 			\input{assets/illustration/scatter_model.tex}
	% 		}
	% 		\label{fi:scatter_model}
	% 	}
	% 	\caption{Block diagram, equivalent circuit, and scatter model of a typical passive tag. The solid and dashed vectors represent signal and energy flows. The backscatter antenna behaves as a constant power source, where the voltage $V_0$ and current $I_0$ are introduced by incident electric field $\vec{E}_{\mathrm{I}}$ and magnetic field $\vec{H}_{\mathrm{I}}$ \cite{Huang2021}.}
	% \end{figure}

	\begin{figure*}[!t]
		\centering
		\subfloat[Block Diagram]{
			\resizebox{0.32\linewidth}{!}{
				\input{assets/illustration/block_diagram.tex}
			}
			\label{fi:block_diagram}
		}
		\subfloat[Equivalent Circuit]{
			\resizebox{0.37\linewidth}{!}{
				\input{assets/illustration/equivalent_circuit.tex}
			}
			\label{fi:equivalent_circuit}
		}
		\subfloat[Scatter Model]{
			\resizebox{0.28\linewidth}{!}{
				\input{assets/illustration/scatter_model.tex}
			}
			\label{fi:scatter_model}
		}
		\caption{Block diagram, equivalent circuit, and scatter model of a passive backscatter node. The solid and dashed vectors represent signal and energy flows. The backscatter antenna behaves as a constant power source, where the voltage $V_0$ and current $I_0$ are introduced by incident electric field $\vec{E}_{\mathrm{I}}$ and magnetic field $\vec{H}_{\mathrm{I}}$ \cite{Huang2021}.}
	\end{figure*}

	Passive backscatter nodes harvest energy from and modulate information over surrounding \gls{rf} signals.
	As shown in Fig. \subref*{fi:block_diagram}, a typical passive node consists of a scattering antenna, an energy harvester, an integrated receiver, a load-switching modulator, and on-chip components (e.g., micro-controller and sensors) \cite{Dobkin2012}.
	Its equivalent circuit is presented in Fig. \subref*{fi:equivalent_circuit}.
	% When illuminated, the node absorbs a portion of the impinging wave for information decoding and energy harvesting \cite{Kim2021a}, while scatters the remaining back to the space. The scattered signal is further decomposed into the \emph{structural} component that consistently contributes to environment multipath and covered by channel estimation \cite{Boyer2014}, and the
	When illuminated, the node absorbs a portion of the impinging wave for information decoding and/or energy harvesting \cite{Kim2021a}, and backscatters the remaining as \emph{structural} and \emph{antenna} components.
	% The scattered signal is further decomposed into the \emph{structural} component that consistently contributes to environment multipath and covered by channel estimation \cite{Boyer2014}, and the \emph{antenna} mode component that
	% and \emph{antenna} mode components \cite{Hansen1989}.
	The former consistently contributes to environment multipath and can be modelled by channel estimation \cite{Boyer2014}, while the latter depends on antenna-load impedance mismatch and can be used for backscatter modulation \cite{Boyer2012} and/or channel reconfiguration \cite{Wu2021b}.
	% Depending on structure, shape and material of general objects, structural scattering consistently contributes to environment multipath and is covered by channel estimation \cite{Boyer2014}.
	% In contrast, antenna scattering models radiation pattern from antenna-load impedance mismatch and can be used for backscatter modulation \cite{Boyer2012} and/or channel reconfiguration \cite{Wu2021b}.
	Fig. \subref*{fi:scatter_model} illustrates the scatter model of a node with $M$ states, where the reflection coefficient of state $m \in \mathcal{M} \triangleq \{1,\ldots,M\}$ is defined as%
	\footnote{It corresponds to a linear backscatter model where the reflection coefficient is irrelevant to incident electromagnetic field strength.}
	\begin{equation}
		\Gamma_m = \frac{Z_m - Z_{\mathrm{A}}^*}{Z_m + Z_{\mathrm{A}}},
		\label{eq:reflection_coefficient}
	\end{equation}
	where $Z_m$ is the load impedance at state $m$ and $Z_{\mathrm{A}}$ is the antenna input impedance.

	\begin{subsection}{SR: Backscatter Modulation}
		% Backscatter sources encode self message by \emph{randomly changing reflection states.} For $M$-ary \gls{qam}, reflection coefficient $\Gamma_m$ maps to the corresponding complex constellation point $c_m$ by \cite{Thomas2012a}
		Backscatter sources encode self message by \emph{random reflection states variation.} For $M$-ary \gls{qam}, reflection coefficient $\Gamma_m$ maps to the corresponding \emph{complex constellation point $c_m$} by \cite{Thomas2012a}
		\begin{equation}
			\Gamma_m = \alpha \frac{c_m}{\max_{m'} \lvert c_{m'} \rvert},
			\label{eq:backscatter_modulation}
		\end{equation}
		where $0 \le \alpha \le 1$ is the amplitude reflect ratio that controls the harvest-scatter tradeoff at the direction of interest.
		% When the \gls{csi} and reflection alphabet $\{\Gamma_1,\ldots,\Gamma_M\}$ are available at the reader, it can decode the tag message from the observed scattered signal.
		% ! Use larger alpha in simulation: for high-order QAM, some constellation point may harvests more power than others

	\end{subsection}

	\begin{subsection}{IRS: Channel Reconfiguration}
		% \gls{ris} elements assist legacy transmission by \emph{deterministically choosing phase shifts} based on relevant \gls{csi}. For a reflecting element with $M$ candidate states, reflection coefficient $\Gamma_m$ maps to the corresponding phase shift $\theta_m$ by \cite{Wu2018}
		\gls{ris} elements assist legacy transmission by \emph{deterministic phase shifts selection} based on relevant \gls{csi}.
		For a reflecting element with $M$ candidate states, reflection coefficient $\Gamma_m$ relates to the corresponding \emph{phase shift $\theta_m$} by \cite{Wu2018}
		\begin{equation}
			\Gamma_m = \beta_m \exp(j \theta_m),
		\end{equation}
		where $0 \le \beta_m \le 1$ is overall amplitude reflect ratio of state $m$.
		% Based on relevant \gls{csi}
	\end{subsection}
	% Tags periodically switch between different states to perform backscatter modulation.
	% For $M$-ary \gls{qam}, the complex constellation point $c_m \in \mathcal{C}$ maps to the reflection coefficient by \cite{Thomas2012a}
	% \begin{equation}
	% 	\Gamma_m = \alpha \frac{c_m}{\max_{m'} \lvert c_{m'} \rvert},
	% 	\label{eq:backscatter_modulation}
	% \end{equation}
	% where $\alpha \in [0,1]$ models the harvest-backscatter ratio at the direction of interest.
	% For passive tags, $\alpha \ll 1$ is commonly assumed as the majority of the incident wave can be harvested to support tag modules \cite{Thomas2012a}.

	\begin{subsection}{Metascatter: Bridge and Generalization}
		\begin{figure}[!t]
			\centering
			\subfloat[Input Distribution]{
				\resizebox{0.8\columnwidth}{!}{
					\input{assets/illustration/input_distribution.tex}
				}
			}
			\\
			\subfloat[Time Block]{
				\resizebox{0.8\columnwidth}{!}{
					\input{assets/illustration/time_block.tex}
				}
			}
			\caption{
				Input probability distribution and time block structure of \gls{sr}, \gls{ris}, and Metascatter.
				$T_s$ and $T_c$ respectively denote the primary and backscatter symbol period.
				Within channel coherence time, Metascatter semi-randomly selects reflection state for each backscatter block, with guidance from input probability distribution.
			}
			\label{fi:metascatter}
		\end{figure}
		% For a passive node with finite states, is it possible to unify backscatter modulation and channel reconfiguration by proper selection of reflection coefficient?
		Metascatters simultaneously transmit and assist by \emph{adaptive input distribution design} based on primary and (cascaded) backscatter \gls{csi}.
		% The reflection pattern is neither fully random nor fully deterministic, but flexibly distributed to balance backscatter encoding and passive beamforming.
		% Instead of using fully random or deterministic reflection pattern over time, as shown in Fig. \ref{fi:metascatter}, Metascatter flexibly controls input distribution of candidate reflection states to balance backscatter encoding and passive beamforming.
		% Instead of using fully random or deterministic reflection pattern over time, as shown in Fig. \ref{fi:metascatter}, Metascatter semi-randomly selects reflection state for each backscatter block with guidance from \emph{input probability distribution $P(\Gamma_m)$.}
		% Instead of using fully random or deterministic reflection pattern over time, as shown in Fig. \ref{fi:metascatter}, Metascatter semi-randomly selects reflection state for each backscatter block, with guidance from \emph{input probability distribution $P(\Gamma_m)$.} In other words, it flexibly controls input distribution of candidate reflection states to balance backscatter encoding and passive beamforming. \gls{sr} and \gls{ris} can be regarded as extreme cases of Metascatter, where node input distribution boils down to uniform and deterministically biased, respectively.
		Instead of using fully random or deterministic reflection pattern over time, as shown in Fig. \ref{fi:metascatter}, Metascatter semi-randomly selects reflection state for each backscatter block, with \emph{guidance of input probability $P(\Gamma_m)$} for state $m$. In other words, it flexibly controls input distribution of candidate reflection states to balance backscatter encoding and passive beamforming. \gls{sr} and \gls{ris} can be regarded as extreme cases of Metascatter, where node input distribution boils down to uniform and deterministic, respectively.
		% flexibly controls input distribution of candidate reflection states to balance backscatter encoding and passive beamforming.
		% Metascatter semi-randomly selects reflection state for each backscatter block, with guidance from \emph{input probability distribution $P(\Gamma_m)$.}
		% % Based on \gls{csi}, Metascatter adapts the reflection state distribution to unify data transmission and channel reconfiguration.
		% \gls{sr} and \gls{ris} can be regarded as its extreme cases, where node input distribution boils down to uniform and deterministically biased, respectively.
		% Within channel coherence time, Metascatter semi-randomly selects reflection state for each backscatter block, with guidance from \emph{input probability distribution $P(\Gamma_m)$.}
		\begin{remark}
			Compared to conventional \gls{ris} literatures that optimize phase shifts under unit-module constraint, Metascatter starts from predefined reflection coefficients and designs their input distribution under sum-probability constraint to achieve flexible primary-backscatter tradeoff.
		\end{remark}
		% Next, we will discuss the input design in a Metascatter-enabled network.
		% consider a Metascatter-aided system to evaluate
	\end{subsection}
\end{section}

\begin{section}{Metascatter-Enabled Network}
	\begin{subsection}{System Model}
		\begin{figure}[!t]
			\centering
			\def\svgwidth{0.8\columnwidth}
			\footnotesize{
				\import{assets/illustration/}{metascatter_network.eps_tex}
			}
			\caption{A Metascatter-enabled single-user multi-node network.}
			\label{fi:metascatter_network}
		\end{figure}
		% As shown in Fig. \ref{fi:metascatter_network}, we propose a Metascatter-enabled single-user multi-node network where the spectrum, energy and infrastructures are shared by two coexisting systems.
		As shown in Fig. \ref{fi:metascatter_network}, we propose a Metascatter-enabled single-user multi-node network where two coexisting systems share spectrum, energy and infrastructures.
		% In the primary point-to-point system, the \gls{ap} transmits information to the single-antenna user.
		% In the primary point-to-point system, a $Q$-antenna \gls{ap} transmit to a single-antenna user while assisted by $K$ nearby single-antenna Metascatters.
		The primary point-to-point transmission from a $Q$-antenna \gls{ap} to a single-antenna user is assisted by $K$ nearby single-antenna Metascatters.
		In the secondary backscatter \gls{mac} system, the \gls{ap} serves as the carrier emitter, $K$ nearby single-antenna Metascatters modulate information over reradiated \gls{rf} signals, and the user decodes their messages.
		For simplicity, we consider a quasi-static block fading model where channels remain constant within coherence interval while vary independently between consecutive blocks.
		% Since backscatter modulation involves load switching, tags typically transmit at much lower rate, and we assume the backscatter symbol period is $N \in \mathbb{Z}_{++}$ times the primary symbol period.
		Due to physical constraints on load switching, we assume the backscatter symbol period is $N \gg 1$ times longer than primary and consider integer $N$ without loss of generality.
		We also assume the direct channel and all cascaded channels can be estimated and fed back to the \gls{ap}.%
		\footnote{
			Due to the lack of \gls{rf} chains at the passive tag, accurate and efficient \gls{csi} acquisition at the \gls{ap} can be challenging.
			One possibility is the \gls{ap} sends training pilots, the tags respond in predefined manners, and the user performs least-square estimation with feedbacks \cite{Bharadia2015,Yang2015b,Guo2019g}.
		}
		Besides, we omit the signal reflected by two or more times\cite{Wu2019} and ignore the time difference of arrival from different paths\cite{Guo2019b}.


		Denote the \gls{ap}-user direct channel as $\boldsymbol{h}_{\mathrm{D}}^H \in \mathbb{C}^{1 \times Q}$, the \gls{ap}-node $k \in \mathcal{K} \triangleq \{1,\ldots,K\}$ forward channel as $\boldsymbol{h}_{\mathrm{F},k}^H \in \mathbb{C}^{1 \times Q}$, and the node $k$-user backward channel as $h_{\mathrm{B},k}$. Also, define the cascaded channel of tag $k$ as $\boldsymbol{h}_{\mathrm{C},k}^H \triangleq h_{\mathrm{B},k} \boldsymbol{h}_{\mathrm{F},k}^H \in \mathbb{C}^{1 \times Q}$, and $\boldsymbol{H}_{\mathrm{C}} \triangleq [\boldsymbol{h}_{\mathrm{C},1},\ldots,\boldsymbol{h}_{\mathrm{C},K}]^H \in \mathbb{C}^{K \times Q}$.
		% Let $x_{\mathcal{K}} \triangleq \{x_k : k \in \mathcal{K}\}$ be the backscatter symbols of all Metascatters.
		Let $x_{\mathcal{K}} \triangleq (x_1,\ldots,x_K)$ be the backscatter symbol tuple of all Metascatters.
		Consider the signal model during one backscatter block (i.e., $N$ primary blocks).
		% We assume the primary symbol follows standard \gls{cscg} distribution and the backscatter symbol of all tags employs $M$-\gls{qam}.
		Under perfect synchronization, the equivalent primary channel is a function of \emph{coded} backscatter symbols
		\begin{subequations}
			\label{eq:equivalent_channel}
			\begin{align}
				\boldsymbol{h}_{\mathrm{E}}^H(x_{\mathcal{K}})
				 & \triangleq \boldsymbol{h}_{\mathrm{D}}^H + \sum_{k \in \mathcal{K}} \alpha_k \boldsymbol{h}_{\mathrm{C},k}^H x_k   \\
				 & = \boldsymbol{h}_{\mathrm{D}}^H + \boldsymbol{x}^H \mathrm{diag}(\boldsymbol{\alpha}) \boldsymbol{H}_{\mathrm{C}},
			\end{align}
		\end{subequations}
		where $\alpha_k$ is the amplitude reflect ratio of Metascatter $k$, $\boldsymbol{\alpha} \triangleq [\alpha_1,\ldots,\alpha_K]^T \in \mathbb{R}_+^{K \times 1}$, $x_k \in \mathcal{X} \triangleq \{c_1,\ldots,c_M\}$ is the coded backscatter symbol of Metascatter $k$, and $\boldsymbol{x} \triangleq [x_1,\ldots,x_K]^H \in \mathbb{C}^{K \times 1}$. The signal received by the user at primary block $n \in \mathcal{N} \triangleq \{1,\ldots,N\}$ is
		\begin{equation}
			y[n] = \boldsymbol{h}_{\mathrm{E}}^H(x_{\mathcal{K}}) \boldsymbol{w} s[n] + v[n],
		\end{equation}
		where $s \sim \mathcal{CN}(0,1)$ is the primary symbol, $v \sim \mathcal{CN}(0,\sigma_v^2)$ is the \gls{awgn}, and $\boldsymbol{w} \in \mathbb{C}^{Q \times 1}$ is the active beamforming vector with average power constraint $\lVert \boldsymbol{w} \rVert^2 \le P$.
		% The equivalent channel for primary link is subject to backscatter uncertainty
		% The equivalent primary channel is a function of backscatter symbols  as
		% \begin{equation}
		% 	% \boldsymbol{h}_{\mathrm{E}}^H(x_{\mathcal{K}}) \triangleq \boldsymbol{h}_{\mathrm{D}}^H + \sum_{k \in \mathcal{K}} \sqrt{\alpha_k} \boldsymbol{h}_{\mathrm{C},k}^H x_k.
		% 	\boldsymbol{h}_{\mathrm{E}}^H(\boldsymbol{x}) \triangleq \boldsymbol{h}_{\mathrm{D}}^H + \boldsymbol{x}^H \mathrm{diag}(\boldsymbol{\alpha}) \boldsymbol{H}_{\mathrm{C}}.
		% 	\label{eq:equivalent_channel}
		% \end{equation}

		% where $\alpha_k$ and $x_k$ denote respectively the harvest-backscatter efficiency and backscatter symbol of tag $k$, $s[n]$ and $w[n] \sim \mathcal{CN}(0,\sigma_v^2)$ denote respectively the primary symbol and \gls{awgn} at block $n$, and $\boldsymbol{w} \in \mathbb{C}^{Q \times 1}$ is the transmit precoder satisfying power constraint $\lVert \boldsymbol{w} \rVert^2 \le P$.
		% For the ease of notation, we define $x_{\mathcal{K}} \triangleq \{x_k : k \in \mathcal{K}\}$ as the tag input combination, and $\boldsymbol{y} \triangleq \left[y[1],\ldots,y[N]\right]^T \in \mathbb{C}^{N \times 1}$ as the received signal per backscatter symbol period.
		% For primary transmission, the equivalent channel is subject to backscatter modulation uncertainty as
		% \begin{equation}
		% 	\boldsymbol{h}_{\mathrm{E}}^H(x_{\mathcal{K}}) \triangleq \boldsymbol{h}_{\mathrm{D}}^H + \sum_{k \in \mathcal{K}} \sqrt{\alpha_k} \boldsymbol{h}_{\mathrm{C},k}^H x_k.
		% 	\label{eq:equivalent_channel}
		% \end{equation}

		\begin{remark}
			Metascatter involves a symbiotic \gls{mac} where the primary and backscatter symbols of different duration are mixed by \gls{mc} instead of \gls{sc}.
			For each node, the reflection coefficient not only encodes the backscatter message, but also influences the equivalent primary channel \eqref{eq:equivalent_channel}.
			% As such, novel receiving strategy other than \gls{sic} should be tailored to signal characteristics to unveil how reflection pattern potentially influences the primary-backscatter tradeoff.
			To accommodate such signal characteristics, novel receiving strategy apart from \gls{sic} is desired to better utilize the reflection pattern and boost the primary-backscatter tradeoff.
		\end{remark}
	\end{subsection}

	\begin{subsection}{Receiving Strategy}
		We propose a Metascatter receiver where the backscatter messages of all Metascatters are first jointly and semi-coherently detected using total received energy per backscatter block, then modeled within equivalent channel \eqref{eq:equivalent_channel} as dynamic passive beamforming.
		% identified by non-coherent energy detection, then
		% Compared with conventional schemes as joint decoding and \gls{sic}, the Metascatter receiver may not achieve as high data rate for one tag, but it avoids non-coherent primary encoding and enables tag multiple access in a practical and low-complexity manner.
		% Therefore, we believe it can be compatible to and readily implemented over legacy point-to-point systems.
		Compared with \gls{ml} and \gls{sic}, Metascatter receiver allows practical and low-complexity node multiple access with minor adjustment over legacy equipments.

		% At a specific backscatter block, denote $m_k \in \mathcal{M}$ as the state index of Metascatter $k$, and let $m_{\mathcal{K}} \triangleq \{m_k: k \in \mathcal{K}\}$ collect the state indexes of all Metascatters.
		At a specific backscatter block, denote $m_k \in \mathcal{M}$ as the state index of Metascatter $k$, and let $m_{\mathcal{K}} \triangleq (m_1,\ldots,m_K)$ be the state index tuple of all Metascatters.
		% The received signal at primary block $n$ is subject to the variation of $s[n]$ and $v[n]$, and thus distributed as $y[n] \sim \mathcal{CN}(0,\sigma_v^2)$
		Conditioned on $m_{\mathcal{K}}$, the received signal at primary block $n$ is subject to the variation of $s[n]$ and $v[n]$, distributed as $y[n] \sim \mathcal{CN}(0,\sigma_{m_{\mathcal{K}}}^2)$ with
		\begin{equation}
			% \sigma_{m_{\mathcal{K}}}^2 = \Bigl\lvert \underbrace{\bigl(\boldsymbol{h}_{\mathrm{D}}^H + \sum_{k \in \mathcal{K}} \sqrt{\alpha_k} \boldsymbol{h}_{\mathrm{C},k}^H x_{m_k}\bigr)}_{\boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}})} \boldsymbol{w} \Bigr\rvert^2 + \sigma_v^2,
			\sigma_{m_{\mathcal{K}}}^2 = \lvert \boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}}) \boldsymbol{w} \rvert^2 + \sigma_v^2,
			\label{eq:receive_variance}
		\end{equation}
		where $x_{m_k}$ and $x_{m_\mathcal{K}}$ are the symbol and symbol tuple associated with state $m_k$ and state tuple $m_{\mathcal{K}}$, respectively.%
		\footnote{
			$x_k$ and $x_{\mathcal{K}}$ are random variables, while $x_{m_k}$ and $x_{m_{\mathcal{K}}}$ are their instances indexed by $m_k$ and $m_{\mathcal{K}}$.
		}
		Also, denote the total received energy within backscatter block as $z=\sum_{n=1}^N \lvert y[n] \rvert^2$.
		% As the sum of $N$ \gls{iid} exponential variables, conditioned on $m_{\mathcal{K}}$, its \gls{pdf} follows Erlang distribution
		As the sum of $N$ \gls{iid} exponential variables, the \gls{pdf} of $z$ conditioned on $m_{\mathcal{K}}$ follows Erlang distribution
		\begin{equation}
			f(z|\mathcal{H}_{m_{\mathcal{K}}}) = \frac{z^{N-1} \exp(-z/\sigma_{m_{\mathcal{K}}}^2)}{\sigma_{m_{\mathcal{K}}}^{2N} (N-1)!},
			% f(z|\mathcal{H}_{m_{\mathcal{K}}}) = \frac{z^{N-1} \exp(\frac{-z}{\sigma_{m_{\mathcal{K}}}^2})}{\sigma_{m_{\mathcal{K}}}^{2N} (N-1)!},
			\label{eq:energy_distribution}
		\end{equation}
		where $\mathcal{H}_{m_{\mathcal{K}}}$ denotes hypothesis $m_{\mathcal{K}}$.
		% To accommodate backscatter characteristics and reduce decoding complexity, we consider a joint semi-coherent energy detection for all Metascatters based on disjoint decision regions over accumulated energy $z$.
		To accommodate backscatter characteristics and reduce decoding complexity, we consider a joint semi-coherent detection for all Metascatters over accumulated energy $z$.
		% To reduce decoding complexity, we consider a joint semi-coherent energy detection for all Metascatters based on disjoint decision regions over accumulated energy $z$.
		\begin{figure}[!t]
			\centering
			\resizebox{0.9\columnwidth}{!}{
				\input{assets/illustration/energy_distribution.tex}
			}
			% \caption{\gls{pdf} of Average Received Power Conditioned on Different Input Hypothesis. Example \gls{ml}.}
			\caption{
				\gls{pdf} of total received energy per backscatter block, conditioned on different input hypothesis.
				% This \gls{ml} decision consists of convex regions and is generally rate-suboptimal except for equiprobable inputs.}
				Here, the convex \gls{ml} decision regions are generally rate-suboptimal except for equiprobable inputs.
			}
			\label{fi:energy_distribution}
		\end{figure}
		% The idea is presented in Fig. \ref{fi:energy_distribution}.
		% As illustrated in Fig. \ref{fi:energy_distribution}, o
		Once disjoint energy decision regions are determined, we can construct a \gls{dtmac} and formulate the transition probability from input $x_{m_{\mathcal{K}}}$ to output $\hat{x}_{m_{\mathcal{K}}'}$ as
		% it essentially formulates a \gls{dtmac}, and the transition probability from input $x_{m_{\mathcal{K}}}$ to output $\hat{x}_{m_{\mathcal{K}}'}$ is
		\begin{equation}
			P(\hat{x}_{m_{\mathcal{K}}'}|x_{m_{\mathcal{K}}}) = \int_{\mathcal{R}_{m_{\mathcal{K}}'}} f(z|\mathcal{H}_{m_{\mathcal{K}}}) \, d z,
			\label{eq:dtmac}
		\end{equation}
		where $\mathcal{R}_{m_{\mathcal{K}}'}$ is the decision region of hypothesis $\mathcal{H}_{m_{\mathcal{K}}'}$. An example of \gls{ml} energy decision is illustrated in Fig. \ref{fi:energy_distribution}.

		\begin{remark}
			% For a general input distribution, not only the optimal decision thresholds
			The rate-optimal thresholding channel design remains under-investigated, and some attempts were made for single source with binary inputs in \cite{Qian2019b,Nguyen2021b}.
			% The question was only answered for single source with binary inputs in \cite{Qian2019b,Nguyen2021b}.
			% Some attempts for single source with binary inputs were presented in \cite{Qian2019b,Nguyen2021b}.
			For non-binary inputs with general distribution, the optimal decision region for each letter can be non-convex (i.e., with non-adjacent partitions) and the optimal number of thresholds is still unknown.
			% Next, we will restrict the design over convex decision regions.
			% For a general input distribution, not only the rate-optimal decision thresholds
			% % Interestingly, the optimal threshold design to maximize the mutual information for a general \gls{dmtc} with a fixed number of output letters remains an open issue.
			% % The reason is that each decision region may contain more than one disjoint partitions (i.e., non-convex) and the number of thresholds are unknown.
			% % Fortunately, for the proposed energy detection, we proved that the \gls{dmtc} capacity can be achieved using only convex decision regions.
			% not only the capacity-achieving thresholding design remains an open problem, but also the optimal number of thresholds for general non-binary-input channels remains unknown.
		\end{remark}
		In the following context, we restrict all decision regions to convex and optimize decision thresholds accordingly. That is, for any bijective mapping $f : m_{\mathcal{K}} \to \mathcal{L} \triangleq \{1,\ldots,M^K\}$, the decision region of letter $l \in \mathcal{L}$ is defined as $\mathcal{R}_l \triangleq [t_{l-1},t_l)$, where $t_{l-1} \le t_l$. We also define the decision threshold vector as $\boldsymbol{t} \triangleq [t_0,\ldots,t_L]^T \in \mathbb{R}_+^{(L+1) \times 1}$.
	\end{subsection}

	\begin{subsection}{Achievable Rates}
		Denote the input probability of state $m_k$ of Metascatter node $k$ as $P_k(x_{m_k})$, and define the input probability distribution vector of node $k$ as $\boldsymbol{p}_k \triangleq [P_k(c_1),\ldots,P_k(c_M)]^T \in \mathbb{R}^{M \times 1}$. With independent encoding at all nodes, the probability of backscatter symbol tuple $x_{m_{\mathcal{K}}}$ is
		\begin{equation}
			P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) = \prod_{k \in \mathcal{K}} P_k(x_{m_k}).
			\label{eq:equivalent_distribution}
		\end{equation}
		% Denote the input probability distribution vector of tag $k$ as $\boldsymbol{p}_k \triangleq [P_k(x_1),\ldots,P_k(x_M)]^T \in \mathbb{R}^{M \times 1}$, where $P_k(x_{m_k})$ is the probability at state $m_k$.
		% Consider independent encoding at all tags such that the probability of input combination $x_{m_{\mathcal{K}}}$ is $P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) = \prod_{k \in \mathcal{K}} P_k(x_{m_k})$.
		% The backscatter information function of input combination $x_{m_{\mathcal{K}}}$ is defined as
		Similar to \cite{Rezaeian2004}, we define the backscatter information function between input symbol tuple instance $x_{m_{\mathcal{K}}}$ and output symbol tuple $\hat{x}_{\mathcal{K}}$ as
		\begin{equation}
			I^{\mathrm{B}}(x_{m_{\mathcal{K}}};\hat{x}_{\mathcal{K}}) \triangleq \sum_{m_{\mathcal{K}}'} P(\hat{x}_{m_{\mathcal{K}}'}|x_{m_{\mathcal{K}}}) \log \frac{P(\hat{x}_{m_{\mathcal{K}}'}|x_{m_{\mathcal{K}}})}{P(\hat{x}_{m_{\mathcal{K}}'})},
			\label{eq:backscatter_information_function}
		\end{equation}
		where $P(\hat{x}_{m_{\mathcal{K}}'}) = \sum_{m_{\mathcal{K}}} P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) P(\hat{x}_{m_{\mathcal{K}}'}|x_{m_{\mathcal{K}}})$.
		We also define the backscatter marginal information of letter $x_{m_k}$ of node $k$ as
		% Besides, the backscatter marginal information function associated with letter $x_{m_k}$ of tag $k$ is
		\begin{equation}
			% I_{\mathrm{B},k}(x_{m_k};\hat{x}_{\mathcal{K}}) \triangleq \sum_{m_{\mathcal{K} \setminus \{k\}}} P_{\mathcal{K} \setminus \{k\}}(x_{m_{\mathcal{K} \setminus \{k\}}}) I_{\mathrm{B}}(x_{m_{\mathcal{K}}};\hat{x}_{\mathcal{K}}),
			I^{\mathrm{B}}_{k}(x_{m_k};\hat{x}_{\mathcal{K}}) \triangleq \sum_{m_{\mathcal{K} \setminus \{k\}}} P_{\mathcal{K} \setminus \{k\}}(x_{m_{\mathcal{K} \setminus \{k\}}}) I^{\mathrm{B}}(x_{m_{\mathcal{K}}};\hat{x}_{\mathcal{K}}),
			\label{eq:backscatter_marginal_information}
		\end{equation}
		where $P_{\mathcal{K} \setminus \{k\}}(x_{m_{\mathcal{K} \setminus \{k\}}}) = \prod_{q \in \mathcal{K} \setminus \{k\}} P_{q}(x_{m_{q}})$.
		Moreover, we can write the backscatter mutual information as
		\begin{equation}
			% I^{\mathrm{B}}(x_{\mathcal{K}};\hat{x}_{\mathcal{K}}) = \sum_{m_{\mathcal{K}}} P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) \sum_{m_{\mathcal{K}}'} P(\hat{x}_{m_{\mathcal{K}}'}|x_{m_{\mathcal{K}}}) \log \frac{P(\hat{x}_{m_{\mathcal{K}}'}|x_{m_{\mathcal{K}}})}{P(\hat{x}_{m_{\mathcal{K}}'})}.
			I^{\mathrm{B}}(x_{\mathcal{K}};\hat{x}_{\mathcal{K}}) = \sum_{m_{\mathcal{K}}} P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) I^{\mathrm{B}}(x_{m_{\mathcal{K}}};\hat{x}_{\mathcal{K}}).
			\label{eq:backscatter_mutual_information}
		\end{equation}

		% Once the tag input combination is successfully decoded, the backscatter uncertainty can be eliminated and the equivalent channel for primary transmission can be updated by \eqref{eq:equivalent_channel}.

		% eliminate modulation uncertainty
		Once backscatter messages are successfully decoded, we can re-encode to determine $x_{\mathcal{K}}$ and retrieve equivalent primary channel by \eqref{eq:equivalent_channel}. We define the primary information function conditioned on backscatter symbol tuple $x_{m_{\mathcal{K}}}$ as
		% Once backscatter symbols are successfully decoded, we can eliminate modulation uncertainty and retrieve equivalent primary channel by \eqref{eq:equivalent_channel}. We define the primary information function conditioned on backscatter symbol tuple $x_{m_{\mathcal{K}}}$ as
		% \begin{equation}
		% 	I_{\mathrm{P}}(x_{m_{\mathcal{K}}};\boldsymbol{y}) \triangleq \log \left(1 + \frac{\lvert \boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}}) \boldsymbol{w} \rvert^2}{\sigma_v^2}\right),
		% 	\label{eq:primary_information_function}
		% \end{equation}
		\begin{equation}
			I^{\mathrm{P}}(s;y|x_{m_{\mathcal{K}}}) \triangleq \log \Bigl(1 + \frac{\lvert \boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}}) \boldsymbol{w} \rvert^2}{\sigma_v^2}\Bigr),
			\label{eq:primary_information_function}
		\end{equation}
		the primary marginal information conditioned on letter $x_{m_k}$ of node $k$ as
		% the primary marginal information function associated with letter $x_{m_k}$ of tag $k$ is
		\begin{equation}
			I^{\mathrm{P}}_{k}(s;y|x_{m_k}) \triangleq \sum_{m_{\mathcal{K} \setminus \{k\}}} P_{\mathcal{K} \setminus \{k\}}(x_{m_{\mathcal{K} \setminus \{k\}}}) I^{\mathrm{P}}(s;y|x_{m_{\mathcal{K}}}),
			\label{eq:primary_marginal_information}
		\end{equation}
		and the primary ergodic mutual information as
		% and the primary (ergodic) mutual information is
		\begin{equation}
			% I^{\mathrm{P}}(s;y|x_{\mathcal{K}}) = \sum_{m_{\mathcal{K}}} P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) \log \left(1 + \frac{\lvert \boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}}) \boldsymbol{w} \rvert^2}{\sigma_v^2}\right).
			I^{\mathrm{P}}(s;y|x_{\mathcal{K}}) = \sum_{m_{\mathcal{K}}} P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) I^{\mathrm{P}}(s;y|x_{m_{\mathcal{K}}}).
			\label{eq:primary_mutual_information}
		\end{equation}

		% Moreover, with $\rho \in [0,1]$ being the relative priority of the primary link, we define corresponding weighted sum information function, marginal information, and mutual information respectively as
		Finally, with a slight abuse of notation, we define the corresponding weighted sum information function, marginal information, and mutual information respectively as
		\begin{align}
			I(x_{m_{\mathcal{K}}})
			 & \triangleq \rho I^{\mathrm{P}}(s;y|x_{m_{\mathcal{K}}}) + (1 - \rho) I^{\mathrm{B}}(x_{m_{\mathcal{K}}};\hat{x}_{\mathcal{K}}),\label{eq:weighted_sum_information_function} \\
			I_k(x_{m_k})
			 & \triangleq \rho I^{\mathrm{P}}_{k}(s;y|x_{m_k}) + (1 - \rho) I^{\mathrm{B}}_{k}(x_{m_k};\hat{x}_{\mathcal{K}}),\label{eq:weighted_sum_marginal_information}                 \\
			I(x_{\mathcal{K}})
			 & \triangleq \rho I^{\mathrm{P}}(s;y|x_{\mathcal{K}}) + (1 - \rho) I^{\mathrm{B}}(x_{\mathcal{K}};\hat{x}_{\mathcal{K}}),\label{eq:weighted_sum_mutual_information}
		\end{align}
		where $0 \le \rho \le 1$ is the relative priority of the primary link.


		% Therefore, the weighted sum information function, marginal information function, and mutual information of primary and backscatter links are respectively given by
		% \begin{align}
		% 	I(x_{m_{\mathcal{K}}};\hat{x}_{\mathcal{K}},\boldsymbol{y})
		% 	 & \triangleq \rho I_{\mathrm{P}}(x_{m_{\mathcal{K}}};\boldsymbol{y}) + (1 - \rho) I_{\mathrm{B}}(x_{m_{\mathcal{K}}};\hat{x}_{\mathcal{K}}),\label{eq:weighted_sum_information_function} \\
		% 	I_k(x_{m_k};\hat{x}_{\mathcal{K}},\boldsymbol{y})
		% 	 & \triangleq \rho I_{\mathrm{P},k}(x_{m_k};\boldsymbol{y}) + (1 - \rho) I_{\mathrm{B},k}(x_{m_k};\hat{x}_{\mathcal{K}}),\label{eq:weighted_sum_marginal_information}                     \\
		% 	I(x_{\mathcal{K}};\hat{x}_{\mathcal{K}},\boldsymbol{y})
		% 	 & \triangleq \rho I_{\mathrm{P}}(x_{\mathcal{K}};\boldsymbol{y}) + (1 - \rho) I_{\mathrm{B}}(x_{\mathcal{K}};\hat{x}_{\mathcal{K}}),\label{eq:weighted_sum_mutual_information}
		% \end{align}
		% where $\rho \in [0,1]$ represents the priority of the primary link.
	\end{subsection}
\end{section}

\begin{section}{Input Distribution, Active Beamforming, and Decision Threshold Design}
	To characterize the achievable primary-(total-)backscatter rate region of the proposed Metascatter-enabled network, we aim to maximize the weighted sum mutual information with respect to node input distributions $\{\boldsymbol{p}_k\}_{k \in \mathcal{K}}$, active beamforming vector $\boldsymbol{w}$, and decision threshold vector $\boldsymbol{t}$ as
	\begin{maxi!}
		{\scriptstyle{\{\boldsymbol{p}_k\}_{k \in \mathcal{K}},\boldsymbol{w},\boldsymbol{t}\in\mathbb{R}_+^{L+1}}}{I(x_{\mathcal{K}})}{\label{op:weighted_sum_rate}}{\label{ob:weighted_sum_rate}}
		% \addConstraint{\sum \nolimits_{m_k} P_k(x_{m_k})}{=1,}{\quad \forall k \in \mathcal{K}}{\label{co:sum_probability}}
		\addConstraint{\sum \nolimits_{m_k} P_k(x_{m_k})}{=1,}{\quad \forall k}{\label{co:sum_probability}}
		% \addConstraint{P_k(x_{m_k})}{\ge 0,}{\quad \forall k \in \mathcal{K}, \ \forall m_k \in \mathcal{M}}{\label{co:nonnegative_probability}}
		\addConstraint{P_k(x_{m_k})}{\ge 0,}{\quad \forall k,m_k}{\label{co:nonnegative_probability}}
		\addConstraint{\lVert \boldsymbol{w} \rVert^2}{\le P}{\label{co:transmit_power}}
		\addConstraint{t_{l-1}}{\le t_l,}{\quad \forall l.}{\label{co:decision_threshold}}
	\end{maxi!}
	% \begin{maxi!}
	% 	{\scriptstyle{\{\boldsymbol{p}_k\}_{k \in \mathcal{K}},\boldsymbol{t},\boldsymbol{w}}}{I(x_{\mathcal{K}})}{\label{op:weighted_sum_rate}}{\label{ob:weighted_sum_rate}}
	% 	\addConstraint{\boldsymbol{p}_k}{\in \Delta^{M-1},}{\quad \forall k \in \mathcal{K}}{\label{co:sum_probability}}
	% 	% \addConstraint{P_k(x_{m_k})}{\ge 0,}{\quad \forall k \in \mathcal{K}, \ \forall m_k \in \mathcal{M}}{\label{co:nonnegative_probability}}
	% 	\addConstraint{\lVert \boldsymbol{w} \rVert^2}{\le P.}{\label{co:transmit_power}}
	% \end{maxi!}
	% \begin{maxi!}
	% 	{\scriptstyle{\boldsymbol{p}_k \in \Delta^{M-1},\boldsymbol{t},\boldsymbol{w}}}{I(x_{\mathcal{K}})}{\label{op:weighted_sum_rate}}{\label{ob:weighted_sum_rate}}
	% 	% \addConstraint{\boldsymbol{p}_k}{\in \Delta^{M-1},}{\quad \forall k \in \mathcal{K}}{\label{co:sum_probability}}
	% 	% \addConstraint{P_k(x_{m_k})}{\ge 0,}{\quad \forall k \in \mathcal{K}, \ \forall m_k \in \mathcal{M}}{\label{co:nonnegative_probability}}
	% 	\addConstraint{\lVert \boldsymbol{w} \rVert^2}{\le P.}{\label{co:transmit_power}}
	% \end{maxi!}
	Problem \eqref{op:weighted_sum_rate} is highly non-convex, and we propose a \gls{bcd} algorithm that iteratively updates $\{\boldsymbol{p}_k\}_{k \in \mathcal{K}}$, $\boldsymbol{w}$ and $\boldsymbol{t}$ until convergence.

	\begin{subsection}{Input Distribution}
		% For any fixed decision boundary $\boldsymbol{t}$ and transmit precoder $\boldsymbol{w}$, the equivalent \gls{dtmac} can be formulated by \eqref{eq:dtmac} and problem \eqref{op:weighted_sum_rate} boils down to
		For any given $\boldsymbol{w}$ and $\boldsymbol{t}$, we can construct the equivalent \gls{dtmac} by \eqref{eq:dtmac} and simplify \eqref{op:weighted_sum_rate} to
		\begin{maxi!}
			{\scriptstyle{\{\boldsymbol{p}_k\}_{k \in \mathcal{K}}}}{I(x_{\mathcal{K}})}{\label{op:input_distribution}}{}
			\addConstraint{\eqref{co:sum_probability},\eqref{co:nonnegative_probability},}
		\end{maxi!}
		which involves coupled term $\prod_{k \in \mathcal{K}} P_k(x_{m_k})$ and is non-convex when $K > 1$. Next, we propose a numerical method that evaluate the \gls{kkt} input distribution by limit of sequences.
		\begin{remark}
			% As pointed out in \cite{Buhler2011}, \gls{kkt} conditions are only necessary for such kind of problems and these solutions may end up being saddle points.
			As pointed out in \cite{Buhler2011}, \gls{kkt} conditions are generally necessary but insufficient for total rate maximization in discrete memoryless \gls{mac}. Therefore, \gls{kkt} solutions may end up being saddle points of problem \eqref{op:input_distribution}.
		\end{remark}
		Following \cite{Rezaeian2004}, we first recast \gls{kkt} conditions to their equivalent form for problem \eqref{op:input_distribution}, then propose an iterative method that guarantees input distribution satisfying above conditions on convergence.
		% Interestingly, the total-rate optimal input design for general discrete memoryless \gls{mac} remains an open problem, and we instead propose a \gls{kkt} solution to problem \eqref{op:input_distribution}.
		\begin{proposition}
			% The \gls{kkt} optimality conditions for problem \eqref{op:input_distribution} are equivalent to, $\forall k \in \mathcal{K}$ and $\forall m_k \in \mathcal{M}$,
			The \gls{kkt} optimality conditions for problem \eqref{op:input_distribution} are equivalent to, $\forall k,m_k$,
			\begin{subequations}
				\label{eq:input_kkt_condition}
				\begin{alignat}{2}
					I_k^\star(x_{m_k}) & = I^\star(x_{\mathcal{K}}), \quad   &  & P_k^\star(x_{m_k}) > 0,\label{eq:probable_states} \\
					I_k^\star(x_{m_k}) & \le I^\star(x_{\mathcal{K}}), \quad &  & P_k^\star(x_{m_k}) = 0.\label{eq:dropped_states}
				\end{alignat}
			\end{subequations}
			\label{pr:input_kkt_condition}
		\end{proposition}

		\begin{proof}
			Please refer to Appendix \ref{ap:input_kkt_condition}.
			\label{pf:input_kkt_condition}
		\end{proof}

		For each node, \eqref{eq:probable_states} suggests each probable state should produce the same marginal information (averaged over all states of other nodes), while \eqref{eq:dropped_states} implies any state with potentially less marginal information should not be used.
		% We notice \eqref{eq:probable_states} means each probable state of each tag should produce the same marginal information (averaged over all states of other tags), while \eqref{eq:dropped_states} implies any state of any tag with potentially less marginal information than above should not be used.
		% Next, we generalize the Blahut-Arimoto algorithm \cite{Arimoto1972,Blahut1972a} and propose a numerical evaluation of \gls{kkt} points by limits of sequences.
		\begin{proposition}
			% The \gls{kkt} solution of input probability of tag $k$ at state $m_k$ is given by the converging point of the sequence
			The \gls{kkt} input probability of node $k$ of state $m_k$ is given by the converging point of the sequence
			% The \gls{kkt} solution of input probability of tag $k$ at state $m_k$ is given by the converging point of the sequence
			\begin{equation}
				P_k^{(r+1)}(x_{m_k}) = \frac{P_k^{(r)}(x_{m_k}) \exp \Bigl( \frac{\rho}{1 - \rho} I_k^{(r)}(x_{m_k}) \Bigr)}{\sum_{m_k'} P_k^{(r)}(x_{m_k'}) \exp \Bigl( \frac{\rho}{1 - \rho} I_k^{(r)}(x_{m_k'}) \Bigr)},
				\label{eq:input_kkt_solution}
			\end{equation}
			% where $r$ is the iteration index and $\boldsymbol{p}_k^{(0)} > \boldsymbol{0}$, $\forall k \in \mathcal{K}$.
			where $r$ is the iteration index and $\boldsymbol{p}_k^{(0)} > \boldsymbol{0}$, $\forall k$.
			\label{pr:input_kkt_solution}
		\end{proposition}
		\begin{proof}
			Please refer to Appendix \ref{ap:input_kkt_solution}.
			\label{pf:input_kkt_solution}
		\end{proof}

		At each iteration, the input distribution of node $k$ is evaluated over updated input distribution of node $1$ to $k-1$, together with previous input distribution of node $k+1$ to $K$. The \gls{kkt} input distribution design is summarized in Algorithm \ref{al:input_distribution}.

		\begin{algorithm}[!t]
			\caption{Numerical Evaluation of \gls{kkt} Input Distribution}
			\label{al:input_distribution}
			\begin{algorithmic}[1]
				\Require $K$, $N$, $\boldsymbol{h}_{\mathrm{D}}^H$, $\boldsymbol{H}_{\mathrm{C}}$, $\boldsymbol{\alpha}$, $\mathcal{X}$, $\sigma_v^2$, $\rho$, $\boldsymbol{w}$, $\boldsymbol{t}$, $\epsilon$
				\Ensure $\{\boldsymbol{p}_k^\star\}_{k \in \mathcal{K}}$
				\State Set $\boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}})$, $\forall m_{\mathcal{K}}$ by \eqref{eq:equivalent_channel}
				\State \phantom{Set} $\sigma^2_{m_{\mathcal{K}}}$, $\forall m_{\mathcal{K}}$ by \eqref{eq:receive_variance}
				\State \phantom{Set} $f(z|\mathcal{H}_{m_{\mathcal{K}}})$, $\forall m_{\mathcal{K}}$ by \eqref{eq:energy_distribution}
				\State \phantom{Set} $P(\hat{x}_{m_{\mathcal{K}}'}|x_{m_{\mathcal{K}}})$, $\forall m_{\mathcal{K}}, m_{\mathcal{K}}'$ by \eqref{eq:dtmac}
				\State Initialize $r \gets 0$
				\State \phantom{Initialize} $\boldsymbol{p}_k^{(0)} > \boldsymbol{0}$, $\forall k$
				\State Get $P_{\mathcal{K}}^{(r)}(x_{m_{\mathcal{K}}})$, $\forall m_{\mathcal{K}}$ by \eqref{eq:equivalent_distribution} \label{st:input_distribution_begin}
				\State \phantom{Get} $I^{(r)}(x_{m_{\mathcal{K}}})$, $\forall m_{\mathcal{K}}$ by \eqref{eq:backscatter_information_function}, \eqref{eq:primary_information_function}, \eqref{eq:weighted_sum_information_function}
				\State \phantom{Get} $I^{(r)}_k(x_{m_k})$, $\forall k,m_k$ by \eqref{eq:backscatter_marginal_information}, \eqref{eq:primary_marginal_information}, \eqref{eq:weighted_sum_marginal_information}
				\State \phantom{Get} $I^{(r)}(x_{\mathcal{K}})$ by \eqref{eq:backscatter_mutual_information}, \eqref{eq:primary_mutual_information}, \eqref{eq:weighted_sum_mutual_information} \label{st:input_distribution_end}
				\Repeat
					\State Update $r \gets r+1$
					\State \phantom{Update} $\boldsymbol{p}_k^{(r)}$, $\forall k$ by \eqref{eq:input_kkt_solution}
					\State Redo step \ref{st:input_distribution_begin}--\ref{st:input_distribution_end}
					% \State Get $P_{\mathcal{K}}^{(r)}(x_{m_{\mathcal{K}}})$, $\forall m_{\mathcal{K}}$ by \eqref{eq:equivalent_distribution}
					% \State \phantom{Get} $I^{(r)}(x_{m_{\mathcal{K}}})$, $\forall m_{\mathcal{K}}$ by \eqref{eq:backscatter_information_function}, \eqref{eq:primary_information_function}, \eqref{eq:weighted_sum_information_function}
					% \State \phantom{Get} $I^{(r)}_k(x_{m_k})$, $\forall k,m_k$ by \eqref{eq:backscatter_marginal_information}, \eqref{eq:primary_marginal_information}, \eqref{eq:weighted_sum_marginal_information}
					% \State \phantom{Get} $I^{(r)}(x_{\mathcal{K}})$ by \eqref{eq:backscatter_mutual_information}, \eqref{eq:primary_mutual_information}, \eqref{eq:weighted_sum_mutual_information}
				\Until $I^{(r)}(x_{\mathcal{K}}) - I^{(r-1)}(x_{\mathcal{K}}) \le \epsilon$
			\end{algorithmic}
		\end{algorithm}
	\end{subsection}

	\begin{subsection}{Active Beamforming}
		For any given $\{\boldsymbol{p}_k\}_{k \in \mathcal{K}}$ and $\boldsymbol{t}$, problem \eqref{op:weighted_sum_rate} reduces to
		\begin{maxi!}
			{\scriptstyle{\boldsymbol{w}}}{I(x_{\mathcal{K}})}{\label{op:active_beamforming}}{\label{ob:active_beamforming}}
			\addConstraint{\eqref{co:transmit_power},}
		\end{maxi!}
		which is still non-convex due to integration and entropy terms.
		\begin{figure*}[!b]
			\hrule
			\begin{equation}
				I(x_{\mathcal{K}})=\sum_{m_{\mathcal{K}}}P_{\mathcal{K}}(x_{m_{\mathcal{K}}})\Biggl(\rho\log\Bigl(1+\frac{\lvert\boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}})\boldsymbol{w}\rvert^2}{\sigma_v^2}\Bigr)+(1-\rho)\sum_l Q\Bigl(N,\frac{t_{l-1}}{\sigma_{m_{\mathcal{K}}}^2},\frac{t_l}{\sigma_{m_{\mathcal{K}}}^2}\Bigr) \log \frac{Q\Bigl(N,\frac{t_{l-1}}{\sigma_{m_{\mathcal{K}}}^2},\frac{t_l}{\sigma_{m_{\mathcal{K}}}^2}\Bigr)}{\sum_{m_{\mathcal{K}}'} P_{\mathcal{K}}(x_{m_{\mathcal{K}}'}) Q\Bigl(N,\frac{t_{l-1}}{\sigma_{m_{\mathcal{K}}'}^2},\frac{t_l}{\sigma_{m_{\mathcal{K}}'}^2}\Bigr)}\Biggr)
				\label{eq:weighted_sum_mutual_information_explicit}
			\end{equation}
		\end{figure*}
		To see this, we explicitly write \eqref{ob:active_beamforming} as \eqref{eq:weighted_sum_mutual_information_explicit} at the bottom of page \pageref{eq:regularized_incomplete_gamma}, where
		\begin{equation}
			Q\Bigl(N,\frac{t_{l-1}}{\sigma_{m_{\mathcal{K}}}^2},\frac{t_l}{\sigma_{m_{\mathcal{K}}}^2}\Bigr) = \frac{\int_{{t_{l-1}}/{\sigma_{m_{\mathcal{K}}}^2}}^{{t_l}/{\sigma_{m_{\mathcal{K}}}^2}} z^{N-1} \exp(-z) \, d z}{(N-1)!}
			\label{eq:regularized_incomplete_gamma}
		\end{equation}
		is the regularized incomplete Gamma function that substitutes the \gls{dtmac} transition probability \eqref{eq:dtmac}.
		Its series representation is given by \cite[Theorem~3]{Jameson2016}
		\begin{align}
			Q\Bigl(N,\frac{t_{l-1}}{\sigma_{m_{\mathcal{K}}}^2},\frac{t_l}{\sigma_{m_{\mathcal{K}}}^2}\Bigr)
			 & = \exp \Bigl(-\frac{t_{l-1}}{\sigma_{m_{\mathcal{K}}}^2}\Bigr) \sum_{n=0}^{N-1} \frac{\Bigl(\frac{t_{l-1}}{\sigma_{m_{\mathcal{K}}}^2}\Bigr)^n}{n!} \nonumber \\
			 & \quad - \exp \Bigl(-\frac{t_l}{\sigma_{m_{\mathcal{K}}}^2}\Bigr) \sum_{n=0}^{N-1} \frac{\Bigl(\frac{t_l}{\sigma_{m_{\mathcal{K}}}^2}\Bigr)^n}{n!}.
			\label{eq:regularized_incomplete_gamma_series}
		\end{align}
		Next, we derive the gradients of \eqref{eq:regularized_incomplete_gamma_series} and \eqref{eq:weighted_sum_mutual_information_explicit} w.r.t. $\boldsymbol{w}^*$ as \eqref{eq:regularized_incomplete_gamma_gradient} and \eqref{eq:weighted_sum_mutual_information_gradient} at the end of page \pageref{eq:regularized_incomplete_gamma_gradient} and \pageref{eq:weighted_sum_mutual_information_gradient}, respectively.
		\begin{figure*}[!b]
			\begin{align}
				\nabla_{\boldsymbol{w}^*} Q\Bigl(N,\frac{t_{l-1}}{\sigma_{m_{\mathcal{K}}}^2},\frac{t_l}{\sigma_{m_{\mathcal{K}}}^2}\Bigr)
				 & = \frac{\boldsymbol{h}_{\mathrm{E}}(x_{m_{\mathcal{K}}})\boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}})\boldsymbol{w}}{\bigl(\lvert\boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}})\boldsymbol{w}\rvert^2+\sigma_v^2\bigr)^2}\nonumber                                                                                                                                                                                                        \\
				 & \quad \times \Biggl(t_l\exp\Bigl(-\frac{t_l}{\lvert\boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}})\boldsymbol{w}\rvert^2+\sigma_v^2}\Bigr)\biggl(-1+\sum_{n=1}^{N-1} \frac{n\Bigl(\frac{t_l}{\lvert\boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}})\boldsymbol{w}\rvert^2+\sigma_v^2}\Bigr)^{n-1}-\Bigl(\frac{t_l}{\lvert\boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}})\boldsymbol{w}\rvert^2+\sigma_v^2}\Bigr)^n}{n!}\biggr)\nonumber    \\
				 & \qquad - t_{l-1}\exp\Bigl(-\frac{t_{l-1}}{\lvert\boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}})\boldsymbol{w}\rvert^2+\sigma_v^2}\Bigr)\biggl(-1+\sum_{n=1}^{N-1} \frac{n\Bigl(\frac{t_{l-1}}{\lvert\boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}})\boldsymbol{w}\rvert^2+\sigma_v^2}\Bigr)^{n-1}-\Bigl(\frac{t_{l-1}}{\lvert\boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}})\boldsymbol{w}\rvert^2+\sigma_v^2}\Bigr)^n}{n!}\biggr)\Biggr)
				\label{eq:regularized_incomplete_gamma_gradient}
			\end{align}
		\end{figure*}
		\begin{figure*}[!b]
			\hrule
			\begin{align}
				\nabla_{\boldsymbol{w}^*} I(x_{\mathcal{K}})
				 & = \sum_{m_{\mathcal{K}}}P_{\mathcal{K}}(x_{m_{\mathcal{K}}})\Biggl(\rho\frac{\boldsymbol{h}_{\mathrm{E}}(x_{m_{\mathcal{K}}})\boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}})\boldsymbol{w}}{\lvert\boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}})\boldsymbol{w}\rvert^2+\sigma_v^2}+(1-\rho)\sum_l\biggl(\log\frac{Q\Bigl(N,\frac{t_{l-1}}{\sigma_{m_{\mathcal{K}}}^2},\frac{t_l}{\sigma_{m_{\mathcal{K}}}^2}\Bigr)}{\sum_{m_{\mathcal{K}}'}P_{\mathcal{K}}(x_{m_{\mathcal{K}}'})Q\Bigl(N,\frac{t_{l-1}}{\sigma_{m_{\mathcal{K}}'}^2},\frac{t_l}{\sigma_{m_{\mathcal{K}}'}^2}\Bigr)}+1\biggr)\nonumber   \\
				 & \qquad \times \nabla_{\boldsymbol{w}^*} Q\Bigl(N,\frac{t_{l-1}}{\sigma_{m_{\mathcal{K}}}^2},\frac{t_l}{\sigma_{m_{\mathcal{K}}}^2}\Bigr)-\frac{Q\Bigl(N,\frac{t_{l-1}}{\sigma_{m_{\mathcal{K}}}^2},\frac{t_l}{\sigma_{m_{\mathcal{K}}}^2}\Bigr)\sum_{m_{\mathcal{K}}'}P_{\mathcal{K}}(x_{m_{\mathcal{K}}'})\nabla_{\boldsymbol{w}^*}Q\Bigl(N,\frac{t_{l-1}}{\sigma_{m_{\mathcal{K}}'}^2},\frac{t_l}{\sigma_{m_{\mathcal{K}}'}^2}\Bigr)}{\sum_{m_{\mathcal{K}}'}P_{\mathcal{K}}(x_{m_{\mathcal{K}}'})Q\Bigl(N,\frac{t_{l-1}}{\sigma_{m_{\mathcal{K}}'}^2},\frac{t_l}{\sigma_{m_{\mathcal{K}}'}^2}\Bigr)}\Biggr)
				\label{eq:weighted_sum_mutual_information_gradient}
			\end{align}
		\end{figure*}
		% Next, we express the gradient of \eqref{eq:regularized_incomplete_gamma_series} and \eqref{eq:weighted_sum_mutual_information_explicit} w.r.t. $\boldsymbol{w}^*$ as \eqref{eq:regularized_incomplete_gamma_gradient} and \eqref{eq:weighted_sum_mutual_information_gradient} at the end of page \pageref{eq:regularized_incomplete_gamma_gradient},
		It allows problem \eqref{op:active_beamforming} to be solved by the \gls{pgd} method, where any unregulated beamforming vector $\bar{\boldsymbol{w}}$ can be projected onto the feasible domain of average transmit power constraint \eqref{co:transmit_power} by
		% the projection function associated with average transmit power constraint \eqref{co:transmit_power} is
		\begin{equation}
			\boldsymbol{w} = \sqrt{P} \frac{\bar{\boldsymbol{w}}}{\max\bigl(\sqrt{P},\lVert\bar{\boldsymbol{w}}\rVert\bigr)}.
			\label{eq:beamforming_projection}
		\end{equation}
		We present the iterative active beamforming design accelerated by backtracking line search in Algorithm \ref{al:active_beamforming}.
		\begin{algorithm}[!t]
			\caption{Iterative Active Beamforming Design by \gls{pgd} with Backtracking Line Search}
			\label{al:active_beamforming}
			\begin{algorithmic}[1]
				\Require $Q$, $N$, $\boldsymbol{h}_{\mathrm{D}}^H$, $\boldsymbol{H}_{\mathrm{C}}$, $\boldsymbol{\alpha}$, $\mathcal{X}$, $P$, $\sigma_v^2$, $\rho$, $\{\boldsymbol{p}_k\}_{k \in \mathcal{K}}$, $\boldsymbol{t}$, $\alpha$, $\beta$, $\gamma$, $\epsilon$
				\Ensure $\boldsymbol{w}^\star$
				\State Set $\boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}})$, $\forall m_{\mathcal{K}}$ by \eqref{eq:equivalent_channel}
				\State \phantom{Set} $P_{\mathcal{K}}(x_{m_{\mathcal{K}}})$, $\forall m_{\mathcal{K}}$ by \eqref{eq:equivalent_distribution}
				\State Initialize $r \gets 0$
				\State \phantom{Initialize} $\boldsymbol{w}^{(0)}$, $\lVert\boldsymbol{w}^{(0)}\rVert^2 \le P$
				\State Get $(\sigma_{m_{\mathcal{K}}}^{(r)})^2$, $\forall m_{\mathcal{K}}$ by \eqref{eq:receive_variance} \label{st:gradient_descent_begin}
				\State \phantom{Get} $Q^{(r)}\bigl(N,\frac{t_{l-1}}{\sigma_{m_{\mathcal{K}}}^2},\frac{t_l}{\sigma_{m_{\mathcal{K}}}^2}\bigr)$, $\forall m_{\mathcal{K}},l$ by \eqref{eq:regularized_incomplete_gamma} or \eqref{eq:regularized_incomplete_gamma_series}
				\State \phantom{Get} $I^{(r)}(x_{\mathcal{K}})$ by \eqref{eq:weighted_sum_mutual_information_explicit} \label{st:gradient_descent_end}
				\State \phantom{Get} $\nabla_{\boldsymbol{w}^*} Q^{(r)}\bigl(N,\frac{t_{l-1}}{\sigma_{m_{\mathcal{K}}}^2},\frac{t_l}{\sigma_{m_{\mathcal{K}}}^2}\bigr)$, $\forall m_{\mathcal{K}},l$ by \eqref{eq:regularized_incomplete_gamma_gradient} \label{st:gradient_update_start}
				\State \phantom{Get} $\nabla_{\boldsymbol{w}^*} I^{(r)}(x_{\mathcal{K}})$ by \eqref{eq:weighted_sum_mutual_information_gradient} \label{st:gradient_update_end}
				\Repeat
					\State Update $r \gets r+1$
					\State \phantom{Update} $\gamma^{(r)}\gets\gamma$
					\State \phantom{Update} $\bar{\boldsymbol{w}}^{(r)} \gets \boldsymbol{w}^{(r-1)}+\gamma\nabla_{\boldsymbol{w}^*} I^{(r-1)}(x_{\mathcal{K}})$ \label{st:backtracking_line_search_begin}
					\State \phantom{Update} $\boldsymbol{w}^{(r)}$ by \eqref{eq:beamforming_projection}
					\State Redo step \ref{st:gradient_descent_begin}--\ref{st:gradient_descent_end} \label{st:backtracking_line_search_end}
					% \State \phantom{Update} $(\sigma_{m_{\mathcal{K}}}^{(r)})^2$, $\forall m_{\mathcal{K}}$ by \eqref{eq:receive_variance}
					% \State \phantom{Update} $Q^{(r)}\bigl(N,\frac{t_{l-1}}{\sigma_{m_{\mathcal{K}}}^2},\frac{t_l}{\sigma_{m_{\mathcal{K}}}^2}\bigr)$, $\forall m_{\mathcal{K}},l$ by \eqref{eq:regularized_incomplete_gamma} or \eqref{eq:regularized_incomplete_gamma_series}
					% \State \phantom{Update} $I^{(r)}(x_{\mathcal{K}})$ by \eqref{eq:weighted_sum_mutual_information_explicit} \label{st:backtracking_line_search_end}
					% \While{$I^{(r-1)}(x_{\mathcal{K}})>I^{(r)}(x_{\mathcal{K}})+\alpha\gamma\lVert\nabla_{\boldsymbol{w}^*}I^{(r-1)}(x_{\mathcal{K}})\rVert$}
					\While{$I^{(r)}(x_{\mathcal{K}})<I^{(r-1)}(x_{\mathcal{K}})+\alpha\gamma\lVert\nabla_{\boldsymbol{w}^*}I^{(r-1)}(x_{\mathcal{K}})\rVert^2$}
						\State Set $\gamma^{(r)}\gets\beta\gamma^{(r)}$
						\State Redo step \ref{st:backtracking_line_search_begin}--\ref{st:backtracking_line_search_end}
					\EndWhile
					\State Redo step \ref{st:gradient_update_start}, \ref{st:gradient_update_end}
				\Until $\lVert\boldsymbol{w}^{(r)}-\boldsymbol{w}^{(r-1)}\rVert \le \epsilon$
			\end{algorithmic}
		\end{algorithm}
	\end{subsection}

	\begin{subsection}{Decision Threshold}
		% Once node input distribution $\{\boldsymbol{p}_k\}_{k \in \mathcal{K}}$ and active beamforming vector $\boldsymbol{w}$ are obtained, problem \eqref{op:weighted_sum_rate}
		For any given $\{\boldsymbol{p}_k\}_{k \in \mathcal{K}}$ and $\boldsymbol{w}$, problem \eqref{op:weighted_sum_rate} reduces to
		\begin{maxi!}
			{\scriptstyle{\boldsymbol{t}\in\mathbb{R}_+^{L+1}}}{I(x_{\mathcal{K}})}{\label{op:decision_threshold}}{\label{ob:decision_threshold}}
			\addConstraint{\eqref{co:decision_threshold},}
		\end{maxi!}
		where it is trivial to conclude $t_0^\star=0$ and $t_L^\star=\infty$ for energy-based backscatter detection.

		\begin{remark}
			Backscatter detection (and decision design) has no impact on primary achievable rate.
			When nodes transmit at non-zero total rate, the user can re-encode backscatter messages to recover coded backscatter tuple $x_{\mathcal{K}}$ at each block.
			Otherwise, $x_{\mathcal{K}}$ can be fully deterministic and known to the user.
			% Once backscatter messages are successfully decoded, the user can re-encode backscatter messages to recover coded backscatter tuple $x_{\mathcal{K}}$ at each block.
			% Upon successful backscatter detection, the user can re-encode backscatter messages to recover coded backscatter tuple $x_{\mathcal{K}}$ at each block.
			% Therefore, decision design has no impact on primary achievable rate.
			% Decision threshold only influences backscatter rate instead of primary rate.
			\label{re:backscatter_detection}
		\end{remark}

		Remark \ref{re:backscatter_detection} suggests any $\boldsymbol{t}$ maximizes total backscatter mutual information $I^{\mathrm{B}}(x_{\mathcal{K}};\hat{x}_{\mathcal{K}})$ is also optimal for problem \eqref{op:decision_threshold}.

		\begin{remark}
			% With input distribution of all nodes, we can formulate an equivalent information source with augmented alphabet of tag input combination.
			% In terms of total backscatter rate, we can formulate an equivalent information source with augmented alphabet of tag input combination.
			% When input distribution of all nodes are available, we can formulate an equivalent information source in terms of total backscatter rate.
			% When input distribution of all nodes are available, we can think an equivalent information source with augmented alphabet of state tuple, in terms of total backscatter rate.
			% In terms of total backscatter rate, we can regard all nodes as an equivalent information source with augmented alphabet of node state tuple $x_{m_{\mathcal{K}}}$.
			In terms of total backscatter rate, the nodes can be regarded as an equivalent source with augmented alphabet of symbol tuple $x_{m_{\mathcal{K}}}$, and the \gls{dtmac} \eqref{eq:dtmac} essentially reduces to a \gls{dmtc}.
			% As such, the \gls{dtmac} \eqref{eq:dtmac} is essentially a \gls{dmtc}, and decision threshold design can be simplified accordingly.
		\end{remark}

		Finally, we can employ existing thresholding design for \gls{dmtc} to solve problem \eqref{op:decision_threshold}.
		For example, \cite{He2021} first discretized the continuous energy $z$ into numerous output bins, then grouped adjacent bins to maximize mutual information using \gls{dp} accelerated by \gls{smawk} algorithm.
		In \cite{Nguyen2020a}, the authors first proved the optimality condition for any three neighbor thresholds, then fix $t_0$, traverse $t_1$, and sequentially optimizes the others by bisection.
		Both will be compared with \gls{ml} decision \cite{Qian2019}
		\begin{equation}
			t_{l}^{\mathrm{\gls{ml}}} = N \frac{\sigma_{l-1}^2 \sigma_{l}^2}{\sigma_{l-1}^2 - \sigma_{l}^2} \log \frac{\sigma_{l-1}^2}{\sigma_{l}^2}, \quad l \in \mathcal{L} \setminus \{0,L\},
			\label{eq:detection_threshold_maximum_likelihood}
		\end{equation}
		which is generally suboptimal for problem \eqref{op:decision_threshold} except for equiprobable inputs at all nodes.

		% \begin{remark}
		% 	Although the \gls{ml} decision threshold is optimal in terms of the likelihood function, it is not necessarily capacity-achieving, although the performance gap can be negligible in the single-tag \gls{bibo} case.
		% \end{remark}

		% Interestingly, the optimal threshold design to maximize the mutual information for a general \gls{dmtc} with a fixed number of output letters remains an open issue.
		% The reason is that each decision region may contain more than one disjoint partitions (i.e., non-convex) and the number of thresholds are unknown.
		% Fortunately, for the proposed energy detection, we proved that the \gls{dmtc} capacity can be achieved using only convex decision regions.
		% This conclusion is summarized below.

		% \begin{proposition}
		% 	For a discrete-input continuous-output channel in Erlang distribution \eqref{eq:energy_distribution}, if the \gls{dmtc} is constructed for detection (i.e., same input/output alphabet) and $L$ input letters are with non-zero probability, then it is possible to achieve the \gls{dmtc} capacity by $L$ non-empty convex decision regions defined by $L+1$ distinct decision thresholds.
		% 	\label{pr:threshold}
		% \end{proposition}

		% \begin{proof}
		% 	Please refer to Appendix \ref{ap:threshold}.
		% 	\label{pf:threshold}
		% \end{proof}

		% Once the optimal number of decision threshold is determined, we can first discretize the output energy level into numerous bins, then obtain the optimal decision regions that maximizes the total backscatter rate by \gls{dp} accelerated by \gls{smawk} algorithm \cite{He2021}.
	\end{subsection}
\end{section}

\begin{section}{Simulation Results}
	% TODO add distribution to initializer to smooth curves?
	% TODO compare PGD and primary-MRT beamformers
	In this section, we provide numerical results to evaluate the proposed input, beamforming and decision design over a single-user multi-node Metascatter-enabled network.
	We assume the distance between \gls{ap} and user is \qty{10}{\meter}, and $K=2$ Metascatters are uniformly dropped within a disk centered at the user of radius \qty{1}{\meter}.
	% The carrier frequency is $f=\qty{200}{\MHz}$, and we consider \gls{iid} Ricean fading for all channels.
	The carrier frequency is $f=\qty{200}{\MHz}$, and we consider \gls{iid} Ricean fading between all terminals.
	For direct, forward and backward links, we set the path loss exponents to \num{2.6}, \num{2.4} and \num{2}, and the Ricean factor to \num{5}, \num{5} and \num{10}, respectively.
	% For direct, forward and backward links, we choose path loss exponents \num{2.6}, \num{2.4} and \num{2}, and Ricean factor \num{5}, \num{5} and \num{10}, respectively.
	% and the path loss exponents for direct, forward and backward links are \num{2.6}, \num{2.4} and \num{2}, respectively.
	% We consider \gls{iid} Ricean fading for all channels with Ricean factor set to \num{5}, \num{5} and \num{10}
	The \gls{ap} has $Q=4$ antennas with maximum average transmit power $P=\qty{36}{\dBm}$.
	All nodes have amplitude reflect ratio $\alpha=0.5$, symbol period ratio $N=20$, and perform \gls{qam} with $M=2$ input states.
	% and we consider amplitude reflect ratio $\alpha=0.5$ and symbol period ratio $N=20$.
	% The user has a receive antenna gain of \qty{3}{\dBi} and average noise power
	The user is with average noise power $\sigma_v^2=\qty{70}{\dBm}$ and receive antenna gain \qty{3}{\dBi}.
	All rate regions are averaged over at least \num{1000} instances, where ``PSP'' and ``BSP'' means primary and backscatter symbol periods, respectively.
	We choose decision design by \gls{smawk} \cite{He2021} as reference, and select discretize boundaries uniformly over the \qty{95}{\percent} confidence region of edge hypotheses.
	The parameters remain fixed unless otherwise specified.

	\begin{subsection}{Input Distribution vs. Weight}
		\begin{figure}[!t]
			\centering
			\subfloat[Instance 1\label{fi:distribution_weights_1}]{
				\resizebox{0.48\columnwidth}{!}{
					\input{assets/simulation/distribution_weights_1.tex}
				}
			}
			\subfloat[Instance 2\label{fi:distribution_weights_2}]{
				\resizebox{0.48\columnwidth}{!}{
					\input{assets/simulation/distribution_weights_2.tex}
				}
			}
			\caption{Typical input distributions vs. weight $\rho$ for a Metascatter with $M=4$ inputs.}
			\label{fi:distribution_weights}
		\end{figure}
		% We consider a single Metascatter with $M=4$ inputs in this case of study.
		In Fig. \ref{fi:distribution_weights}, we present typical input distributions of a single Metascatter with $M=4$ inputs under different weight $\rho$.
		Fig. \subref*{fi:distribution_weights_1} and \subref*{fi:distribution_weights_2} are obtained from \gls{iid} drop and channel realizations.
		We note that even for $\rho=0$ (i.e., best backscatter performance), the optimal input distribution is not equiprobable like \gls{sr}, and adaptive channel coding can further increase total backscatter rate based on \gls{csi}.
		On the other hand, the optimal input distribution becomes fully deterministic at $\rho=1$ (i.e., best primary performance), where the state maximizes equivalent primary channel \eqref{eq:equivalent_channel} strength is chosen with probability \num{1}.
		In this case, Metascatter boils down to an \gls{ris} element with $M$ discrete states.
		As $\rho$ moves from \num{0} to \num{1}, the optimal input distribution becomes gradually biased to one state and flexibly balances the primary-backscatter tradeoff.
	\end{subsection}

	\begin{subsection}{Rate Region vs. Input, Beamforming, and Decision Schemes}
		\begin{figure}[!t]
			\centering
			\subfloat[Input Distribution\label{fi:region_distribution}]{
				\resizebox{0.48\columnwidth}{!}{
					\input{assets/simulation/region_distribution.tex}
				}
			}
			\subfloat[Decision Threshold\label{fi:region_threshold}]{
				\resizebox{0.48\columnwidth}{!}{
					\input{assets/simulation/region_threshold.tex}
				}
			}
			\caption{Average primary-(total-)backscatter rate regions for different input distribution and decision threshold schemes.}
		\end{figure}
		Fig. \subref*{fi:region_distribution} compares the achievable rate regions by following input designs.
		\begin{itemize}
			% \item ``Exhaustion'' means $K$-dimensional grid search over probability simplex;
			% \item ``\gls{kkt}'' corresponds to Algorithm \ref{al:input_distribution};
			% \item ``Cooperation'' assumes backscatter cooperation/joint encoding at all Metascatters, and employs Blahut-Arimoto algorithm \cite{Arimoto1972,Blahut1972a} to determine \emph{tuple} input distribution;
			\item \textbf{Exhaustion:} $K$-dimensional grid search over probability simplex;
			\item \textbf{\gls{kkt}:} results of Algorithm \ref{al:input_distribution};
					% \item \textbf{Cooperation:} with backscatter cooperation/joint encoding at all Metascatters, Blahut-Arimoto algorithm \cite{Arimoto1972,Blahut1972a} for \emph{tuple} input distribution;
					% \item \textbf{Cooperation:} backscatter cooperation/joint encoding at all Metascatters, \emph{tuple input distribution} by Blahut-Arimoto algorithm \cite{Arimoto1972,Blahut1972a};
					% \item \textbf{Cooperation:} with backscatter cooperation (i.e., joint encoding) at all Metascatters, \emph{tuple input distribution} by Blahut-Arimoto algorithm \cite{Arimoto1972,Blahut1972a};
			\item \textbf{Cooperation:} backscatter cooperation/joint encoding at all Metascatters, tuple input distribution/joint probability array optimization by Blahut-Arimoto algorithm \cite{Arimoto1972,Blahut1972a};
					% with backscatter cooperation (i.e., joint encoding) at all Metascatters, \emph{tuple input distribution} by Blahut-Arimoto algorithm \cite{Arimoto1972,Blahut1972a};
			\item \textbf{Marginalization:} marginal distributions of joint probability array;
			\item \textbf{Decomposition:} normalized tensors of rank-1 \gls{cp} decomposition of joint probability array;
			\item \textbf{Randomization:} Gaussian recovery from joint probability array \cite{Calvo2010}.
		\end{itemize}

		We notice adaptive joint encoding at all Metascatters provides the outer bound of rate region.
		However, it involves arbitrarily dependent codewords, and backscatter cooperation between passive nodes is generally unaffordable.
		In contrast, the rate region of \gls{kkt} input design in Algorithm \ref{al:input_distribution} approaches that of exhaustive search, and the loss is negligible for $K=2$.
		% Although the randomization method \cite{Calvo2010} achieves similar performance, the computational complexity is much higher as it involves solving $K+1$ linear programming problems
		Although the randomization method \cite{Calvo2010} returns similar rate region, it requires solving $K+1$ linear programming problems before applying Gaussian recovery.
		The marginal distribution is slightly worse than \gls{kkt} despite having the same computational complexity, while the approximation from \gls{cp} decomposition is unsatisfying.

		% TODO: beamforming

		Fig. \subref*{fi:region_threshold} compares the achievable rate region by following threshold schemes.
		\begin{itemize}
			\item \textbf{\gls{dp}:} sequential quantizer grouping by dynamic programming \cite{He2021};
			\item \textbf{\gls{smawk}:} above accelerated by \gls{smawk} algorithm;
			\item \textbf{Bisection:} sequential bisection threshold design \cite{Nguyen2020a};
			\item \textbf{\gls{ml}:} maximum likelihood decision \eqref{eq:detection_threshold_maximum_likelihood} \cite{Qian2019}.
		\end{itemize}

		We observe that input-adaptive threshold designs achieve higher total backscatter rate than \gls{ml}.
		This is because the decision regions can be flexibly adjusted to enhance the capacity of \gls{dtmac} \eqref{eq:dtmac}.
		For example, the tuples with negligible input probability should have narrower decision regions than those frequently employed, in order to improve detection performance.
		It emphasizes the importance of joint input distribution and decision region design.

		% We note that ideal joint adaptive encoding at all Metascatters can further boost the total backscatter rate.
		% However, this ideal upper bound requires real-time feedback
		% ``Exhaustion'' means $K$-dimensional grid search over probability simplex, ``KKT'' corresponds to Algorithm \ref{ap:input_kkt_solution}, ``Cooperation'' assumes full backscatter cooperation and joint encoding at all Metascatters
	\end{subsection}


	\begin{subsection}{Rate Region vs. System Configuration}
		\begin{figure}[!t]
			\centering
			\subfloat[Metscatter Nodes\label{fi:region_tags}]{
				\resizebox{0.48\columnwidth}{!}{
					\input{assets/simulation/region_tags.tex}
				}
			}
			\subfloat[Input States\label{fi:region_states}]{
				\resizebox{0.48\columnwidth}{!}{
					\input{assets/simulation/region_states.tex}
				}
			}
			\\
			\subfloat[Transmit Antennas\label{fi:region_txs}]{
				\resizebox{0.48\columnwidth}{!}{
					\input{assets/simulation/region_txs.tex}
				}
			}
			\subfloat[Scatter Ratio\label{fi:region_scatter}]{
				\resizebox{0.48\columnwidth}{!}{
					\input{assets/simulation/region_scatter.tex}
				}
			}
			\caption{Average primary-(total-)backscatter rate regions.}
			\label{fi:region_config_1}
		\end{figure}

		% Fig. \ref{fi:region_config_1} reveals the impact of Metascatter nodes, input states, transmit antennas and scatter ratio on the achievable rate region.
		We present in \ref{fi:region_config_1} the impact of Metascatter nodes, input states, transmit antennas and scatter ratio on the achievable rate region.
		For the specified scenario, Fig. \subref*{fi:region_tags} shows the total backscatter rate almost scales proportionally with the number of Metascatter nodes, and the decrease of individual backscatter rate is unobvious.
		Besides, we conclude from \subref*{fi:region_states} that increasing the reflection states has a marginal effect on both primary and backscatter rates.
		Those two facts motivates the use of numerous elementary/uncomplicated backscatter nodes, instead of high-order transponders or programmable high-resolution surfaces.
		Figs. \subref*{fi:region_txs} and \subref*{fi:region_scatter} also prove increasing transmit antennas or scatter ratio can improve both primary and backscatter performance.

		\begin{figure}[!t]
			\centering
			\subfloat[Node Coverage\label{fi:region_coverage}]{
				\resizebox{0.48\columnwidth}{!}{
					\input{assets/simulation/region_coverage.tex}
				}
			}
			\subfloat[Symbol Period Ratio\label{fi:region_duration}]{
				\resizebox{0.48\columnwidth}{!}{
					\input{assets/simulation/region_duration.tex}
				}
			}
			\\
			\subfloat[Carrier Frequency\label{fi:region_frequency}]{
				\resizebox{0.48\columnwidth}{!}{
					\input{assets/simulation/region_frequency.tex}
				}
			}
			\subfloat[Average Noise Power\label{fi:region_noise}]{
				\resizebox{0.48\columnwidth}{!}{
					\input{assets/simulation/region_noise.tex}
				}
			}
			\caption{Average primary-(total-)backscatter rate regions.}
			\label{fi:region_config_2}
		\end{figure}

		Fig. \subref*{fi:region_coverage} shows the tradeoff between coverage disk radius $r$ and achievable rate region.
		When nodes are far from the user, both primary and backscatter rates decrease due to the product pass loss of forward and backward channels.
		Under the assumption of ideal backscatter decoding and re-encoding, Fig. \subref*{fi:region_duration} suggests using lower symbol period ratio $N$ can boost total backscatter rate per primary symbol.
		However, it requires more frequent detection and re-encoding at the user to maintain the primary rate.
		When $N$ becomes sufficiently large, total backscatter rate approaches \num{0} and Metascatters boil down to conventional \gls{ris} elements with fixed reflection patterns during whole channel block.
		In Fig. \subref*{fi:region_frequency}, we observe that passive Metascatter achieves higher backscatter rate at lower carrier frequency because of preferable propagation loss.
		Finally, \subref*{fi:region_noise} prove the performance of energy detection is robust for a wide range of noise power.
	\end{subsection}
\end{section}

\begin{section}{Conclusion}
	This paper introduced Metascatter that adapts input distribution of passive backscatter nodes to simultaneously transmit and assist over existing wireless systems.
	Starting from backscatter principles, we showed how Metascatters bridges and generalizes parasitic source of \gls{sr} and reflecting element of \gls{ris} via smart input design.
	An application scenario was considered where multiple Metascatters ride over a point-to-point transmission to simultaneously encode self message and perform passive beamforming.
	To characterize achievable primary-backscatter rate region, we proposed a \gls{bcd} algorithm that evaluates \gls{kkt} input distribution in closed form, optimizes active beamforming by \gls{pgd}, and refines decision regions by existing methods.
	Numerical results demonstrated the advantage of adaptive node input distribution design for both primary and backscatter subsystems.

	One particular interesting question is how to design Metascatters in a multi-user system.
	If one node can contribute to and be decoded by multiple users, its input distribution may be further adjusted to mimic multi-beam gain of dynamic beamforming \cite{Qiu2022}.
\end{section}

\begin{appendix}
	\begin{subsection}{Proof of Proposition \ref{pr:input_kkt_condition}}
		Denote the Lagrange multipliers associated with \eqref{co:sum_probability} and \eqref{co:nonnegative_probability} as $\{\nu_k\}_{k \in \mathcal{K}}$ and $\{\lambda_{k,m_k}\}_{k \in \mathcal{K},m_k \in \mathcal{M}}$, respectively.
		The Lagrangian function of problem \eqref{op:input_distribution} is
		\begin{align}
			% L(\{\boldsymbol{p}_k\}_{k \in \mathcal{K}},\{\nu_k\},\{\lambda_{k,m_k}\})
			L
			%  & = - I(x_{\mathcal{K}}) + \sum_{k \in \mathcal{K}} \nu_k \left( \sum_{m_k \in \mathcal{M}} P_k(x_{m_k}) - 1 \right)\nonumber \\
			 & = - I(x_{\mathcal{K}}) + \sum_k \nu_k \left( \sum_{m_k \in \mathcal{M}} P_k(x_{m_k}) - 1 \right)\nonumber \\
			%  & \quad - \sum_{k \in \mathcal{K}} \sum_{m_k \in \mathcal{M}} \lambda_{k,m_k} P_k(x_{m_k}),
			 & \quad - \sum_k \sum_{m_k} \lambda_{k,m_k} P_k(x_{m_k}),
		\end{align}
		% and the \gls{kkt} conditions on the optimal primal and dual variables are, $\forall m_k \in \mathcal{M}$ and $\forall k \in \mathcal{K}$,
		% and the \gls{kkt} conditions are, $\forall m_k \in \mathcal{M}$ and $\forall k \in \mathcal{K}$,
		and the \gls{kkt} conditions are, $\forall k,m_k$,
		\begin{subequations}
			\label{eq:input_kkt_condition_original}
			\begin{equation}
				- \nabla_{P_k^\star(x_{m_k})} I^\star(x_{\mathcal{K}}) + \nu_k^\star - \lambda_{k,m_k}^\star = 0,
			\end{equation}
			\begin{equation}
				\lambda_{k,m_k}^\star = 0, \quad P_k^\star(x_{m_k}) > 0,
			\end{equation}
			\begin{equation}
				\lambda_{k,m_k}^\star \ge 0, \quad P_k^\star(x_{m_k}) = 0.
			\end{equation}
		\end{subequations}
		The directional derivative can be explicitly expressed as
		\begin{equation}
			\nabla_{P_k^\star(x_{m_k})} I^\star(x_{\mathcal{K}}) = I_k^\star(x_{m_k}) - (1 - \rho).
			\label{eq:input_directional_derivative}
		\end{equation}
		Combining \eqref{eq:input_kkt_condition_original} and \eqref{eq:input_directional_derivative}, we have
		\begin{subequations}
			\label{eq:input_kkt_condition_transformed}
			\begin{alignat}{2}
				I_k^\star(x_{m_k}) & = \nu_k^\star + (1 - \rho), \quad   &  & P_k^\star(x_{m_k}) > 0,\label{eq:probable_states_marginal} \\
				I_k^\star(x_{m_k}) & \le \nu_k^\star + (1 - \rho), \quad &  & P_k^\star(x_{m_k}) = 0,\label{eq:dropped_states_marginal}
			\end{alignat}
		\end{subequations}
		which suggests
		\begin{equation}
			\sum_{m_k} P_k^\star(x_{m_k}) I_k^\star(x_{m_k}) = \nu_k^\star + (1 - \rho).
			\label{eq:input_kkt_condition_implied}
		\end{equation}
		On the other hand, by definition of weighted sum marginal information \eqref{eq:weighted_sum_marginal_information},
		\begin{equation}
			\sum_{m_k} P_k^\star(x_{m_k}) I_k^\star(x_{m_k}) = I^\star(x_{\mathcal{K}}),
			\label{eq:weighted_sum_marginal_information_implied}
		\end{equation}
		where the right-hand side is irrelevant to $k$.
		\eqref{eq:input_kkt_condition_transformed}, \eqref{eq:input_kkt_condition_implied}, and \eqref{eq:weighted_sum_marginal_information_implied} together complete the proof.
		\label{ap:input_kkt_condition}
	\end{subsection}

	\begin{subsection}{Proof of Proposition \ref{pr:input_kkt_solution}}
		We first prove sequence \eqref{eq:input_kkt_solution} is non-decreasing in weighted sum mutual information.
		Let $P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) = \prod_{q \in \mathcal{K}} P_q(x_{m_q})$ and $P_{\mathcal{K}}'(x_{m_{\mathcal{K}}}) = P_k'(x_{m_k}) \prod_{q \in \mathcal{K} \setminus \{k\}} P_q(x_{m_q})$ be two probability distributions with potentially different marginal for tag $k \in \mathcal{K}$ at state $m_k \in \mathcal{M}$, and define an intermediate function $J \left( P_{\mathcal{K}}(x_{m_{\mathcal{K}}}),P_{\mathcal{K}}'(x_{m_{\mathcal{K}}}) \right)$ as \eqref{eq:intermediate_information_function} at the end of page \pageref{eq:intermediate_information_function}.
		\begin{figure*}[!b]
			\hrule
			% \begin{equation}
			% 	J \left( P_{\mathcal{K}}(x_{m_{\mathcal{K}}}),P_{\mathcal{K}}'(x_{m_{\mathcal{K}}}) \right) \triangleq \rho \sum_{m_{\mathcal{K}}} P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) \log \left(1 + \frac{\lvert \boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}}) \boldsymbol{w} \rvert^2}{\sigma_v^2}\right) + (1 - \rho) \sum_{m_{\mathcal{K}}} P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) \sum_{m_{\mathcal{K}}'} P(\hat{x}_{m_{\mathcal{K}}'}|x_{m_{\mathcal{K}}}) \log \frac{P(\hat{x}_{m_{\mathcal{K}}'}|x_{m_{\mathcal{K}}}) P_{\mathcal{K}}'(x_{m_{\mathcal{K}}})}{P'(\hat{x}_{m_{\mathcal{K}}'}) P_{\mathcal{K}}(x_{m_{\mathcal{K}}})}.
			% 	\label{eq:intermediate_information_function}
			% \end{equation}
			\begin{align}
				J \left( P_{\mathcal{K}}(x_{m_{\mathcal{K}}}),P_{\mathcal{K}}'(x_{m_{\mathcal{K}}}) \right)
				 & \triangleq \rho \sum_{m_{\mathcal{K}}} P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) \log \left(1 + \frac{\lvert \boldsymbol{h}_{\mathrm{E}}^H(x_{m_{\mathcal{K}}}) \boldsymbol{w} \rvert^2}{\sigma_v^2}\right)\nonumber                                                                                                                    \\
				 & \quad + (1 - \rho) \sum_{m_{\mathcal{K}}} P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) \sum_{m_{\mathcal{K}}'} P(\hat{x}_{m_{\mathcal{K}}'}|x_{m_{\mathcal{K}}}) \log \frac{P(\hat{x}_{m_{\mathcal{K}}'}|x_{m_{\mathcal{K}}}) P_{\mathcal{K}}'(x_{m_{\mathcal{K}}})}{P'(\hat{x}_{m_{\mathcal{K}}'}) P_{\mathcal{K}}(x_{m_{\mathcal{K}}})}.
				\label{eq:intermediate_information_function}
			\end{align}
		\end{figure*}
		It is straightforward to verify $J \left( P_{\mathcal{K}}(x_{m_{\mathcal{K}}}),P_{\mathcal{K}}(x_{m_{\mathcal{K}}}) \right) = I(x_{\mathcal{K}})$ and $J \left( P_{\mathcal{K}}(x_{m_{\mathcal{K}}}),P_{\mathcal{K}}'(x_{m_{\mathcal{K}}}) \right)$ is a concave function for a fixed $P_{\mathcal{K}}'(x_{m_{\mathcal{K}}})$.
		By choosing $\nabla_{P_k^\star(x_{m_k})} J \left( P_{\mathcal{K}}(x_{m_{\mathcal{K}}}),P_{\mathcal{K}}'(x_{m_{\mathcal{K}}}) \right) = 0$, we have
		\begin{equation}
			S_k'(x_{m_k}) - S_k'(x_{i_k}) + (1 - \rho) \log \frac{P_k(x_{i_k})}{P_k^\star(x_{m_k})} = 0,
			\label{eq:optimal_intermediate_information_condition}
		\end{equation}
		where $i_k \ne m_k$ is the reference state and
		\begin{align}
			S_k'(x_{m_k})
			 & \triangleq I_k'(x_{m_k}) + (1 - \rho) \sum_{m_{\mathcal{K} \setminus \{k\}}} P_{\mathcal{K} \setminus \{k\}}(x_{m_{\mathcal{K} \setminus \{k\}}})\nonumber \\
			 & \quad \times \sum_{m_{\mathcal{K}}'} P(\hat{x}_{m_{\mathcal{K}}'}|x_{m_{\mathcal{K}}}) \log P_{\mathcal{K}}'(x_{m_{\mathcal{K}}}).
		\end{align}
		Evidently, $\forall m_k \ne i_k$, \eqref{eq:optimal_intermediate_information_condition} boils down to
		\begin{equation}
			P_k^\star(x_{m_k}) = \frac{P_k'(x_{m_k}) \exp \left( \frac{\rho}{1 - \rho} I_k'(x_{m_k}) \right)}{\sum_{m_k'} P_k'(x_{m_k'}) \exp \left( \frac{\rho}{1 - \rho} I_k'(x_{m_k'}) \right)}.
			\label{eq:optimal_relative_distribution}
		\end{equation}
		We also notice $P_k(x_{i_k}) = 1 - \sum_{m_k \ne i_k} P_k^\star(x_{m_k})$ has exactly the same expression as \eqref{eq:optimal_relative_distribution}.
		% We also notice $P_k(x_{i_k}) = 1 - \sum_{m_k \ne i_k} P_k^\star(x_{m_k})$ is in the same expression as \eqref{eq:optimal_relative_distribution}.
		Therefore, the result is irrelevant to the choice of reference state, and \eqref{eq:optimal_relative_distribution} is indeed optimal $\forall m_k \in \mathcal{M}$.
		% It implies the selection of reference state does not matter and \eqref{eq:optimal_relative_distribution} is indeed optimal $\forall m_k \in \mathcal{M}$.
		That is, for a fixed $P_{\mathcal{K}}'(x_{m_{\mathcal{K}}})$, choosing $P_k(x_{m_k})$ by \eqref{eq:optimal_relative_distribution} ensures
		\begin{equation}
			J \left( P_{\mathcal{K}}(x_{m_{\mathcal{K}}}),P_{\mathcal{K}}'(x_{m_{\mathcal{K}}}) \right) \ge I'(x_{\mathcal{K}}).
			\label{eq:information_difference_lower}
		\end{equation}
		On the other hand, it also guarantees
		\begin{subequations}
			\label{eq:information_difference_upper}
			\begin{align}
				\Delta
				 & \triangleq I(x_{\mathcal{K}}) - J \left( P_{\mathcal{K}}(x_{m_{\mathcal{K}}}),P_{\mathcal{K}}'(x_{m_{\mathcal{K}}}) \right)                                                                                \\
				 & = (1 - \rho) \sum_{m_k} \frac{P_k'(x_{m_k}) f_k'(x_{m_k})}{\sum_{m_k'} P_k'(x_{m_k'}) f_k'(x_{m_k'})} \sum_{m_{\mathcal{K}}''} P(\hat{x}_{m_{\mathcal{K}}''}|x_{m_k})\nonumber                             \\
				 & \quad \times \log \frac{\sum_{m_k'} P_k'(x_{m_k'}) P(\hat{x}_{m_{\mathcal{K}}''}|x_{m_k'}) f_k'(x_{m_k})}{\sum_{m_k'} P_k'(x_{m_k'}) P(\hat{x}_{m_{\mathcal{K}}''}|x_{m_k'}) f_k'(x_{m_k'})}               \\
				 & \ge (1 - \rho) \sum_{m_k} \frac{P_k'(x_{m_k}) f_k'(x_{m_k})}{\sum_{m_k'} P_k'(x_{m_k'}) f_k'(x_{m_k'})} \sum_{m_{\mathcal{K}}''} P(\hat{x}_{m_{\mathcal{K}}''}|x_{m_k})\nonumber                           \\
				 & \quad \times \left( 1 - \frac{\sum_{m_k'} P_k'(x_{m_k'}) P(\hat{x}_{m_{\mathcal{K}}''}|x_{m_k'}) f_k'(x_{m_k'})}{\sum_{m_k'} P_k'(x_{m_k'}) P(\hat{x}_{m_{\mathcal{K}}''}|x_{m_k'}) f_k'(x_{m_k})} \right) \\
				 & = 0,
			\end{align}
		\end{subequations}
		where $f_k'(x_{m_k}) \triangleq \exp \left( \frac{\rho}{1 - \rho} I_k'(x_{m_k}) \right)$ and the equality holds if and only if \eqref{eq:optimal_relative_distribution} converges.
		\eqref{eq:information_difference_lower} and \eqref{eq:information_difference_upper} together imply $I(x_{\mathcal{K}}) \ge I'(x_{\mathcal{K}})$.
		Since mutual information is bounded above, we conclude the sequence \eqref{eq:input_kkt_solution} is non-decreasing and convergent in mutual information.

		Next, we prove any converging point of sequence \eqref{eq:input_kkt_solution}, denoted as $P_k^\star(x_{m_k})$, fulfills \gls{kkt} conditions \eqref{eq:input_kkt_condition}.
		% Next, we prove that sequence \eqref{eq:input_kkt_solution} fulfills \gls{kkt} conditions \eqref{eq:input_kkt_condition} on convergence.
		% To see this, recall $P_k^{(0)}(x_{m_k}) > 0$ and define
		To see this, define
		% To see this, we define
		\begin{equation}
			D_k^{(r)}(x_{m_k}) \triangleq \frac{P_k^{(r+1)}(x_{m_k})}{P_k^{(r)}(x_{m_k})} = \frac{f_k^{(r)}(x_{m_k})}{\sum_{m_k'} P_k^{(r)}(x_{m_k'}) f_k^{(r)}(x_{m_k'})}.
		\end{equation}
		As sequence \eqref{eq:input_kkt_solution} is convergent, any state with $P_k^\star(x_{m_k}) > 0$ need to satisfy $D_k^\star(x_{m_k}) \triangleq \lim_{r \to \infty} D_k^{(r)}(x_{m_k}) = 1$, namely
		\begin{equation}
			I_k^\star(x_{m_k}) = \frac{1 - \rho}{\rho} \log \sum_{m_k'} P_k^\star(x_{m_k'}) f_k^\star(x_{m_k'}),
		\end{equation}
		which is reminiscent of \eqref{eq:probable_states_marginal} and \eqref{eq:probable_states}.
		That is to say, given $P_k^{(0)}(x_{m_k}) > 0$, any converging point with $P_k^\star(x_{m_k}) > 0$ must satisfy \eqref{eq:probable_states}.
		On the other hand, we assume $P_k^\star(x_{m_k})$ does not satisfy \eqref{eq:dropped_states}, such that for any state with $P_k^\star(x_{m_k}) = 0$,
		% On the other hand, we show if $P_k^\star(x_{m_k})$ does not satisfy \eqref{eq:dropped_states}, then it is not a converging point of sequence \eqref{eq:input_kkt_solution}. By this assumption, for any state with $P_k^\star(x_{m_k}) = 0$,
		\begin{equation}
			I_k^\star(x_{m_k}) > I^\star(x_{\mathcal{K}}) = \sum_{m_k'} P_k^\star(x_{m_k'}) I_k^\star(x_{m_k'}),
		\end{equation}
		where the equality inherits from \eqref{eq:weighted_sum_mutual_information}.
		Since exponential function is monotonically increasing, we have $f_k^\star(x_{m_k}) > \sum_{m_k'} P_k^\star(x_{m_k'}) f_k^\star(x_{m_k'})$ and $D_k^\star(x_{m_k}) > 1$.
		Considering $P_k^{(0)}(x_{m_k}) > 0$ and $P_k^\star(x_{m_k}) = 0$, it contradicts with
		\begin{equation}
			P_k^{(r)}(x_{m_k}) = P_k^{(0)}(x_{m_k}) \prod_{n=1}^r D_k^{(n)}(x_{m_k}).
		\end{equation}
		Therefore, given $P_k^{(0)}(x_{m_k}) > 0$, any converging point with $P_k^\star(x_{m_k}) = 0$ must satisfy \eqref{eq:dropped_states}.
		This completes the proof.
		\label{ap:input_kkt_solution}
	\end{subsection}

	% \begin{subsection}{Proof of Proposition \ref{pr:threshold}}
	% 	Since $L$ input letters are with non-zero probability and $x \to z \to \hat{x}$ formulates a Markov chain, we need $L$ non-empty decision regions and at least $L+1$ distinct thresholds (including \num{0} and $\infty$) to minimize the distortion between source and decision.
	% 	On the other hand, the optimal decision regions are apparently empty for those unused letters.

	% 	Suppose the optimal number of thresholds is $S+1$ where $S \ge L$.
	% 	Let $\boldsymbol{t} \triangleq [t_0,\ldots,t_S]^T \in \mathbb{R}_{+}^{(S+1) \times 1}$ be the optimal threshold vector where $t_{s-1} < t_s$, $\forall s \in \mathcal{S} \triangleq \{1,\ldots,S\}$.
	% 	Since the optimal decision region for any letter may consist of multiple partitions, without loss of generality, we assume the mapping from threshold vector to decision region $l' \in \mathcal{L} \triangleq \{1,\ldots,L\}$ is given by $\mathcal{R}_{l'} = \bigcup_{s \equiv l' \pmod L} [t_{s-1},t_s)$.
	% 	\begin{footnote}
	% 		The proof holds for any valid mapping from threshold vector to decision regions, and we consider this specific case for the ease of presentation.
	% 	\end{footnote}
	% 	The threshold optimization problem is
	% 	\begin{maxi!}
	% 		{\scriptstyle{\boldsymbol{t}}}{I_{\mathrm{B}}(x;\hat{x})}{\label{op:decision_threshold}}{\label{ob:backscatter_mutual_information}}
	% 		\addConstraint{t_{s-1}}{< t_s,}{\quad \forall s \in \mathcal{S}.}{\label{co:strict_inequality}}
	% 	\end{maxi!}

	% 	Problem \eqref{op:decision_threshold} is intricate due to the strict inequality constraint \eqref{co:strict_inequality}.
	% 	Following \cite{Nguyen2020}, we first relax it to the convex counterpart, then discard the solutions that violate any original constraint.
	% 	The Lagrangian function for the relaxed problem is
	% 	\begin{equation}
	% 		L = - I_{\mathrm{B}}(x;\hat{x}) + \sum_{s \in \mathcal{S}} \mu_s (t_{s-1} - t_s),
	% 	\end{equation}
	% 	where $\mu_s$ is the Lagrange multiplier associated with the non-strict version of \eqref{co:strict_inequality}.
	% 	The \gls{kkt} conditions on the optimal primal and dual solutions are, $\forall s \in \mathcal{S}$,
	% 	\begin{subequations}
	% 		\label{eq:kkt_thresholding}
	% 		\begin{equation}
	% 			- \nabla_{t_s^\star} I^\star_{\mathrm{B}}(x;\hat{x}) + \mu_{s-1}^\star - \mu_s^\star = 0,
	% 			\label{eq:stationarity}
	% 		\end{equation}
	% 		\begin{equation}
	% 			\mu_s^\star \ge 0,
	% 			\label{eq:dual_feasibility}
	% 		\end{equation}
	% 		\begin{equation}
	% 			\mu_s^\star (t_{s-1}^\star - t_s^\star) = 0.
	% 			\label{eq:complementary_slackness}
	% 		\end{equation}

	% 	\end{subequations}
	% 	Due to the strict inequality constraint \eqref{co:strict_inequality}, conditions \eqref{eq:dual_feasibility} and \eqref{eq:complementary_slackness} together imply $\mu_s^\star = 0$, $\forall s \in \mathcal{S}$.
	% 	Besides, it is trivial to conclude $t_0^\star = 0$ for energy-based detection.
	% 	As such, the necessary optimality conditions for problem \eqref{op:decision_threshold}, $\forall s \in \mathcal{S}$,
	% 	\begin{equation}
	% 		\nabla_{t_{s}^\star} I^\star_{\mathrm{B}}(x;\hat{x}) = 0,
	% 	\end{equation}
	% 	which can be explicitly written as, $\forall s \equiv l' \pmod L$,
	% 	\begin{equation}
	% 		\sum_l P(x_l) \frac{(t_s^\star)^{N-1} \exp{-t_s^\star/\sigma_l^2}}{\sigma_l^{2N} (N-1)!} \log \frac{P(x_l|\hat{x}_{l'+1})}{P(x_l|\hat{x}_{l'})} = 0,
	% 		\label{eq:kkt_threshold_explicit}
	% 	\end{equation}

	% 	According to \cite{He2021}, the optimal backward channel quantizer is convex and separates each pair of posterior distribution by a hyperplane.
	% 	It implies, for a given output letter $l'$, the sequence $\{\log {P(x_l|\hat{x}_{l'+1})}/{P(x_l|\hat{x}_{l'})}\}_{l \in \mathcal{L}}$ changes sign exactly once.
	% 	We notice the left-hand side of \eqref{eq:kkt_threshold_explicit} is a generalized Dirichlet polynomial, and by Descartes' rule of signs \cite{Jameson2006}, has at most one positive solution.
	% 	% TODO
	% 	In other words, starting from $t_0^\star$, each optimal decision region requires at most one additional distinct threshold, and we have $S \le L$.
	% 	Therefore, we conclude $S = L$ and the proof is completed.
	% 	\qedsymbol
	% 	\label{ap:threshold}
	% \end{subsection}
\end{appendix}


\bibliographystyle{IEEEtran}
\bibliography{library.bib}
\end{document}
