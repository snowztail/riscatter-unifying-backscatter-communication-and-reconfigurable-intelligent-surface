\documentclass[journal]{IEEEtran}

\usepackage{adjustbox}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{array}
\usepackage{circuitikz}
\usepackage{cite}
\usepackage{colortbl}
\usepackage{environ}
\usepackage{grffile}
\usepackage{hyperref}
\usepackage{import}
\usepackage{mathtools}
\usepackage{microtype}
\usepackage{multirow}
\usepackage{pgffor}
\usepackage{pgfplots}
\usepackage{physics}
\usepackage{siunitx}
\usepackage{stfloats}
\usepackage{tikz}
\usepackage{url}
\usepackage{xcolor}
\usepackage[acronym]{glossaries-extra}
\usepackage[T1]{fontenc}
\usepackage[caption=false,font=footnotesize,subrefformat=parens,labelformat=parens]{subfig}
\usepackage[short]{optidef}
% \usepackage[subtle]{savetrees}

\listfiles
\interdisplaylinepenalty=2500
\pgfplotsset{compat=newest}
\usepgfplotslibrary{patchplots}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}
\newtheorem{theorem}{Theorem}
\DeclareSIUnit{\belm}{Bm}
\DeclareSIUnit{\dBm}{\deci\belm}
\DeclareSIUnit{\beli}{Bi}
\DeclareSIUnit{\dBi}{\deci\beli}
\ctikzset{american}
\usetikzlibrary{arrows,calc,matrix,patterns,positioning}

\DeclarePairedDelimiterX{\infdivx}[2]{(}{)}{%
	#1\;\delimsize\|\;#2%
}
\newcommand{\infdiv}{D\infdivx}

\makeatletter
\tikzset{
	block/.style={draw,rectangle,align=center},
    from/.style args={#1 to #2}{
        above right={0cm of #1},
        /utils/exec=\pgfpointdiff
            {\tikz@scan@one@point\pgfutil@firstofone(#1)\relax}
            {\tikz@scan@one@point\pgfutil@firstofone(#2)\relax},
        minimum width/.expanded=\the\pgf@x,
        minimum height/.expanded=\the\pgf@y
	}
}
\makeatother

\algrenewcommand{\algorithmicwhile}{\textbf{While}}
\algrenewcommand{\algorithmicif}{\textbf{If}}
\algrenewcommand{\algorithmicthen}{\textbf{Then}}
\algrenewcommand{\algorithmicelse}{\textbf{Else}}
\algrenewcommand{\algorithmicend}{\textbf{End}}
\algrenewcommand{\algorithmicrepeat}{\textbf{Repeat}}
\algrenewcommand{\algorithmicuntil}{\textbf{Until}}

\setabbreviationstyle[acronym]{long-short}

\newacronym{ambc}{AmBC}{Ambient Backscatter Communications}
\newacronym{ap}{AP}{Access Point}
\newacronym{awgn}{AWGN}{Additive White Gaussian Noise}
\newacronym{bcd}{BCD}{Block Coordinate Descent}
\newacronym{bibo}{BIBO}{Binary-Input Binary-Output}
\newacronym{bpcu}{\si{bpcu}}{bit per channel use}
\newacronym{bpsphz}{\si{bps/Hz}}{bit per second per Hertz}
\newacronym{cscg}{CSCG}{Circularly Symmetric Complex Gaussian}
\newacronym{csi}{CSI}{Channel State Information}
\newacronym{dmc}{DMC}{Discrete Memoryless Channel}
\newacronym{dmtc}{DMTC}{Discrete Memoryless Thresholding Channel}
\newacronym{irs}{IRS}{Intelligent Reflecting Surface}
\newacronym{kkt}{KKT}{Karush–Kuhn–Tucker}
\newacronym{mac}{MAC}{Multiple Access Channel}
\newacronym{mc}{MC}{Multiplication Coding}
\newacronym{ml}{ML}{Maximum-Likelihood}
\newacronym{psk}{PSK}{Phase Shift Keying}
\newacronym{qam}{QAM}{Quadrature Amplitude Modulation}
\newacronym{rf}{RF}{Radio Frequency}
\newacronym{sc}{SC}{Superposition Coding}
\newacronym{sic}{SIC}{Successive Interference Cancellation}
\newacronym{sr}{SR}{Symbiotic Radio}
\newacronym{tg}{TG}{tag}
\newacronym{ue}{UE}{user}



\begin{document}
	\title{Backscatter Modulation Design for Symbiotic Radio Networks}
	\maketitle

	\begin{section}{Backscatter Model}
		\begin{subsection}{Backscatter Principles}
			\begin{figure}[!t]
				\centering
				\subfloat[Block diagram of a passive tag]{
					\resizebox{0.6\columnwidth}{!}{
						\begin{circuitikz}[transform shape]
							\coordinate (O) at (0,0);
							\node[block,from={O to $(O) + (6.375,3.25)$}](T){};
							\draw (0,1.75)
								to[short] ++(-1,0)
								to[short] ++(0,0.75) node[bareantenna](A){Ant};
							\draw (0,1.75)
								to[short,-*] ++(0.25,0) coordinate(J);
							\draw (J)
								to[short] ++(0,1)
								to[short] ++(0.5,0) coordinate(J1);
							\node[block,from={$(J1) + (0,-0.25)$ to $(J1) + (2.5,0.25)$}](R){Rectifier};
							\draw (J)
								to[short] ++(0.5,0) coordinate(J2);
							\node[block,from={$(J2) + (0,-0.25)$ to $(J2) + (2.5,0.25)$}](D){Demodulator};
							\draw (J)
								to[short] ++(0,-1)
								to[short] ++(0.5,0) coordinate(J3)
								to [vR,mirror,invert,/tikz/circuitikz/bipoles/length=1cm] ++(1.75,0) node[ground,rotate=90]{};
							\node[block,from={$(J3) + (0,-0.25)$ to $(J3) + (2.5,0.25)$},draw=none](M){};
							\draw ($(J3) + (0,-0.25)$) rectangle ($(J3) + (2.5,0.25)$);
							\draw ($(J3) + (1.25,-0.5)$) node[]{Modulator};
							\draw[-{Latex[length=2mm]}] (R.east) -- ++(0.75,0);
							\draw[-{Latex[length=2mm]}] (D.east) -- ++(0.75,0);
							\draw[{Latex[length=2mm]}-] (M.east) -- ++(0.75,0);
							\node[block,from={$(R.east) + (0.75,-0.25)$ to $(R.east) + (2.875,0.25)$}](P){Power buffer};
							\node[block,from={$(M.east) + (0.75,-0.25)$ to $(D.east) + (2.875,0.25)$}](S){Digital\\section};
							\draw[dashed,-{Latex[length=2mm]}] (P.south) to (S.north);
							\coordinate (F1) at ($(P.south)!0.5!(S.north)$);
							\coordinate (F2) at ($(D.east)!0.5!(S.west)$);
							\coordinate (F3) at ($(D.south)!0.5!(M.north)$);
							\draw[dashed] (F1) to (F1-|D.north);
							\draw[dashed,-{Latex[length=2mm]}] (F1-|D.north) to (D.north);
							\draw[dashed] (F1-|F2) to (F2|-F3) to (M|-F3);
							\draw[dashed,-{Latex[length=2mm]}] (M|-F3) to (M.north);
						\end{circuitikz}
					}
					\label{fi:block_diagram_of_a_passive_tag}
				}
				\subfloat[Backscatter modualtion]{
					\resizebox{0.35\columnwidth}{!}{
						\begin{circuitikz}[transform shape]
							\draw (0,0) node[bareantenna](bareantenna){};
							\draw (bareantenna.west) ++(-1.5,0) node[waves](WI){};
							\draw (WI.north east) ++(0.25,0) node[font=\Large]{$\vec{E}_{\mathrm{I}}$};
							\draw (WI.south east) ++(0.25,0) node[font=\Large]{$\vec{H}_{\mathrm{I}}$};
							\draw (bareantenna.east) ++(0.875,0) node[waves](WR){};
							\draw (WR.north east) ++(0.25,0) node[font=\Large]{$\vec{E}_m$};
							\draw (WR.south east) ++(0.25,0) node[font=\Large]{$\vec{H}_m$};
							\draw (bareantenna)
								to [R=$Z_{\mathrm{A}}$,font=\Large,/tikz/circuitikz/bipoles/length=1cm] ++(0,-2)
								to [R=$Z_m$,font=\Large,/tikz/circuitikz/bipoles/length=1cm] ++(2,0) node[ground]{};
						\end{circuitikz}
					}
					\label{fi:backscatter_modualtion}
				}
				\caption{For a passive tag, the rectifier and demodulator rely on the incident electromagnetic wave for energy harvesting and source decoding, while the load-switcher adjusts the reradiated signal for backscatter modulation.}
				\label{fi:tag}
			\end{figure}
			A bistatic backscatter system consists of an excitation source, multiple (semi-)passive tags, and a backscatter reader. When illuminated, the tags simultaneously harvest energy, backscatter message, and demodulate the source signal if necessary. Fig.~\subref*{fi:block_diagram_of_a_passive_tag} shows a typical passive with a scattering antenna, an energy harvester, an integrated receiver\footnote{For example, \cite{Kim2021a} prototyped a compact-size pulse position demodulator based on an envelope detector, which brings great potential to coordination, synchronization, and reflection pattern control.}, a load-switching modulator, and on-chip components (e.g., micro-controller, memory, and sensors). A portion of the impinging signal is absorbed by the tag while the remaining is backscattered to the space. According to Green's decomposition \cite{Hansen1989}, the backscattered signal can be decomposed into the \emph{structural mode} component and the \emph{antenna mode} component. The former is fixed and depends on the antenna geometry and material properties\footnote{The structural mode component can be regarded as part of the environment multipath and modeled by channel estimation \cite{Boyer2014}.}, while the latter is adjustable and depends on the mismatch of the antenna and load impedance. Fig.~\subref*{fi:backscatter_modualtion} illustrates a simplified circuit and backscatter model at tag state $m$. The corresponding reflection coefficient is defined as\footnote{We assume the linear backscatter model where the reflection coefficient is irrelevant to the incident electromagnetic field at the tag \cite{Dobkin2012}.}
			\begin{equation}
				\Gamma_m = \frac{Z_m - Z_{\mathrm{A}}^*}{Z_m + Z_{\mathrm{A}}},
				\label{eq:reflection_coefficient}
			\end{equation}
			where $Z_m$ is the load impedance at state $m$ and $Z_{\mathrm{A}}$ is the antenna input impedance.
		\end{subsection}

		\begin{subsection}{Backscatter Modulation}
			Backscatter modulation is achieved by switching the tag load impedance between different states. For an $M$-ary \gls{qam} at state $m \in \mathcal{M} \triangleq \{1,\ldots,M\}$, the reflection coefficient $\Gamma_m$ maps to the signal constellation point $\bar{c}_m$ as \cite{Thomas2012a}
			\begin{equation}
				\Gamma_m = \alpha \frac{\bar{c}_m}{\max_{m'} \lvert \bar{c}_{m'} \rvert},
				\label{eq:backscatter_modulation}
			\end{equation}
			where $\alpha \in [0,1]$ is the reflection efficiency at a given direction. For simplicity, we consider an $M$-ary \gls{psk} with constellation set $\mathcal{C} \triangleq \{\bar{c}_1,\ldots,\bar{c}_M\}$, where the $m$-th constellation point is
			\begin{equation}
				\bar{c}_m = \exp \left(j \frac{2 \pi m}{M}\right).
				\label{eq:mpsk}
			\end{equation}

			\begin{remark}
				For passive tags, the reflection efficiency $\alpha$ controls the tradeoff between the harvestable power and backscatter strength: $\alpha = 0$ corresponds to maximum power transfer to the tag, while $\alpha = 1$ with $M$-\gls{psk} corresponds to ideal \gls{irs} with $M$ discrete states.
			\end{remark}
		\end{subsection}
	\end{section}

	\begin{section}{Backscatter Detection and Achievable Rates}
		\begin{subsection}{System Model}
			\begin{figure}[!t]
				\centering
				\def\svgwidth{0.9\columnwidth}
				\import{assets/}{symbiotic_radio.eps_tex}
				\caption{A single-user multi-tag symbiotic radio system.}
				\label{fi:symbiotic_radio}
			\end{figure}
			As shown in Fig.~\ref{fi:symbiotic_radio}, we propose a single-\gls{ue} multi-\gls{tg} symbiotic radio network where the \gls{rf} signal generated by the $Q$-antenna \gls{ap} is shared by two coexisting systems. In the primary downlink system, the \gls{ap} transmits information to the single-antenna user. In the secondary backscatter system, the \gls{ap} acts as the carrier emitter, the $K$ nearby single-antenna tags modulate their information over the reradiated \gls{rf} signals, and the user serves as the multi-tag backscatter reader. Denote the \gls{ap}-\gls{ue} direct channel as $\boldsymbol{h}_{\mathrm{D}}^H \in \mathbb{C}^{1 \times Q}$, the \gls{ap}-\gls{tg} $k \in \mathcal{K} \triangleq \{1,\ldots,K\}$ forward channel as $\boldsymbol{h}_{\mathrm{F},k}^H \in \mathbb{C}^{1 \times Q}$, the \gls{tg} $k$-\gls{ue} backward channel as $h_{\mathrm{B},k}$, and the cascaded forward-backward channel of tag $k$ as $\boldsymbol{h}_{\mathrm{C},k}^H \triangleq h_{\mathrm{B},k} \boldsymbol{h}_{\mathrm{F},k}^H \in \mathbb{C}^{1 \times Q}$. For simplicity, we consider a quasi-static block fading model where the channel coefficients remain constant within each coherence interval and vary independently over different coherence intervals, and assume the coherence interval $T$ is much longer than the backscatter symbol period $T_c$ and primary symbol period $T_s$. We also assume the direct channel and all cascaded channels can be successfully estimated and fed back to the \gls{ap}.\footnote{Due to the lack of \gls{rf} chains at the passive tag, accurate and efficient \gls{csi} acquisition at the \gls{ap} can be challenging. One possible approach is that the \gls{ap} sends pre-defined pilots, the tags respond in well-designed manners, and the user performs least-square estimation with feedbacks \cite{Bharadia2015,Yang2015b,Guo2019g}.} Since the tags need to physically switch the loads for backscatter modulation, they communicate at a much longer symbol period (and lower rates) than the primary system. As such, we assume the transitions of all tags are perfectly synchronized, and the backscatter symbol period satisfies $T_c = N T_s$ where $N \gg 1$ is a positive integer.

			Without loss of generality, we focus on the transmissions and detections during one particular backscatter symbol period. To provide a preliminary insight, we assume the primary symbol $s[n]$ at block $n \in \mathcal{N} \triangleq \{1,\ldots,N\}$ is in standard \gls{cscg} distribution, and the backscatter symbol $c_k$ of tag $k$ employs $M$-\gls{psk} modulation by \eqref{eq:mpsk}, i.e., $c_k \in \mathcal{C}$, $\forall k \in \mathcal{K}$. Thus, the signal received by the user at block $n$ can be expressed as\footnote{We omit the signal reflected by two or more times\cite{Wu2019} and assume the time difference of arrival from different paths are negligible\cite{Guo2019b}.}
			\begin{equation}
				y[n] = \left(\boldsymbol{h}_{\mathrm{D}}^H + \sum_{k \in \mathcal{K}} \sqrt{\alpha_k} \boldsymbol{h}_{\mathrm{C},k}^H c_k\right) \boldsymbol{w} s[n] + w[n],
				\label{eq:received_signal}
			\end{equation}
			where $\boldsymbol{w} \in \mathbb{C}^{Q \times 1}$ is the active precoder satisfying $\lVert \boldsymbol{w} \rVert^2 \le P$, $P$ is the average transmit power constraint at the \gls{ap}, and $w[n] \sim \mathcal{CN}(0,\sigma_w^2)$ is the equivalent \gls{awgn} at block $n$. Besides, we collect the backscatter symbols of $K$ tags into $c_{\mathcal{K}} \triangleq \{c_k : k \in \mathcal{K}\}$, stack the received signal over $N$ blocks as $\boldsymbol{y} \triangleq \left[y[1],\ldots,y[N]\right]^T \in \mathbb{C}^{N \times 1}$, and define the equivalent channel for primary transmission as
			\begin{equation}
				\boldsymbol{h}_{\mathrm{E}}^H(c_{\mathcal{K}}) \triangleq \boldsymbol{h}_{\mathrm{D}}^H + \sum_{k \in \mathcal{K}} \sqrt{\alpha_k} \boldsymbol{h}_{\mathrm{C},k}^H c_k.
				\label{eq:equivalent_primary_channel}
			\end{equation}

			\begin{remark}
				The proposed symbiotic radio system includes a multiplicative \gls{mac} where the \gls{ap} and the tags simultaneously transmit to the user. It inspired [TODO] to perform \gls{sic} that first non-coherently detects the primary message under backscatter uncertainty, then cancels its contribution and decodes the tag messages. This scheme requires non-coherent coding at the \gls{ap} and $K$ re-encoding, precoding, and subtraction operations at the user. However, different from the conventional \gls{mac} with \gls{sc}, the symbiotic radio system involves \gls{mc} that combines the primary and secondary messages by multiplication. Hence, novel multi-stream detection techniques should be tailored to symbiotic radio systems to accommodate the massive connectivity of tags and the multiplicative combination of links.
			\end{remark}
		\end{subsection}

		\begin{subsection}{Backscatter Detection}
			To reveal the impact of backscatter modulation on the primary transmission and avoid the exponential complexity of joint detection, we extend the non-coherent \gls{ambc} detection \cite{Qian2019} to the multi-tag case, and propose a low-complexity energy detection to decode the backscatter symbols under primary source uncertainty. It requires no dedicated receivers or non-coherent codes at the \gls{ap}, and can be readily implemented over legacy downlink systems.

			\begin{remark}
				One key property of symbiotic radio is the primary message propagates to the user from a known channel and multiple multiplicative channels with uncertainty introduced by backscatter modulation. As such, each reflection coefficient simultaneously encodes the tag message and influences the equivalent channel of the primary link. If the backscatter symbols can be successfully decoded first, they can be modeled within the equivalent channel \eqref{eq:equivalent_primary_channel} as in channel training, instead of being removed by \gls{sic}.
			\end{remark}

			To explicitly specify the instances of the backscatter symbols, we define the modulation index set as $m_{\mathcal{K}} \triangleq \{m_k \in \mathcal{M} : k \in \mathcal{K}\}$ and label the corresponding tag input combination as $\bar{c}_{m_{\mathcal{K}}} \triangleq \{\bar{c}_{m_k} \in \mathcal{C} : m_k \in \mathcal{M}, k \in \mathcal{K}\}$. Since any $\bar{c}_{m_{\mathcal{K}}}$ remains constant per $N$ primary symbols, the received signal at block $n$ is only subject to the variation of the primary source $s[n]$ and \gls{awgn} $w[n]$, and thus follows \gls{cscg} distribution $y_{m_{\mathcal{K}}}[n] \sim \mathcal{CN}\left(0,\sigma_{m_{\mathcal{K}}}^2\right)$, where the variance
			\begin{equation}
				\sigma_{m_{\mathcal{K}}}^2 = \Bigl\lvert \underbrace{\bigl(\boldsymbol{h}_{\mathrm{D}}^H + \sum_{k \in \mathcal{K}} \sqrt{\alpha_k} \boldsymbol{h}_{\mathrm{C},k}^H \bar{c}_{m_k}\bigr)}_{\boldsymbol{h}_{\mathrm{E}}^H(\bar{c}_{m_{\mathcal{K}}})} \boldsymbol{w} \Bigr\rvert^2 + \sigma_w^2,
				\label{eq:receive_variance}
			\end{equation}
			denotes the expectation of the received power per primary block under tag modulation index set $m_{\mathcal{K}}$. For the ease of exposition, we denote the hypothesis that the tag input combination at status $i \in \mathcal{M^K} \triangleq \{1,\ldots,M^K\}$ as $\mathcal{H}_i$, sort $\{\sigma_{m_{\mathcal{K}}}^2\}$ in ascending order by a one-to-one mapping $m_{\mathcal{K}} \mapsto i$,\footnote{When more than one modulation index sets yield the same energy level, the mapping is not unique and the detection fails to separate them. This blind spot issue can be mitigated by multi-antenna techniques.} define the received signal energy over $N$ primary blocks as $z \triangleq \lVert \boldsymbol{y} \rVert^2$, and let $f(z \mid \mathcal{H}_i)$ be the conditional probability density function of receiving $z$ under hypothesis $\mathcal{H}_i$. Correspondingly, $z$ is the sum of $N$ i.i.d. exponential variables each with mean $\sigma_i^2$, and the conditional probability density function follows Erlang distribution with shape $N$ and scale $\sigma_i^2$ as
			\begin{equation}
				f(z \mid \mathcal{H}_i) = \frac{z^{N-1} e^{-z/\sigma_i^2}}{\sigma_i^{2N} (N-1)!}.
				\label{eq:energy_distribution}
			\end{equation}

			\begin{remark}
				The backscatter links essentially form a discrete-input continuous-output memoryless channel. To further reduce decoding complexity, we apply hard-decision detection and construct a \gls{dmtc}, whose capacity is a function of both input distribution and decision thresholds \cite{Nguyen2018}.
			\end{remark}

			Denote the decision region of hypothesis $\mathcal{H}_i$ as
			\begin{equation}
				\mathcal{R}_i \triangleq [T_{i-1,i}, T_{i,i+1}),
				\label{eq:decision_region}
			\end{equation}
			where $T_{i-1,i}$ is the decision threshold between $\mathcal{H}_{i-1}$ and $\mathcal{H}_i$, and $T_{i,i+1}$ is the decision threshold between $\mathcal{H}_i$ and $\mathcal{H}_{i+1}$. We also define $T_{0,1} \triangleq 0$, $T_{M^K,M^K+1} \triangleq \infty$, and $\boldsymbol{t} \triangleq [T_{0,1},\ldots,T_{M^K,M^K+1}]^T \in \mathbb{R}^{(M^K + 1) \times 1}$.

			Consider the (\gls{ml}) detector for example. The likelihood ratio between hypotheses $\mathcal{H}_i$ and $\mathcal{H}_{i'}$ is \cite{Qian2019}
			\begin{equation}
				\Lambda_{i,{i'}}^{\mathrm{\gls{ml}}}(z) = \frac{f(z \mid \mathcal{H}_i)}{f(z \mid \mathcal{H}_{i'})} = \left( \frac{\sigma_{i'}^2}{\sigma_i^2} \right)^N \exp \left( \frac{\sigma_i^2 - \sigma_{i'}^2}{\sigma_i^2 \sigma_{i'}^2} z \right),
				\label{eq:likelihood_ratio}
			\end{equation}
			the corresponding decision rule is
			\begin{equation}
				\Lambda_{i,{i'}}^{\mathrm{\gls{ml}}}(z) \underset{\mathcal{H}_{i'}}{\overset{\mathcal{H}_i}{\lessgtr}} 1 \iff z \underset{\mathcal{H}_{i'}}{\overset{\mathcal{H}_i}{\lessgtr}} T_{i,{i'}}^{\mathrm{\gls{ml}}},
				\label{eq:decision_rule}
			\end{equation}
			and the detection threshold is
			\begin{equation}
				T_{i,{i'}}^{\mathrm{\gls{ml}}} \triangleq N \frac{\sigma_i^2 \sigma_{i'}^2}{\sigma_i^2 - \sigma_{i'}^2} \log \frac{\sigma_i^2}{\sigma_{i'}^2}.
				\label{eq:detection_threshold}
			\end{equation}

			\begin{remark}
				Although the \gls{ml} decision threshold is optimal in terms of the likelihood function, it is not necessarily capacity-achieving, although the performance gap can be negligible in the single-tag \gls{bibo} case.
			\end{remark}

			Once the decision region is determined, we can formulate an equivalent point-to-point \gls{dmc} from tag input combination alphabet $\mathcal{M^K}$ to output energy level alphabet $\mathcal{M^K}$. The probability of receiving energy level $j$ under tag input combination $i$ is\footnote{For simplicity, we assume there exists at least one feasible precoder that produces distinct received energy levels for all tag input combinations. [TODO] Merge with precoder design.}
			\begin{equation}
				P(\bar{z}_j \mid \bar{c}_i) = P(z \in \mathcal{R}_j \mid \mathcal{H}_i) = \int_{\mathcal{R}_j} f(z \mid \mathcal{H}_i) \dd z.
				\label{eq:point_to_point_channel}
			\end{equation}

			On top of this, we can compute the marginal probability of each tag and obtain $K$ transition matrices from $\mathcal{M}$ to $\mathcal{M^K}$ that compose a discrete memoryless \gls{mac}. The probability of observing energy level $j$ when tag $k$ at status $m_k$ is
			\begin{equation}
				P(\bar{z}_j \mid \bar{c}_{m_k}) = \frac{\sum_{m_{\mathcal{K} \setminus \{k\}}} P(\bar{z}_j \mid \bar{c}_{m_{\mathcal{K}}})}{\sum_{m_{\mathcal{K}}} P(\bar{z}_j \mid \bar{c}_{m_{\mathcal{K}}})}.
				\label{eq:mac}
			\end{equation}

			In summary, with the \gls{csi} knowledge and for any given precoder and detection threshold set, we can obtain the expected power of the received signal per block by \eqref{eq:receive_variance}, the conditional probability density function of the accumulated energy by \eqref{eq:energy_distribution}, the decision region by \eqref{eq:decision_region}, the equivalent point-to-point channel by \eqref{eq:point_to_point_channel}, and the discrete memoryless \gls{mac} by \eqref{eq:mac}.
		\end{subsection}

		\begin{subsection}{Sum backscatter rate}
			We first introduce some prerequisites of information theory. Define the input probability distribution of tag $k$ at status $m_k$ as $P_k(\bar{c}_{m_k})$, and let $\boldsymbol{p}_k \triangleq [P_k(\bar{c}_1),\ldots,P_k(\bar{c}_M)]^T \in \mathbb{R}^{M \times 1}$, $\boldsymbol{P} \triangleq [\boldsymbol{p}_1^T,\ldots,\boldsymbol{p}_K^T]^T \in \mathbb{R}^{M \times K}$. Assume the input distribution of all tags are mutually independent such that $P_{\mathcal{K}}(\bar{c}_{m_{\mathcal{K}}}) = \prod_{k \in \mathcal{K}} P_k(\bar{c}_{m_k})$. Following \cite{Rezaeian2004}, the backscatter information function associated with tag input combination $\bar{c}_{m_{\mathcal{K}}}$ is defined as
			\begin{equation}
				I_{\mathrm{B}}(\bar{c}_{m_{\mathcal{K}}};z) \triangleq \sum_j P(\bar{z}_j \mid \bar{c}_{m_{\mathcal{K}}}) \log \frac{P(\bar{z}_j \mid \bar{c}_{m_{\mathcal{K}}})}{P(\bar{z}_j)},
				\label{eq:backscatter_information_function}
			\end{equation}
			% \begin{align}
			% 	I_{\mathrm{B}}(\bar{c}_{m_{\mathcal{K}}};z)
			% 	& \triangleq \sum_j P(\bar{z}_j \mid \bar{c}_{m_{\mathcal{K}}}) \log \frac{P(\bar{z}_j \mid \bar{c}_{m_{\mathcal{K}}})}{P(\bar{z}_j)}\\
			% 	& = \sum_j P(\bar{z}_j \mid \bar{c}_{m_{\mathcal{K}}}) \log \frac{P(\bar{z}_j \mid \bar{c}_{m_{\mathcal{K}}})}{\sum_{m_{\mathcal{K}}} \prod_{k \in \mathcal{K}} P(\bar{c}_{m_{\mathcal{K}}}) P(\bar{z}_j \mid \bar{c}_{m_{\mathcal{K}}})}
			% 	\label{eq:backscatter_information_function}
			% \end{align}
			the backscatter marginal information function of tag $q \in \mathcal{K}$ associated with $\bar{c}_{i_q}$, $i_q \in \mathcal{M}$ is defined as
			\begin{equation}
				I_{\mathrm{B},q}(\bar{c}_{i_q};z) \triangleq \sum_{m_{\mathcal{K} \setminus \{q\}}} \prod_{k \in \mathcal{K} \setminus \{q\}} P_k(\bar{c}_{m_k}) I_{\mathrm{B}}(\bar{c}_{m_{\mathcal{K} \setminus \{q\}}},\bar{c}_{i_q};z),
				\label{eq:backscatter_marginal_information_function}
			\end{equation}
			% the backscatter marginal information function of tag $k$ associated with $\bar{c}_{m_k}$ is defined as
			% \begin{equation}
			% 	I_{\mathrm{B},k}(\bar{c}_{m_k};z) \triangleq \sum_{m_{\mathcal{K} \setminus \{k\}}} \prod_{k' \in \mathcal{K} \setminus \{k\}} P_{k'}(\bar{c}_{m_{k'}}) I_{\mathrm{B}}(\bar{c}_{m_{\mathcal{K} \setminus \{k\}}}, \bar{c}_{m_k};z),
			% 	% \label{eq:backscatter_marginal_information_function}
			% \end{equation}
			% \begin{equation}
			% 	I_{\mathrm{B},k}(\bar{c}_{m_k};z) \triangleq \sum_{m_{\mathcal{K} \setminus \{k\}}} \prod_{k' \in \mathcal{K} \setminus \{k\}} P_{k'}(\bar{c}_{m_{k'}}) I_{\mathrm{B}}(\bar{c}_{m_{\mathcal{K}}};z),
			% 	\label{eq:backscatter_marginal_information_function}
			% \end{equation}
			% \begin{align}
			% 	I_{\mathrm{B},k}(\bar{c}_{m_k};z)
			% 	& \triangleq \sum_{m_{\mathcal{K} \setminus \{k\}}} P_{\mathcal{K} \setminus \{k\}}(\bar{c}_{m_{\mathcal{K} \setminus \{k\}}}) I_{\mathrm{B}}(\bar{c}_{m_{\mathcal{K}}};z)\\
			% 	& = \sum_{m_{\mathcal{K} \setminus \{k\}}} \prod_{k' \in \mathcal{K} \setminus \{k\}} P_{k'}(\bar{c}_{m_{k'}}) I_{\mathrm{B}}(\bar{c}_{m_{\mathcal{K}}};z),
			% 	% \label{eq:backscatter_marginal_information_function}
			% \end{align}
			% the backscatter marginal information function of $\mathcal{S} \subset \mathcal{K}$ is defined as
			% \begin{equation}
			% 	I_{\mathrm{B},\mathcal{S}}(\bar{c}_{m_{\mathcal{S}}};z) \triangleq \sum_{m_{\mathcal{K} \setminus \mathcal{S}}} P_{\mathcal{K} \setminus \mathcal{S}}(\bar{c}_{m_{\mathcal{K} \setminus \mathcal{S}}}) I_{\mathrm{B}}(\bar{c}_{m_{\mathcal{K}}};z),
			% 	\label{eq:backscatter_marginal_information_function}
			% \end{equation}
			and the backscatter mutual information can be expressed as\footnote{Please be aware that $c_{\mathcal{K}}$, $c_k$, $z$ are random variables, while $\bar{c}_{m_{\mathcal{K}}}$ and $\bar{c}_i$, $\bar{c}_{m_k}$, $\bar{z}_j$ represent the corresponding instances.}
			\begin{subequations}
				\begin{align}
					I_{\mathrm{B}}(c_{\mathcal{K}};z)
					& = \mathbb{E}_{c_{\mathcal{K}}} \left[I_{\mathrm{B}}(\bar{c}_{m_{\mathcal{K}}};z)\right] = \mathbb{E}_{c_k} \left[I_{\mathrm{B},k}(\bar{c}_{m_k};z)\right]\label{eq:backscatter_sum_rate_expectation}\\
					& = \sum_{m_{\mathcal{K}}} \prod_{k \in \mathcal{K}} P_k(\bar{c}_{m_k}) \sum_j P(\bar{z}_j \mid \bar{c}_{m_{\mathcal{K}}}) \log \frac{P(\bar{z}_j \mid \bar{c}_{m_{\mathcal{K}}})}{P(\bar{z}_j)}.\label{eq:backscatter_sum_rate_expansion}
				\end{align}
				\label{eq:backscatter_sum_rate}
			\end{subequations}
			% \begin{align}
			% 	I_{\mathrm{B}}(c_{\mathcal{K}};z)
			% 	& = \mathbb{E}_{c_{\mathcal{K}}} \left[I_{\mathrm{B}}(\bar{c}_{m_{\mathcal{K}}};z)\right] = \mathbb{E}_{c_{\mathcal{S}}} \left[I_{\mathrm{B},\mathcal{S}}(\bar{c}_{m_{\mathcal{S}}};z)\right]\\
			% 	& = \sum_{m_{\mathcal{K}}} \prod_{k \in \mathcal{K}} P_k(\bar{c}_{m_k}) \sum_j P(\bar{z}_j \mid \bar{c}_{m_{\mathcal{K}}}) \log \frac{P(\bar{z}_j \mid \bar{c}_{m_{\mathcal{K}}})}{P(\bar{z}_j)}.\label{eq:backscatter_sum_rate}
			% \end{align}

			Evidently, \eqref{eq:backscatter_information_function}--\eqref{eq:backscatter_sum_rate} are functions of the tag input distribution $\boldsymbol{P}$ as well as the discrete memoryless \gls{mac} $P(z \mid c_{\mathcal{K}})$, and thus depend on the transmit precoder $\boldsymbol{w}$ and the detection threshold $\boldsymbol{t}$.
		\end{subsection}

		\begin{subsection}{Ergodic primary rate}
			Once the tag input combination is successfully decoded, the user can eliminate backscatter uncertainty and model its contribution within the equivalent primary channel \eqref{eq:equivalent_primary_channel}. As such, the tags can adjust the propagation environment in a potentially beneficial manner, and create artificial channel variation within each fading block. Similarly, we define the primary information function associated with tag input combination $\bar{c}_{m_{\mathcal{K}}}$ and the primary marginal information function of tag $q$ associated with symbol $\bar{c}_{i_q}$ respectively as
			\begin{align}
				I_{\mathrm{P}}(\bar{c}_{m_{\mathcal{K}}};\boldsymbol{y})
				& \triangleq N \log_2 \left(1 + \frac{\lvert \boldsymbol{h}_{\mathrm{E}}^H(\bar{c}_{m_{\mathcal{K}}}) \boldsymbol{w} \rvert^2}{\sigma_w^2}\right),\label{eq:primary_information_function}\\
				I_{\mathrm{P},q}(\bar{c}_{i_q};\boldsymbol{y})
				& \triangleq \sum_{m_{\mathcal{K} \setminus \{q\}}} \prod_{k \in \mathcal{K} \setminus \{q\}} P_{k}(\bar{c}_{m_{k}}) I_{\mathrm{P}}(\bar{c}_{m_{\mathcal{K} \setminus \{q\}}},\bar{c}_{i_q};\boldsymbol{y}),\label{eq:primary_marginal_information_function}
			\end{align}
			% \begin{equation}
			% 	I_{\mathrm{P},k}(\bar{c}_{m_k};\boldsymbol{y}) \triangleq \sum_{m_{\mathcal{K} \setminus \{k\}}} \prod_{k' \in \mathcal{K} \setminus \{k\}} P_{k'}(\bar{c}_{m_{k'}}) I_{\mathrm{P}}(\bar{c}_{m_{\mathcal{K}}};\boldsymbol{y}),
			% 	\label{eq:primary_marginal_information_function}
			% \end{equation}
			% \begin{equation}
			% 	I_{\mathrm{P},k}(\bar{c}_{m_k}) \triangleq \sum_{m_{\mathcal{K} \setminus \{k\}}} P_{\mathcal{K} \setminus \{k\}}(\bar{c}_{m_{\mathcal{K} \setminus \{k\}}}) I_{\mathrm{P}}(\bar{c}_{m_{\mathcal{K}}}),
			% 	\label{eq:primary_marginal_information_function}
			% \end{equation}
			% \begin{equation}
			% 	I_{\mathrm{P},\mathcal{S}}(\bar{c}_{m_{\mathcal{S}}}) \triangleq \sum_{m_{\mathcal{K} \setminus \mathcal{S}}} P_{\mathcal{K} \setminus \mathcal{S}}(\bar{c}_{m_{\mathcal{K} \setminus \mathcal{S}}}) I_{\mathrm{P}}(\bar{c}_{m_{\mathcal{K}}}),
			% 	\label{eq:primary_marginal_information_function}
			% \end{equation}
			and the ergodic primary rate can be expressed as\footnote{The unit of \eqref{eq:backscatter_information_function}--\eqref{eq:backscatter_sum_rate} are \gls{bpcu}, while the unit of \eqref{eq:primary_information_function}--\eqref{eq:primary_ergodic_rate} are \gls{bpsphz}.}
			\begin{subequations}
				\begin{align}
					I_{\mathrm{P}}(c_{\mathcal{K}};\boldsymbol{y})
					& = \mathbb{E}_{c_{\mathcal{K}}} \left[I_{\mathrm{P}}(\bar{c}_{m_{\mathcal{K}}};\boldsymbol{y})\right] = \mathbb{E}_{c_k} \left[I_{\mathrm{P},k}(\bar{c}_{m_k};\boldsymbol{y})\right]\label{eq:primary_ergodic_rate_expectation}\\
					& = \sum_{m_{\mathcal{K}}} \prod_{k \in \mathcal{K}} P_k(\bar{c}_{m_k}) N \log_2 \left(1 + \frac{\lvert \boldsymbol{h}_{\mathrm{E}}^H(\bar{c}_{m_{\mathcal{K}}}) \boldsymbol{w} \rvert^2}{\sigma_w^2}\right).
					\label{eq:primary_ergodic_rate_expansion}
				\end{align}
				\label{eq:primary_ergodic_rate}
			\end{subequations}
			% \begin{align}
			% 	I_{\mathrm{P}}(c_{\mathcal{K}})
			% 	& = \mathbb{E}_{c_{\mathcal{K}}} \left[I_{\mathrm{P}}(\bar{c}_{m_{\mathcal{K}}})\right] = \mathbb{E}_{c_{\mathcal{S}}} \left[I_{\mathrm{P},\mathcal{S}}(\bar{c}_{m_{\mathcal{S}}})\right]\\
			% 	& = \sum_{m_{\mathcal{K}}} \prod_{k \in \mathcal{K}} P_k(\bar{c}_{m_k}) \log_2 \left(1 + \frac{\lvert \boldsymbol{h}_{\mathrm{E}}^H(\bar{c}_{m_{\mathcal{K}}}) \boldsymbol{w} \rvert^2}{\sigma_w^2}\right).
			% 	\label{eq:primary_ergodic_rate}
			% \end{align}

			In contrast to the backscatter case, \eqref{eq:primary_information_function}--\eqref{eq:primary_ergodic_rate} are irrelevant to the detection threshold $\boldsymbol{t}$, but depend on the tag input probability distribution $\boldsymbol{P}$ and the transmit precoder $\boldsymbol{w}$.
		\end{subsection}
	\end{section}

	\begin{section}{Input Distribution, Decision Region, and Precoder Design}
		\begin{subsection}{Primary-backscatter rate region}
			The weighted sum marginal information of tag $q$ associated with symbol $\bar{c}_{i_q}$ and the weighted sum primary-backscatter rate are defined respectively as
			\begin{align}
				I_q(\bar{c}_{i_q};\boldsymbol{y},z)
				& \triangleq \rho I_{\mathrm{P},q}(\bar{c}_{i_q};\boldsymbol{y}) + (1 - \rho) I_{\mathrm{B},q}(\bar{c}_{i_q};z),\label{eq:weighted_sum_marginal_information}\\
				I(c_{\mathcal{K}};\boldsymbol{y},z)
				& \triangleq \rho I_{\mathrm{P}}(c_{\mathcal{K}};\boldsymbol{y}) + (1 - \rho) I_{\mathrm{B}}(c_{\mathcal{K}};z),\label{eq:weighted_sum_rate}
			\end{align}
			where $\rho \in [0,1]$ denotes the priority of the primary link. To investigate how backscatter modulation and detection may influence the primary transmission, we optimize the input probability distribution, decision region, and transmit precoder to maximize the weighted primary-backscatter sum rate
			\begin{maxi!}
				{\scriptstyle{\boldsymbol{P},\boldsymbol{t},\boldsymbol{w}}}{I}{\label{op:rate_region}}{\label{ob:weighted_sum_rate}}
				\addConstraint{\sum \nolimits_{m_k} P_k(\bar{c}_{m_k})}{=1,\quad\label{co:sum_probability}}{\forall k \in \mathcal{K}}
				\addConstraint{P_k(\bar{c}_{m_k})}{\ge 0,\quad\label{co:nonnegative_probability}}{\forall m_k \in \mathcal{M}, \ \forall k \in \mathcal{K}}
				\addConstraint{\lVert \boldsymbol{w} \rVert^2}{\le P.\label{co:average_transmit_power}}
			\end{maxi!}
			where \eqref{co:sum_probability} and \eqref{co:nonnegative_probability} are input probability constraints and \eqref{co:average_transmit_power} is the average transmit power budget. As problem \eqref{op:rate_region} is not jointly convex over $\boldsymbol{P}$, $\boldsymbol{t}$ and $\boldsymbol{w}$, we propose a \gls{bcd} method that iteratively updates the input distribution, decision region, and transmit precoder, until convergence is achieved.
		\end{subsection}

		\begin{subsection}{Input probability distribution}
			For any fixed decision boundary $\boldsymbol{t}$ and transmit precoder $\boldsymbol{w}$, the equivalent discrete memoryless \gls{mac} can be determined by \eqref{eq:mac} and problem~\eqref{op:rate_region} boils down to
			\begin{maxi!}
				{\scriptstyle{\boldsymbol{P}}}{I}{\label{op:input_probability_distribution}}{}
				\addConstraint{\eqref{co:sum_probability},\eqref{co:nonnegative_probability},}
			\end{maxi!}
			which is non-convex for $K > 1$ due to the product term $\prod_{k \in \mathcal{K}} P_k(\bar{c}_{m_k})$. Fortunately, the \gls{kkt} conditions are sufficient and necessary for this type of problem, and the proof follows straightforwardly from \cite{Watanabe2009}.\footnote{For any elementary discrete memoryless \gls{mac} (sizes of input alphabets are no greater than that of output alphabet), the sufficiency can be proved by combining the local maximum and connectedness of \gls{kkt} solutions. For any general discrete memoryless \gls{mac}, the capacity can be achieved by an elementary discrete memoryless \gls{mac} included within. Thus, we restrict the discussion of this paper to elementary discrete memoryless \gls{mac}s.} Denote the Lagrange multiplier associated with \eqref{co:sum_probability} and \eqref{co:nonnegative_probability} as $\boldsymbol{\mu} \triangleq [\mu_1,\ldots,\mu_K]^T \in \mathbb{R}^{K \times 1}$ and $\boldsymbol{\Lambda} \triangleq [\boldsymbol{\lambda}_1^T,\ldots,\boldsymbol{\lambda}_K^T]^T \in \mathbb{R}^{M \times K}$ with $\boldsymbol{\lambda}_k \triangleq [\lambda_{k,1},\ldots,\lambda_{k,M}]^T \in \mathbb{R}^{M \times 1}$, respectively. The Lagrangian function of problem~\eqref{op:input_probability_distribution} is
			\begin{align}
				J
				& = - I + \sum_{k \in \mathcal{K}} \mu_k \left( \sum_{m_k \in \mathcal{M}} P_k(\bar{c}_{m_k}) - 1 \right)\nonumber\\
				& \quad - \sum_{k \in \mathcal{K}} \sum_{m_k \in \mathcal{M}} \lambda_{k,m_k} P_k(\bar{c}_{m_k}),
			\end{align}
			and the corresponding \gls{kkt} conditions on the primal and dual solutions are, $\forall i_q \in \mathcal{M}$ and $\forall q \in \mathcal{K}$,
			\begin{subequations}
				\begin{equation}
					- \pdv{I}{P_q^{\star}(\bar{c}_{i_q})} + \mu_q^{\star} - \lambda_{q,i_q}^{\star} = 0,
				\end{equation}
				\begin{equation}
					\lambda_{q,i_q}^{\star} = 0, \quad P_q^{\star}(\bar{c}_{i_q}) > 0,
				\end{equation}
				\begin{equation}
					\lambda_{q,i_q}^{\star} \ge 0, \quad P_q^{\star}(\bar{c}_{i_q}) = 0.
				\end{equation}
			\end{subequations}

			The partial derivative can be explicitly expressed as
			\begin{subequations}
				\begin{align}
					\pdv{I}{P_q^{\star}(\bar{c}_{i_q})}
					& = \rho I_{\mathrm{P},q}(\bar{c}_{i_q};\boldsymbol{y}) + (1 - \rho) \left( I_{\mathrm{B},q}(\bar{c}_{i_q};z) - 1 \right)\\
					& = I_q(\bar{c}_{i_q};\boldsymbol{y},z) - (1 - \rho),
				\end{align}
			\end{subequations}
			which suggests $\mu_q^{\star}$ must satisfy
			\begin{subequations}
				\begin{alignat}{2}
					\mu_q^{\star} & = I_q(\bar{c}_{i_q};\boldsymbol{y},z) - (1 - \rho), \quad && P_q^{\star}(\bar{c}_{i_q}) > 0,\\
					\mu_q^{\star} & \ge I_q(\bar{c}_{i_q};\boldsymbol{y},z) - (1 - \rho), \quad && P_q^{\star}(\bar{c}_{i_q}) = 0.
				\end{alignat}
			\end{subequations}

			Due to the sufficiency and necessity of the \gls{kkt} conditions, we can conclude that any input probability distribution $\boldsymbol{P}^{\star}$ maximizes the weighted sum primary-backscatter rate if and only if, $\forall i_q \in \mathcal{M}$ and $\forall q \in \mathcal{K}$,
			\begin{subequations}
				\begin{alignat}{2}
					I_q(\bar{c}_{i_q};\boldsymbol{y},z) & = C_q, \quad && P_q^{\star}(\bar{c}_{i_q}) > 0,\\
					I_q(\bar{c}_{i_q};\boldsymbol{y},z) & \le C_q, \quad && P_q^{\star}(\bar{c}_{i_q}) = 0,
				\end{alignat}
			\end{subequations}
			where $C_q \triangleq \mu_q^{\star} + (1 - \rho)$. Apparently, it holds that
			\begin{equation}
				\sum_{i_q} P_q^{\star}(\bar{c}_{i_q}) I_q(\bar{c}_{i_q};\boldsymbol{y},z) = C_q.
			\end{equation}

			On the other hand, by the definition of marginations \eqref{eq:backscatter_sum_rate_expectation}, \eqref{eq:primary_ergodic_rate_expectation} and weighted summations \eqref{eq:weighted_sum_marginal_information}, \eqref{eq:weighted_sum_rate}, we have
			\begin{equation}
				\sum_{i_q} P_q^{\star}(\bar{c}_{i_q}) I_q(\bar{c}_{i_q};\boldsymbol{y},z) = I(c_{\mathcal{K}};\boldsymbol{y},z),
			\end{equation}
			which is irrelevant to $q$. Hence, $C_q = I(c_{\mathcal{K}};\boldsymbol{y},z)$, $\forall q \in \mathcal{K}$ and
			\begin{subequations}
				\begin{alignat}{2}
					I_q(\bar{c}_{i_q};\boldsymbol{y},z) & = I(c_{\mathcal{K}};\boldsymbol{y},z), \quad && P_q^{\star}(\bar{c}_{i_q}) > 0,\\
					I_q(\bar{c}_{i_q};\boldsymbol{y},z) & \le I(c_{\mathcal{K}};\boldsymbol{y},z), \quad && P_q^{\star}(\bar{c}_{i_q}) = 0.
				\end{alignat}
			\end{subequations}

			It suggests that an input probability distribution maximizes the weighted primary-backscatter sum rate if and only if each probable state of each tag produces the same mutual information.
		\end{subsection}


		\begin{subsection}{Decision region}
			As indicated by \cite{Qian2019b}, the optimal \gls{ml} decision regions are very close to the optimal decision regions to problem \eqref{op:rate_region}. We can either use \eqref{eq:decision_region} as suboptimal, or take derivative of \eqref{eq:backscatter_sum_rate} w.r.t. $T_{i-1,i}$ and $T_{i,i+1}$ (however, closed-form solutions are unavailable and two-dimensional search is needed).
		\end{subsection}

		\begin{subsection}{Precoder}
			Interestingly, we can design precoder to adjust the expectation of the received power \eqref{eq:receive_variance} at each tag input combination, which can avoid the detection blind spots in \cite{Qian2019} and further boost the weighted sum-rate. However, the problem is highly non-convex -- the information function associated with input combination status $i$ is
			\begin{align}
				I(\bar{c}_i;z)
				& = \sum_{j \in \mathcal{M^K}} \int_{T_{j-1,j}}^{T_{j,j+1}} \frac{z^{N-1} \exp \left(-\frac{z}{\mathrm{tr}(H_{\mathrm{E},i} W) + \sigma_w^2}\right)}{\left(\mathrm{tr}(H_{\mathrm{E},i} W) + \sigma_w^2\right)^N (N-1)!} \dd z\nonumber\\
				& \quad \times \log \frac{\int_{T_{j-1,j}}^{T_{j,j+1}} \frac{z^{N-1} \exp \left(-\frac{z}{\mathrm{tr}(H_{\mathrm{E},i} W) + \sigma_w^2}\right)}{\left(\mathrm{tr}(H_{\mathrm{E},i} W) + \sigma_w^2\right)^N (N-1)!} \dd z}{\sum_{i' \in \mathcal{M^K}} \int_{T_{j-1,j}}^{T_{j,j+1}} \frac{z^{N-1} \exp \left(-\frac{z}{\mathrm{tr}(H_{\mathrm{E},i'} W) + \sigma_w^2}\right)}{\left(\mathrm{tr}(H_{\mathrm{E},i'} W) + \sigma_w^2\right)^N (N-1)!} \dd z},
				\label{eq:foo}
			\end{align}
			and the mutual information can be expressed as a function of $W$ by combining \eqref{eq:backscatter_sum_rate} and \eqref{eq:foo}.

			So far I have no idea how to solve this issue, and found no reference regarding precoder design for \gls{ambc}/\gls{sr} with discrete channels (although some naive combiner designs are available for \gls{bibo}). Personally, I believe the precoder design is the key to (i) boost the rate region and avoid blind spots in conventional \gls{ambc}; (ii) build our proposal over existing infrastructures. Ideally, assuming the number of transmit antennas $Q$ is larger than the number of tags $K$, the optimal energy levels should be almost uniformly spaced (as $z$ follows Erlang distribution) to concentrate the channel transitional probability on diagonal as possible.
		\end{subsection}
	\end{section}

	% \begin{section}{The Single-tag Case}
	% 	% \begin{figure}[!t]
	% 	% 	\centering
	% 	% 	\def\svgwidth{0.9\columnwidth}
	% 	% 	\import{assets/}{symbiotic_radio.pdf_tex}
	% 	% 	\caption{A single-user single-tag symbiotic radio system.}
	% 	% 	\label{fi:symbiotic_radio}
	% 	% \end{figure}
	% 	As shown in Fig.~NULL, we propose a single-user (\gls{ue}) single-tag (\gls{tg}) symbiotic radio network where the \gls{rf} signal generated by the single-antenna Access Point (\gls{ap}) is shared by two coexisting systems. In the primary \gls{ap}-\gls{ue} downlink system, the \gls{ap} transmits to the single-antenna user. In the secondary \gls{ap}-\gls{tg}-\gls{ue} backscatter system, the \gls{ap} acts as the carrier emitter, the user serves as the backscatter reader, and the single-antenna tag modulates its information over the reradiated \gls{rf} signal by varying the reflection coefficient. Denote the \gls{ap}-\gls{ue} direct channel as $h_{\mathrm{D}}$, the \gls{ap}-\gls{tg} forward channel as $h_{\mathrm{F}}$, and the \gls{tg}-\gls{ue} backward channel as $h_{\mathrm{B}}$. We consider the quasi-static block fading model and assume the CSI of the direct channel and the cascaded forward-backward channel $h_{\mathrm{C}} \triangleq h_{\mathrm{B}} h_{\mathrm{F}}$ are known at the \gls{ap}.\footnote{Due to the lack of \gls{rf} chains at the passive tag, accurate and efficient CSI acquisition at the \gls{ap} can be challenging. One possible approach is that the \gls{ap} sends known pilots, the tag responds in a pre-defined manner, and the user performs least-square estimation then feeds back to the \gls{ap} \cite{Bharadia2015,Yang2015b,Guo2019g}.} It is assumed that the primary symbol $s$ follows standard \gls{cscg} distribution $\mathcal{CN}(0,1)$ and the secondary symbol $c$ employs $M$-\gls{psk} modulation by \eqref{eq:backscatter_modulation}. Due to the practical constraints on switching speed and synchronization gap, the passive tag typically transmits at a much lower data rate than the \gls{ap}. Hence, we assume the secondary symbol period is $N \gg 1 \in \mathbb{Z}_{++}$ times the primary symbol period and focus on the interval of one particular $c$. At (primary) symbol block $n \in \mathcal{N} \triangleq \{1,\ldots,N\}$, the user simultaneously captures the signal from both primary and secondary links as\footnote{We assume the time difference of arrival from the \gls{ap}-\gls{ue} path and the \gls{ap}-\gls{tg}-\gls{ue} path are negligible compared to the symbol period \cite{Guo2019b,Liang2020,Long2020b}.}
	% 	\begin{equation}
	% 		y[n] = \sqrt{P} h_{\mathrm{D}} s[n] + \sqrt{\alpha P} h_{\mathrm{C}} c s[n] + w[n],
	% 	\end{equation}
	% 	where $P$ is the average transmit power at the \gls{ap} and $w \sim \mathcal{CN}(0,\sigma^2)$ is the additive white Gaussian noise. We also define $\boldsymbol{y} \triangleq \bigl[y[1],\ldots,y[N]\bigr]^T$.

	% 	\begin{remark}
	% 		The symbiotic radio network can be regarded as a special case of Multiple Access Channel (\gls{mac}) because the \gls{ap} and the tag simultaneously transmit to the user. It is known that Superposition Coding-Successive Interference Cancellation (\gls{sc}-\gls{sic}) with different decoding orders can achieve different vertices of the \gls{mac} capacity region \cite{Goldsmith2005}. Therefore, most relevant papers proposed the user to first decode the primary message (by treating the tag interference as noise), cancel out its contribution from the received signal, then decode the secondary message. Since the direct channel is typically much stronger than the cascaded channel \cite{Ozdogan2020}, the primary decoding is expected to enjoy a high Signal-to-Interference-and-Noise Ratio (SINR) and the secondary decoding is ideally interference-free.
	% 	\end{remark}

	% 	\begin{remark}
	% 		The main difference between symbiotic radio and conventional \gls{mac} is that the primary message also reaches the user from the backscatter link. This characteristic inspires one to first decode the tag message, then model its contribution within the equivalent channel during primary decoding (i.e., unify backscatter decoding and channel training), instead of performing \gls{sic}. In such case, the reflection pattern not only embeds the tag message but also adjusts the legacy channel in a controllable manner. Therefore, for a fixed fading block, the primary transmission is able to achieve the ergodic capacity with artificial channel variation created by the backscatter modulation. [Channel over channel, randomness over randomness]
	% 	\end{remark}

	% 	\begin{subsection}{Backscatter Transmission}
	% 		To investigate how backscatter modulation potentially benefits the primary transmission, we first decode the tag symbol $c$ in presence of the interference from the primary message $\boldsymbol{s}$. In such case, the detection indeed coincides with that of Ambient Backscatter Communications (\gls{ambc}) where the signaling from the ambient source is unknown, and the received signal per symbol block follows the \gls{cscg} distribution of $y_m[n] \sim \mathcal{CN}(0,\sigma_m^2)$, where
	% 		\begin{equation}
	% 			\sigma_m^2 \triangleq \lvert h_{\mathrm{D}} + \sqrt{\alpha} h_{\mathrm{C}} c_m \rvert^2 P + \sigma^2
	% 			\label{eq:typical_energy}
	% 		\end{equation}
	% 		denotes the typical received signal energy over $N$ symbol blocks when the tag is at state $m$, which can be estimated at the user. For the ease of exposition, we sort $\{\sigma_m^2\}$ in a ascending order by bijective mapping $f \colon m \mapsto i$\footnote{Note that the mapping is not unique and the detection fails when two different constellation points yield the same energy level.} and let $\sigma_i^2 \le \sigma_j^2$ for $i < j$, $i,j \in \mathcal{M}$. Denote $\mathcal{H}_i$ as the hypothesis that the tag transmits $c_i$. Following \cite{Qian2019}, the optimal Maximum-Likelihood (\gls{ml}) detector boils down to the energy detector, and the likelihood ratio between hypotheses $\mathcal{H}_i$ and $\mathcal{H}_j$ is
	% 		\begin{equation}
	% 			\Lambda_{i,j}(\boldsymbol{y}) = \frac{f(\boldsymbol{y} \mid \mathcal{H}_i)}{f(\boldsymbol{y} \mid \mathcal{H}_j)} = \left( \frac{\sigma_j^2}{\sigma_i^2} \right)^N \exp \left( \frac{(\sigma_i^2 - \sigma_j^2) z}{\sigma_i^2 \sigma_j^2} \right),
	% 		\end{equation}
	% 		where $f(\boldsymbol{y} \mid \mathcal{H}_i)$, $f(\boldsymbol{y} \mid \mathcal{H}_j)$ denote respectively the conditional probability density function of receiving $\boldsymbol{y}$ under hypothesis $\mathcal{H}_i$ and $\mathcal{H}_j$, and $z \triangleq \lVert y \rVert^2$ is the received signal energy over $N$ symbol blocks. The corresponding decision rule is
	% 		\begin{equation}
	% 			\Lambda_{i,j}(\boldsymbol{y}) \underset{H_j}{\overset{H_i}{\lessgtr}} 1 \iff z \underset{H_j}{\overset{H_i}{\lessgtr}} T_{i,j},
	% 		\end{equation}
	% 		where the optimal detection threshold is
	% 		\begin{equation}
	% 			T_{i,j} \triangleq N \frac{\sigma_i^2 \sigma_j^2}{\sigma_i^2 - \sigma_j^2} \log \frac{\sigma_i^2}{\sigma_j^2},
	% 			\label{eq:detection_threshold}
	% 		\end{equation}
	% 		and the decision region of hypothesis $\mathcal{H}_i$ can be expressed as
	% 		\begin{equation}
	% 			\mathcal{R}_i \triangleq [T_{i-1, i}, T_{i, i+1}),
	% 			\label{eq:decision_region_}
	% 		\end{equation}
	% 		with $T_{0, 1} \triangleq 0$ and $T_{M, M+1} \triangleq \infty$. On top of this, we define the forward transition probability matrix $\boldsymbol{P} \in \mathbb{R}_{+}^{M \times M}$ as
	% 		\begin{equation}
	% 			\boldsymbol{P} \triangleq
	% 			\begin{bmatrix}
	% 				p_{1, 1} & \ldots & p_{1, M} \\
	% 				\vdots & \ddots & \vdots \\
	% 				p_{M, 1} & \ldots & p_{M, M}
	% 			\end{bmatrix},
	% 		\end{equation}
	% 		where $p_{i,j}$ denotes the transition probability from channel input state $i$ to output state $j$. It can be derived as
	% 		\begin{equation}
	% 			p_{i,j} = p(z \in \mathcal{R}_j \mid \mathcal{H}_i) = \int_{\mathcal{R}_j} f(z \mid \mathcal{H}_i) \dd z,
	% 			\label{eq:transition_probability}
	% 		\end{equation}
	% 		where $f(z \mid \mathcal{H}_i)$ is the conditional probability density function of receiving $z$ under hypothesis $\mathcal{H}_i$. Since $z$ follows chi-squared distribution with $2N$ degrees of freedom, it holds that
	% 		\begin{equation}
	% 			f(z \mid \mathcal{H}_i) = \frac{z^{N-1} e^{-z/\sigma_i^2}}{\sigma_i^{2N} \Gamma(N)},
	% 			\label{eq:conditional_pdf}
	% 		\end{equation}
	% 		where $\Gamma(\cdot)$ is the gamma function. To summarize, with the CSI of the direct and cascaded links, the typical energy of the received signal can be estimated by \eqref{eq:typical_energy}, the energy detection threshold can be computed by \eqref{eq:detection_threshold}, the decision region can be retrieved by \eqref{eq:decision_region}, and the forward transition matrix $\boldsymbol{P}$ can be calculated by substituting \eqref{eq:conditional_pdf} into \eqref{eq:transition_probability}.

	% 		We then investigate the achievable rate of the backscatter link. Denote the tag input probability mass function as $\boldsymbol{r} = [r_1,\ldots,r_M]^T \in \mathbb{R}_+^{M \times 1}$ where $r_m$ is the probability to transmit symbol $c_m$ [strictly positive?]. For a given input distribution $\boldsymbol{r}$ and forward transition matrix $\boldsymbol{P}$, the achievable backscatter rate can be written as
	% 		\begin{equation}
	% 			R_c = \max_{\boldsymbol{Q} \ge 0} \sum_{i \in \mathcal{M}} \sum_{j \in \mathcal{M}} r_i p_{i,j} \log_2 \frac{q_{j, i}}{r_i} \ [\si{bpcu}],
	% 			\label{eq:secondary_rate}
	% 		\end{equation}
	% 		where $\boldsymbol{Q} \in \mathbb{R}_{+}^{M \times M}$ is the backward transition probability matrix
	% 		\begin{equation}
	% 			\boldsymbol{Q} \triangleq
	% 			\begin{bmatrix}
	% 				q_{1, 1} & \ldots & q_{1, M} \\
	% 				\vdots & \ddots & \vdots \\
	% 				q_{M, 1} & \ldots & q_{M, M}
	% 			\end{bmatrix},
	% 		\end{equation}
	% 		and $q_{j, i}$ denotes the transition probability from channel output state $j$ to input state $i$.
	% 	\end{subsection}

	% 	\begin{subsection}{Legacy Transmission}
	% 		Once the backscattered symbol is successfully recovered, it is combined with the cascaded channel to eliminate the uncertainty of the \gls{ap}-\gls{tg}-\gls{ue} path and assist the legacy transmission. Therefore, the received signal at symbol block $n$ is essentially
	% 		\begin{equation}
	% 			y[n] = \sqrt{P} (h_{\mathrm{D}} + \sqrt{\alpha} h_{\mathrm{C}} c) s[n] + w[n] \triangleq \sqrt{P} h_{\mathrm{E}}(c) s + w[n],
	% 		\end{equation}
	% 		which is reminiscent of an \gls{irs}-aided point-to-point transmission with an equivalent channel of
	% 		\begin{equation}
	% 			h_{\mathrm{E}}(c) \triangleq h_{\mathrm{D}} + \sqrt{\alpha} h_{\mathrm{C}} c.
	% 		\end{equation}
	% 		For primary transmission, backscatter modulation creates an artificial fast fading within each fading block, and \gls{ap} can obtain the equivalent CSI distribution for any given tag input probability mass function $\boldsymbol{r}$. Therefore, the ergodic capacity of primary transmission within each symbol block is \cite{Tse2005}
	% 		\begin{align}
	% 			R_s
	% 			& = \mathbb{E}_c \bigl[ \log_2 (1 + \gamma \lvert h_{\mathrm{E}}(c) \rvert^2) \bigr] \nonumber \\
	% 			& = \sum_{i \in \mathcal{M}} r_i \log_2 \bigl( 1 + \gamma \lvert h_{\mathrm{D}} + \sqrt{\alpha} h_{\mathrm{C}} c_i \rvert^2 \bigr) \ [\si{bps/Hz}],
	% 			\label{eq:primary_rate}
	% 		\end{align}
	% 		where $\gamma \triangleq P / \sigma^2$ is the average transmit Signal-to-Noise Ratio (SNR). It can be concluded that the achievable rate of both primary and secondary links depend on the tag input distribution.
	% 	\end{subsection}
	% 	\label{se:system_model}

	% 	\begin{subsection}{Achievable rate region}
	% 		To achieve a flexible tradeoff between the backscatter and legacy links, we aims to optimize the tag input probability mass function, under $M$-\gls{psk} modulation, to maximize the weighted sum of the primary and secondary rates subject to the sum-probability constraint
	% 		\begin{maxi!}
	% 			{\scriptstyle{\boldsymbol{r} \ge 0}}{\rho R_s + (1 - \rho) R_c}{\label{op:weighted_sum_rate}}{\label{ob:weighted_sum_rate}}
	% 			\addConstraint{\sum_{i \in \mathcal{M}} r_i}{=1,}{\label{co:sum_probability}}
	% 		\end{maxi!}
	% 		where $\rho \in [0, 1]$ is the weight factor. By substituting \eqref{eq:secondary_rate} and \eqref{eq:primary_rate} into \eqref{ob:weighted_sum_rate}, the problem expands to
	% 		\begin{maxi!}
	% 			{\scriptstyle{\boldsymbol{r} \ge 0, \boldsymbol{Q} \ge 0}}{\rho \sum_{i \in \mathcal{M}} r_i \log_2 \bigl( 1 + \gamma \lvert h_{\mathrm{D}} + \sqrt{\alpha} h_{\mathrm{C}} c_i \rvert^2 \bigr) \nonumber}{}{}
	% 			\breakObjective{+ (1 - \rho) \sum_{i \in \mathcal{M}} \sum_{j \in \mathcal{M}} r_i p_{i,j} \log_2 \frac{q_{j, i}}{r_i}}{\label{ob:weighted_sum_rate_expanded}}
	% 			\addConstraint{\sum_{i \in \mathcal{M}} r_i}{=1.}{}
	% 		\end{maxi!}
	% 		Similar to the Blahut-Arimoto algorithm \cite{Arimoto1972,Blahut1972}, we optimize $\boldsymbol{r}$ and $\boldsymbol{Q}$ alternatively to obtain the local optimal tag input distribution and the corresponding weighted sum-rate.
	% 		\begin{theorem}
	% 			For any valid tag input probability mass function $\boldsymbol{r}$ [$\boldsymbol{r} > \boldsymbol{0}$?], the optimal backward transition probability from channel output state $j$ to input state $i$ follows Bayes' Theorem as
	% 			\begin{equation}
	% 				q_{j, i}^{\star} = \frac{r_i p_{i,j}}{\sum_{i'} r_{i'} p_{i', j}}.
	% 				\label{eq:backward_transition}
	% 			\end{equation}
	% 			\label{th:backward_transition}
	% 		\end{theorem}
	% 		\begin{proof}
	% 			Please refer to Appendix~\ref{ap:backward_transition}.
	% 		\end{proof}
	% 		\begin{theorem}
	% 			For any valid backward transition probability $\boldsymbol{Q}$ [$\boldsymbol{Q} \ge 0$?], the optimal tag input probability mass function is given by
	% 			\begin{equation}
	% 				r_i = \frac{\bigl( 1 + \gamma \lvert h_{\mathrm{D}} + \sqrt{\alpha} h_{\mathrm{C}} c_i \rvert^2 \bigr)^{\rho / (1 - \rho)} \prod_{j \in \mathcal{M}} q_{j, i}^{p_{i,j}}}{\sum_{i' \in \mathcal{M}} \bigl( 1 + \gamma \lvert h_{\mathrm{D}} + \sqrt{\alpha} h_{\mathrm{C}} c_{i'} \rvert^2 \bigr)^{\rho / (1 - \rho)} \prod_{j \in \mathcal{M}} q_{j, i'}^{p_{i', j}}}.
	% 				\label{eq:input_distribution}
	% 			\end{equation}
	% 			\label{th:input_distribution}
	% 		\end{theorem}
	% 		\begin{proof}
	% 			Please refer to Appendix~\ref{ap:input_distribution}.
	% 		\end{proof}
	% 		\begin{proposition}
	% 			For any feasible initial point [constellation subset], the Algorithm is guaranteed to converge to the global optimal of problem \eqref{op:weighted_sum_rate} and achieve the maximum weighted-sum rate.
	% 		\end{proposition}
	% 		\begin{proof}
	% 			The proof is similar to that in \cite[Chapter~9.3]{Yeung2008} and omitted here.
	% 		\end{proof}
	% 	\end{subsection}
	% \end{section}

	% \begin{section}{OFDM}
	% 	Due to the constraint of energy detection, with single-antenna tags and reader, at most one \gls{ambc} tag can be decoded at a time and accurate detection requires repetition coding over multiple time/frequency blocks to mitigate the impact of primary symbols. Here we consider frequency-independent tag reflection and schedule one tag per OFDM symbol.

	% 	At OFDM symbol $r$, tag $l$ modulates its own information over all $N$ subcarriers while the remaining tags may operate in the cooperative (quantized \gls{irs}) mode. Channel frequency response at subband $n$ and block $r$
	% 	Received signal at OFDM symbol $r$ and subband $n$ is
	% 	\begin{equation}
	% 		y_n[r] = \sqrt{P} h_{\mathrm{E}}[r] s_n[r] + \sqrt{\alpha P} h_{\mathrm{C},l} c_l s_n[r] + w_n[r],
	% 	\end{equation}
	% 	where $h_{\mathrm{E}}[r] \triangleq \sum_{l' \ne l} h_{\mathrm{C},l'} c_{l'}^\star$ and $c_l$ is the symbol of tag $l$. Apparently $y_n[r] \sim \mathcal{CN}(0,\sigma_n^2[r])$ with $\sigma_n^2[r] \triangleq \lvert h_{\mathrm{E}}[r] + \sqrt{\alpha} h_{\mathrm{C},l} c_l \rvert^2 P + \sigma^2$. Define $\boldsymbol{y}[r] \triangleq [y_1[r],\ldots,y_N[r]]^T$ and we can do energy detection over $N$ subcarriers.
	% \end{section}

	% \begin{section}{Multi-Tag Case}
	% 	In the $K$-tag scenario, the received signal at symbol block $n$ is
	% 	\begin{equation}
	% 		y[n] = \sqrt{P} h_{\mathrm{D}} s[n] + \sum_k \sqrt{\alpha_k} h_{\mathrm{C},k} c_k \sqrt{P} s[n] + w[n].
	% 	\end{equation}

	% 	On the one hand, we can compute the \emph{sum-rate} of the tags and characterize the (ergodic) primary-secondary capacity region by adjusting weight $\rho$. The weighted sum-rate can be expressed as
	% 	\begin{align}
	% 		J_1
	% 		& = \rho \mathbb{E}_{\boldsymbol{c}} \left[ \log_2 \left( 1 + \gamma \lvert h_{\mathrm{D}} + \sum_k \sqrt{\alpha_k} h_{\mathrm{C},k} c_k \rvert \right) \right] + (1 - \rho) R_c\\
	% 		& = \rho \sum_{i_1,\dots,i_K \in \mathcal{M}} \prod_{k \in \mathcal{K}} r_{k,i_k} \log_2 \left( 1 + \gamma \lvert h_{\mathrm{D}} + \sum_{k' \in \mathcal{K}} \sqrt{\alpha_{k'}} h_{\mathrm{C},k'} c_{k',i_{k'}} \rvert^2 \right)\\
	% 		& \quad + (1 - \rho) \sum_{i \in \mathcal{M}} \sum_{j \in \mathcal{M}^K} \sum_{k \in \mathcal{K}} r_{k,i} p_{i,j} \log \frac{q_{j,i}}{r_{k,i}}.
	% 	\end{align}
	% 	In this case, although we can independently maximize the primary/secondary rate in closed form (resp. quantized \gls{irs} and multi-user Blahut-Arimoto), the joint form can be tricky due to the $K$-product term. We may consider a 2-loop iterative algorithm, where the inner loop optimizes input distribution over letters while the outer loop over users. I am still working on the convergence and optimality proofs and they are very deep into information theory.

	% 	On the other hand, we can compute the rate region of the user and $K$ tags. However, the capacity region of discrete \gls{mac} remains unknown. We can obtain its outer bound by formulating a non-convex problem with a rank-1 constraint, then solve the relaxed problem. The difficulty is that the optimization is performed over $K$-dimensional array $\mathbb{R}^{\underbrace{M \times \ldots \times M}_{K}}$.
	% \end{section}


	% \begin{appendix}
	% 	\begin{subsection}{Proof of Theorem~\ref{th:backward_transition}}
	% 		Denote the objective function \eqref{ob:weighted_sum_rate_expanded} as $R(\boldsymbol{r}, \boldsymbol{Q})$. Let $w_j \triangleq \sum_{i'} r_{i'} p_{i', j}$ and rearrange \eqref{eq:backward_transition} as
	% 		\begin{equation}
	% 			w_j q_{j, i}^{\star} = r_i p_{i,j}.
	% 		\end{equation}
	% 		Therefore,
	% 		\begin{align}
	% 			R(\boldsymbol{r}, \boldsymbol{Q}^{\star}) - R(\boldsymbol{r}, \boldsymbol{Q})
	% 			& = (1 - \rho) \sum_{i \in \mathcal{M}} \sum_{j \in \mathcal{M}} r_i p_{i,j} \log_2 \frac{q_{j, i}^{\star}}{q_{j, i}} \nonumber \\
	% 			& = (1 - \rho) \sum_{i \in \mathcal{M}} \sum_{j \in \mathcal{M}} w_j q_{j, i}^{\star} \log_2 \frac{q_{j, i}^{\star}}{q_{j, i}} \nonumber \\
	% 			& = (1 - \rho) \sum_{j \in \mathcal{M}} w_j \sum_{i \in \mathcal{M}} q_{j, i}^{\star} \log_2 \frac{q_{j, i}^{\star}}{q_{j, i}} \nonumber \\
	% 			& = (1 - \rho) \sum_{j \in \mathcal{M}} w_j \infdiv{q_{j, i}^{\star}}{q_{j, i}} \nonumber \\
	% 			& \ge 0,
	% 		\end{align}
	% 		with equality iff $\boldsymbol{Q} = \boldsymbol{Q}^{\star}$.
	% 		\label{ap:backward_transition}
	% 	\end{subsection}
	% 	\begin{subsection}{Proof of Theorem~\ref{th:input_distribution}}
	% 		We employ the method of Lagrange multipliers, temporally ignore the constraint $\boldsymbol{r} \ge 0$, and assume all logarithms are of base $e$. Define the Lagrangian function as
	% 		\begin{align}
	% 			J
	% 			& = \rho \sum_{i \in \mathcal{M}} r_i \log \bigl( 1 + \gamma \lvert h_{\mathrm{D}} + \sqrt{\alpha} h_{\mathrm{C}} c_i \rvert^2 \bigr) \nonumber \\
	% 			& \quad + (1 - \rho) \sum_{i \in \mathcal{M}} \sum_{j \in \mathcal{M}} r_i p_{i,j} \log \frac{q_{j, i}}{r_i} + \lambda \left( 1 - \sum_{i \in \mathcal{M}} r_i \right),
	% 		\end{align}
	% 		where $\lambda$ is the Lagrange multiplier associated with the sum-probability constraint. Differentiating $J$ with respect to $r_i$ gives
	% 		\begin{align}
	% 			\pdv{J}{r_i}
	% 			& = \rho \log \bigl( 1 + \gamma \lvert h_{\mathrm{D}} + \sqrt{\alpha} h_{\mathrm{C}} c_i \rvert^2 \bigr) \\
	% 			& \quad + (1 - \rho) \left( \sum_{j \in \mathcal{M}} p_{i,j} \log q_{j, i} - \log r_i - 1 \right),
	% 		\end{align}
	% 		and setting $\pdv*{J}{r_i} = 0$ suggests
	% 		\begin{equation}
	% 			r_i = e^{ -(\frac{\lambda}{1 - \rho} + 1)} \bigl( 1 + \gamma \lvert h_{\mathrm{D}} + \sqrt{\alpha} h_{\mathrm{C}} c_i \rvert^2 \bigr)^{\rho / (1 - \rho)} \prod_{j \in \mathcal{M}} q_{j, i}^{p_{i,j}}.
	% 		\end{equation}
	% 		By considering $\sum_{i \in \mathcal{M}} r_i = 1$, we can eliminate $\lambda$ and obtain the optimal tag input distribution as \eqref{eq:input_distribution}.
	% 		\label{ap:input_distribution}
	% 	\end{subsection}
	% \end{appendix}

	\bibliographystyle{IEEEtran}
	\bibliography{IEEEabrv,library.bib}
\end{document}
